# app/tasks.py

import logging
from datetime import datetime
import pytz
from flask import current_app
from apscheduler.schedulers.background import BackgroundScheduler

from . import db
from .models import Article
from .wp_client import post_to_wp  # çµ±ä¸€ã•ã‚ŒãŸ WordPress æŠ•ç¨¿é–¢æ•°
from sqlalchemy.orm import selectinload

# âœ… GSCã‚¯ãƒªãƒƒã‚¯ãƒ»è¡¨ç¤ºå›æ•°ã®æ¯æ—¥æ›´æ–°ã‚¸ãƒ§ãƒ–ç”¨
from app.google_client import update_all_gsc_sites


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ãª APScheduler ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆ__init__.py ã§ start ã•ã‚Œã¦ã„ã¾ã™ï¼‰
scheduler = BackgroundScheduler(timezone="UTC")


def _auto_post_job(app):
    with app.app_context():
        now = datetime.now(pytz.utc)

        try:
            pending = (
                db.session.query(Article)
                .filter(Article.status == "done", Article.scheduled_at <= now)
                .options(selectinload(Article.site))
                .order_by(Article.scheduled_at.asc())
                .limit(300)
                .all()
            )

            for art in pending:
                if not art.site:
                    current_app.logger.warning(f"è¨˜äº‹ {art.id} ã®æŠ•ç¨¿å…ˆã‚µã‚¤ãƒˆæœªè¨­å®š")
                    continue

                try:
                    url = post_to_wp(art.site, art)
                    art.posted_at = now
                    art.status = "posted"
                    db.session.commit()
                    current_app.logger.info(f"Auto-posted Article {art.id} -> {url}")

                except Exception as e:
                    db.session.rollback()
                    current_app.logger.warning(f"åˆå›æŠ•ç¨¿å¤±æ•—: Article {art.id} {e}")

                    retry_attempts = 3
                    for attempt in range(retry_attempts):
                        try:
                            url = post_to_wp(art.site, art)
                            art.posted_at = now
                            art.status = "posted"
                            db.session.commit()
                            current_app.logger.info(f"Retry Success: Article {art.id} -> {url}")
                            break
                        except Exception as retry_exception:
                            db.session.rollback()
                            current_app.logger.warning(
                                f"Retry {attempt + 1} failed for Article {art.id}: {retry_exception}"
                            )

        finally:
            db.session.close()

def _gsc_metrics_job(app):
    """
    âœ… GSCã‚¯ãƒªãƒƒã‚¯ãƒ»è¡¨ç¤ºå›æ•°ã®æ¯æ—¥æ›´æ–°ã‚¸ãƒ§ãƒ–
    """
    with app.app_context():
        current_app.logger.info("ğŸ”„ GSCãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°ã‚¸ãƒ§ãƒ–ã‚’é–‹å§‹ã—ã¾ã™")
        try:
            update_all_gsc_sites()
            current_app.logger.info("âœ… GSCãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°å®Œäº†")
        except Exception as e:
            current_app.logger.error(f"âŒ GSCãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°å¤±æ•—: {str(e)}")

def gsc_loop_generate(site):
    """
    ğŸ” GSCã‹ã‚‰ã®ã‚¯ã‚¨ãƒªã§1000è¨˜äº‹æœªæº€ãªã‚‰é€šå¸¸è¨˜äº‹ãƒ•ãƒ­ãƒ¼ã§ç”Ÿæˆã™ã‚‹
    """
    from app import db
    from app.google_client import fetch_search_queries_for_site
    from app.models import Keyword
    from app.article_generator import enqueue_generation
    from flask import current_app

    if not site.gsc_connected:
        current_app.logger.info(f"[GSC LOOP] ã‚¹ã‚­ãƒƒãƒ—ï¼šæœªæ¥ç¶šã‚µã‚¤ãƒˆ {site.name}")
        return

    total_keywords = Keyword.query.filter_by(site_id=site.id).count()
    if total_keywords >= 1000:
        current_app.logger.info(f"[GSC LOOP] {site.name} ã¯æ—¢ã«1000è¨˜äº‹ã«åˆ°é”æ¸ˆã¿")
        return

    try:
        queries = fetch_search_queries_for_site(site, days=28)
    except Exception as e:
        current_app.logger.warning(f"[GSC LOOP] ã‚¯ã‚¨ãƒªå–å¾—å¤±æ•— - {site.url}: {e}")
        return

    existing_keywords = set(
        k.keyword for k in Keyword.query.filter_by(site_id=site.id).all()
    )
    new_keywords = [q for q in queries if q not in existing_keywords]

    if not new_keywords:
        current_app.logger.info(f"[GSC LOOP] {site.name} ã«æ–°è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãªã—")
        return

    for kw in new_keywords:
        db.session.add(Keyword(
            keyword=kw,
            site_id=site.id,
            user_id=site.user_id,
            source='gsc',
            status='pending',   # â† é€šå¸¸è¨˜äº‹ã¨åŒã˜
            used=False
        ))

    db.session.commit()
    
    from app.models import PromptTemplate
    prompt = PromptTemplate.query.filter_by(user_id=site.user_id).order_by(PromptTemplate.id.desc()).first()
    if prompt:
        title_prompt = prompt.title_pt   # â˜… ä¿®æ­£ï¼šæ­£ã—ã„ã‚«ãƒ©ãƒ å title_pt
        body_prompt  = prompt.body_pt    # â˜… ä¿®æ­£ï¼šæ­£ã—ã„ã‚«ãƒ©ãƒ å body_pt
    else:
        title_prompt = ""
        body_prompt  = ""

    # ğŸ”§â˜…ä¿®æ­£â‘¡ï¼šenqueue_generation ã« format/self_review ã‚‚æ¸¡ã™ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§OKãªã‚‰çœç•¥å¯èƒ½ï¼‰
    from app.article_generator import enqueue_generation

    BATCH = 40  # â˜… 1ãƒãƒƒãƒã‚ãŸã‚Šã®ä¸Šé™
    for i in range(0, len(new_keywords), BATCH):
        kw_batch = new_keywords[i : i + BATCH]     # â˜… ã‚¹ãƒ©ã‚¤ã‚¹ã§40ä»¶ãšã¤å–ã‚Šå‡ºã™

        enqueue_generation(                        # â˜… ã“ã“ã‚’ãƒ«ãƒ¼ãƒ—å†…ã¸
            user_id      = site.user_id,
            site_id      = site.id,
            keywords     = kw_batch,
            title_prompt = title_prompt,
            body_prompt  = body_prompt,
            format       = "html",
            self_review  = False,
        )


        current_app.logger.info(                   # â˜… ãƒãƒƒãƒã”ã¨ã®ãƒ­ã‚°
            f"[GSC LOOP] {site.name} â†’ batch {i//BATCH+1}: {len(kw_batch)} ä»¶ã‚­ãƒ¥ãƒ¼æŠ•å…¥"
        )

def _gsc_generation_job(app):
    """
    âœ… GSCè¨˜äº‹è‡ªå‹•ç”Ÿæˆã‚¸ãƒ§ãƒ–ï¼ˆæ¯æ—¥ï¼‰
    """
    with app.app_context():
        from app.models import Site

        current_app.logger.info("ğŸ“ GSCè¨˜äº‹ç”Ÿæˆã‚¸ãƒ§ãƒ–ã‚’é–‹å§‹ã—ã¾ã™")
        sites = Site.query.filter_by(gsc_connected=True).all()

        for site in sites:
            try:
                gsc_loop_generate(site)
            except Exception as e:
                current_app.logger.warning(f"[GSCè‡ªå‹•ç”Ÿæˆ] å¤±æ•— - {site.url}: {e}")

        current_app.logger.info("âœ… GSCè¨˜äº‹ç”Ÿæˆã‚¸ãƒ§ãƒ–ãŒå®Œäº†ã—ã¾ã—ãŸ")


def init_scheduler(app):
    """
    Flask ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã«å‘¼ã³å‡ºã—ã¦:
      1) APScheduler ã«è‡ªå‹•æŠ•ç¨¿ã‚¸ãƒ§ãƒ–ã‚’ç™»éŒ²
      2) 3åˆ†é–“éš”ã§ _auto_post_job ã‚’å®Ÿè¡Œã™ã‚‹ã‚ˆã†ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
      - GSCè¨˜äº‹ç”Ÿæˆã‚¸ãƒ§ãƒ–ï¼š10åˆ†é–“éš”ï¼ˆâ†ã“ã“ä¿®æ­£ï¼‰
    """
    scheduler.add_job(
        func=_auto_post_job,
        trigger="interval",
        minutes=3,
        args=[app],
        id="auto_post_job",
        replace_existing=True,
        max_instances=1
    )

    # âœ… GSCã‚¯ãƒªãƒƒã‚¯ãƒ»è¡¨ç¤ºå›æ•°ã‚’æ¯æ—¥0æ™‚ã«è‡ªå‹•æ›´æ–°ã™ã‚‹ã‚¸ãƒ§ãƒ–
    scheduler.add_job(
        func=_gsc_metrics_job,
        trigger="cron",
        hour=0,
        minute=0,
        args=[app],
        id="gsc_metrics_job",
        replace_existing=True,
        max_instances=1
    )

    # âœ… GSCè¨˜äº‹ç”Ÿæˆã‚¸ãƒ§ãƒ–
    scheduler.add_job(
        func=_gsc_generation_job,
        trigger="interval",
        minutes=10,
        args=[app],
        id="gsc_generation_job",
        replace_existing=True,
        max_instances=1
    )


    scheduler.start()
    app.logger.info("Scheduler started: auto_post_job every 3 minutes")
    app.logger.info("Scheduler started: gsc_metrics_job daily at 0:00")
    app.logger.info("Scheduler started: gsc_generation_job every 10 minutes")