from __future__ import annotations
from datetime import timedelta
import logging
logger = logging.getLogger(__name__)
from flask import current_app  # æ—¢å­˜ã§ä½¿ç”¨ã€æ˜ç¤º
from sqlalchemy.exc import OperationalError  # âœ… è¿½åŠ ï¼šsafe_commit ç”¨

from flask import (
    Blueprint, render_template, redirect, url_for,
    flash, request, abort, g, jsonify, current_app, send_from_directory, session
)
from flask_login import (
    login_user, logout_user, login_required, current_user
)
from werkzeug.security import generate_password_hash, check_password_hash
from pytz import timezone
from sqlalchemy import asc, nulls_last
from sqlalchemy.orm import selectinload

from app.extensions import func

from . import db
from .models import User, Article, PromptTemplate, Site, Keyword, Genre
from .forms import (
    LoginForm, RegisterForm,
    GenerateForm, PromptForm, ArticleForm, SiteForm, 
    ProfileForm
)
from .article_generator import enqueue_generation
from .wp_client import post_to_wp, _decorate_html, fetch_single_post

# --- æ—¢å­˜ã® import ã®ä¸‹ã«è¿½åŠ  ---
import re
import os
import logging
import openai
import threading
import datetime
from .image_utils import fetch_featured_image  # â† âœ… æ­£ã—ã„
from collections import defaultdict
from urllib.parse import quote, urlsplit

from .article_generator import (
    _unique_title,
    _compose_body,
    _generate,
)
from app.forms import EditKeywordForm
from .forms import KeywordForm
from app.image_utils import _is_image_url

from app.services.blog_signup.livedoor_signup import generate_livedoor_id_candidates
from app.services.blog_signup.livedoor_atompub_recover import open_create_tab_for_handoff
# === Title & Meta ãƒãƒƒãƒå†ç”Ÿæˆï¼ˆç®¡ç†APIï¼‰ã§å‘¼ã¶é–¢æ•° ===
from app.tasks import run_title_meta_backfill

# ==== å¤–éƒ¨SEO: ç°¡æ˜“ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚¹ãƒˆã‚¢ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³â†’çŠ¶æ…‹ï¼‰ ====
EXTSEO_STATUS = {}  # { token: { step, progress, captcha_url, site_id, account_id, ... } }

def _extseo_update(token: str, **kv):
    """å¤–éƒ¨SEOã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ãƒãƒ¼ã‚¸æ›´æ–°ï¼ˆprogressã¯0-100ã«ä¸¸ã‚ã‚‹ï¼‰"""
    st = dict(EXTSEO_STATUS.get(token) or {})
    for k, v in kv.items():
        if v is None:
            continue
        if k == "progress" and isinstance(v, (int, float)):
            v = max(0, min(100, int(v)))
        st[k] = v
    EXTSEO_STATUS[token] = st
    return st



JST = timezone("Asia/Tokyo")
bp = Blueprint("main", __name__)

# å¿…è¦ãªã‚‰ app/__init__.py ã§ admin_bp ã‚’ç™»éŒ²
admin_bp = Blueprint("admin", __name__)

from app import db
from app.models import User, Site, Article
# ãƒªãƒ©ã‚¤ãƒˆè¨ˆç”»ãƒ†ãƒ¼ãƒ–ãƒ«ï¼šå­˜åœ¨åã«åˆã‚ã›ã¦ importã€‚ãªã‘ã‚Œã° fallback ã§ text() ã‚’ä½¿ã†
try:
    from app.models import ArticleRewritePlan
except Exception:
    ArticleRewritePlan = None
from sqlalchemy import text as _sql_text
from app.tasks import rewrite_enqueue_for_user
from app.tasks import _rewrite_retry_job, _serp_warmup_nightly_job
from concurrent.futures import ThreadPoolExecutor
_ui_executor = ThreadPoolExecutor(max_workers=2, thread_name_prefix="ui-triggers")

# --- Topic API: ãƒ˜ãƒƒãƒ€ãƒˆãƒ¼ã‚¯ãƒ³èªè¨¼ãƒ˜ãƒ«ãƒ‘ ---
def _topic_api_authorized() -> tuple[bool, int | None]:
    """
    X-Topic-Token ã‚’æ¤œè¨¼ã—ã¦ (ok, user_id) ã‚’è¿”ã™ã€‚
    - ãƒ­ã‚°ã‚¤ãƒ³ä¸è¦ã§å©ããŸã‚ã®è»½é‡APIéµ
    - ç¾çŠ¶ã¯ç’°å¢ƒå¤‰æ•° or å›ºå®šå€¤ 'local-test-token' ã‚’è¨±å¯
    """
    try:
        token = (request.headers.get("X-Topic-Token") or "").strip()
        allowed = {t for t in (os.getenv("TOPIC_API_TOKEN"), "local-test-token") if t}
        if token and token in allowed:
            uid = int(os.getenv("TOPIC_API_USER_ID", "1"))
            return True, uid
    except Exception:
        current_app.logger.exception("[topic_api] token parse/verify failed")
    return False, None


# === Impersonation helpers =====================================================
# ç½®ãå ´æ‰€ï¼šbp/admin_bp ã‚’ä½œã£ãŸç›´å¾Œï¼ˆæœ€åˆã®ãƒ«ãƒ¼ãƒˆå®šç¾©ã‚ˆã‚Šå‰ï¼‰

def is_admin_effective() -> bool:
    """
    ç¾åœ¨ãƒ­ã‚°ã‚¤ãƒ³ä¸­ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç®¡ç†è€…ã€ã¾ãŸã¯ admin_id ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿æŒã—ã¦ã„ã‚‹
    ï¼ˆ=ç®¡ç†è€…ãŒãªã‚Šã™ã¾ã—ä¸­ï¼‰ãªã‚‰ True
    """
    try:
        return (
            getattr(current_user, "is_authenticated", False)
            and (getattr(current_user, "is_admin", False) or session.get("admin_id"))
        )
    except Exception:
        return False

from functools import wraps

def admin_required_effective(view_func):
    """
    ãªã‚Šã™ã¾ã—ä¸­ã§ã‚‚ç®¡ç†è€…æ¨©é™ã‚’ç¶­æŒã—ã¦ã„ã‚‹å ´åˆã¯é€šã™ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼
    """
    @wraps(view_func)
    @login_required
    def _wrapped(*args, **kwargs):
        if not is_admin_effective():
            abort(403)
        return view_func(*args, **kwargs)
    return _wrapped

@admin_bp.route("/admin/return")
@login_required
def admin_return():
    """
    ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜ã—ãŸ admin_id ã«æˆ»ã‚‹ï¼ˆç®¡ç†è€…ã¸å¾©å¸°ï¼‰
    """
    admin_id = session.get("admin_id")
    if not admin_id:
        flash("ç®¡ç†è€…ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚", "warning")
        return redirect(url_for("main.dashboard", username=current_user.username))

    admin = User.query.get(admin_id)
    if not admin:
        session.pop("admin_id", None)
        flash("ç®¡ç†è€…ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚", "danger")
        return redirect(url_for("main.login"))

    login_user(admin)
    session.pop("admin_id", None)
    flash("ç®¡ç†è€…ã«æˆ»ã‚Šã¾ã—ãŸã€‚", "info")
    return redirect(url_for("admin.admin_users"))
# ==============================================================================

# ------------------------------------------------------------------------------
# ç®¡ç†API: Title & Meta ãƒãƒƒãƒå†ç”Ÿæˆ
#
# ãƒ»ã‚¿ã‚¤ãƒˆãƒ«ï¼šè¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ã‚’ãã®ã¾ã¾ <title> ã¨ã—ã¦åˆ©ç”¨ï¼ˆDBæ›´æ–°ã¯ä¸è¦ï¼‰
# ãƒ»ãƒ¡ã‚¿èª¬æ˜ï¼šAIã§è‡ªå‹•ç”Ÿæˆï¼ˆæ—¢å®š180æ–‡å­—ï¼‰ã€‚æ—¢å­˜è¨˜äº‹ã¸ä¸€æ‹¬é©ç”¨ã€‚
#
# 
# å—ã‘å–ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆGET/POSTã¨ã‚‚å¯ï¼‰:
#   - site_id: int       â€¦ å¯¾è±¡ã‚µã‚¤ãƒˆé™å®šï¼ˆçœç•¥å¯ï¼‰
#   - user_id: int       â€¦ å¯¾è±¡ãƒ¦ãƒ¼ã‚¶ãƒ¼é™å®šï¼ˆçœç•¥å¯ï¼‰
#   - limit: int         â€¦ 1å›ã®å‡¦ç†ä¸Šé™ï¼ˆæ—¢å®š 200ï¼‰
#   - dryrun: bool       â€¦ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã¿ï¼ˆDBæ›¸è¾¼ãªã—ï¼‰ã€‚true/1/on ã§æœ‰åŠ¹
#   - push_to_wp: bool   â€¦ DBåæ˜ å¾Œã« WP ã¸ã‚‚åŒæœŸï¼ˆposted è¨˜äº‹ã®ã¿ï¼‰ã€‚dryrunæ™‚ã¯ç„¡è¦–
#   - after_id: int      â€¦ ç¶šãå®Ÿè¡Œç”¨ã‚«ãƒ¼ã‚½ãƒ«ï¼ˆå‰å›ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã® cursor ã‚’æ¸¡ã™ï¼‰
#
# ä¾‹:
#   GET  /admin/tools/title-meta-backfill?site_id=1&limit=200&dryrun=1
#   POST /admin/tools/title-meta-backfill  ï¼ˆJSON/FORM ã§åŒãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
# ------------------------------------------------------------------------------
def _as_bool(v):
    if isinstance(v, bool):
        return v
    s = str(v).strip().lower()
    return s in ("1", "true", "yes", "on")

def _as_int(v, default=None):
    try:
        return int(v)
    except Exception:
        return default
    
import time
import os
from flask import render_template, request, jsonify, current_app
try:
    from flask_wtf.csrf import csrf_exempt
except Exception:
    csrf_exempt = lambda f: f  # WTFormsæœªä½¿ç”¨ç’°å¢ƒã§ã‚‚å‹•ã‹ã™ãŸã‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
from app import db
from sqlalchemy.orm import load_only
from sqlalchemy import func, case, or_

try:
    # ã‚ãªãŸã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã® User / Site / Article ãƒ¢ãƒ‡ãƒ«åã«åˆã‚ã›ã¦ import
    from app.models import User, Site, Article
except Exception:
    User = None
    Site = None
    Article = None

@admin_bp.route("/admin/tools/title-meta-backfill", methods=["GET", "POST"])
@admin_required_effective
@csrf_exempt  # â† ã“ã®APIã ã‘CSRFå…é™¤ï¼ˆç¢ºå®Ÿã«é€šã™ï¼‰
def admin_title_meta_backfill():
    """
    Title & Meta ãƒãƒƒãƒå†ç”Ÿæˆï¼ˆUIç°¡ç•¥ç‰ˆï¼‰
    - GET: è¶…è»½é‡æç”»ï¼ˆDBã‚¢ã‚¯ã‚»ã‚¹ãªã—ï¼‰ã§ãƒ†ãƒ³ãƒ—ãƒ¬ã¸
    - POST: user_id ã®ã¿å—ã‘å–ã‚Šã€ãƒãƒƒãƒå‡¦ç†ã‚’è‡ªå‹•ã§æœ€å¾Œã¾ã§å®Ÿè¡Œï¼ˆDBåæ˜  + posted ã¯ WP åŒæœŸï¼‰
    """
    # ---- GET: è¶…è»½é‡æç”»ï¼ˆDBãƒ’ãƒƒãƒˆç¦æ­¢ï¼‰----
    if request.method == "GET":
        t0 = time.perf_counter()
        # ã“ã®ãƒšãƒ¼ã‚¸ã¯åˆå›è¡¨ç¤ºã‚’æœ€é€Ÿã«ã™ã‚‹ãŸã‚ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼/ã‚µã‚¤ãƒˆã®DBå–å¾—ã‚’è¡Œã‚ãªã„
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å€™è£œã¯ãƒ†ãƒ³ãƒ—ãƒ¬å´ã§ /admin/tools/_users ã‚’AJAXé…å»¶å–å¾—ã™ã‚‹å‰æ
        users, sites = [], []
        dt = int((time.perf_counter() - t0) * 1000)
        current_app.logger.info("[admin:title-meta] FAST render (no DB) in %dms", dt)
        return render_template("admin/title_meta_backfill.html", users=users, sites=[])

    # ---- POST: â€œã“ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¨è¨˜äº‹ã«é©ç”¨ï¼ˆè‡ªå‹•ã§æœ€å¾Œã¾ã§ï¼‰â€ ----
    payload = (request.get_json(silent=True) or {}) or request.form.to_dict()
    current_app.logger.info("[admin:title-meta:POST] payload=%s", payload)
    user_id = _as_int(payload.get("user_id"))
    if not user_id:
        return jsonify({"ok": False, "error": "user_id is required"}), 400

    # æ—¢å®šæŒ™å‹•ï¼šDBåæ˜  + postedã®ã¿ WP åæ˜ ã€‚limit ã¯å†…éƒ¨ã§ååˆ†å¤§ããã—ã¦å‘¨å›æ•°ã‚’æ¸›ã‚‰ã™
    LIMIT_PER_CHUNK = _as_int(os.getenv("ADMIN_TM_LIMIT_PER_CHUNK", 500), 500) or 500
    MAX_ITERS       = _as_int(os.getenv("ADMIN_TM_MAX_ITERS", 200), 200) or 200

    from app.tasks import run_title_meta_backfill as _run_title_meta_backfill

    total_updated = 0
    iters = 0
    cursor = None
    last_result = {}
    # â˜… è¿½åŠ : WPåæ˜ ã®å®Ÿç¸¾ã‚«ã‚¦ãƒ³ã‚¿ï¼ˆåˆ†å­/åˆ†æ¯/å†…è¨³ï¼‰ã‚’åˆç®—
    wp_target_total_sum = 0
    wp_synced_ok_sum    = 0
    wp_unresolved_sum   = 0
    wp_failed_sum       = 0

    while True:
        iters += 1
        if iters > MAX_ITERS:
            current_app.logger.warning("[admin:title-meta] reached MAX_ITERS user_id=%s cursor=%s", user_id, cursor)
            break
        result = _run_title_meta_backfill(
            site_id=None,
            user_id=user_id,
            limit=LIMIT_PER_CHUNK,
            dryrun=False,
            after_id=cursor,
            push_to_wp=True,   # æ—§ã€Œæœ¬é©ç”¨ + WPåæ˜ ã€ã«ç›¸å½“
        )
        last_result = result
        if not result or not result.get("ok"):
            # å¤±æ•—ã¯å³çµ‚äº†
            status = 400
            err = (result or {}).get("error", "unknown error")
            return jsonify({"ok": False, "error": err, "updated": total_updated, "iterations": iters-1}), status

        # 1ãƒãƒ£ãƒ³ã‚¯ã®æ›´æ–°ä»¶æ•°ï¼ˆå­˜åœ¨ã™ã‚Œã°ï¼‰ã‚’åŠ ç®—
        total_updated += int(result.get("updated", 0))

        # â˜… è¿½åŠ : ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã®WPå®Ÿç¸¾ã‚’åˆç®—ï¼ˆã‚­ãƒ¼ãŒç„¡ã„æ—§ç‰ˆã§ã‚‚0æ‰±ã„ï¼‰
        wp_target_total_sum += int(result.get("wp_target_total", 0) or 0)
        wp_synced_ok_sum    += int(result.get("wp_synced_ok", 0) or 0)
        wp_unresolved_sum   += int(result.get("wp_unresolved", 0) or 0)
        wp_failed_sum       += int(result.get("wp_failed", 0) or 0)

        # ç¶šãã‚«ãƒ¼ã‚½ãƒ«ã®ã‚­ãƒ¼åã¯å®Ÿè£…å·®ç•°ã«åˆã‚ã›ã¦ä¸¡å¯¾å¿œ
        cursor = result.get("cursor") or result.get("next_after_id")
        done   = bool(result.get("done")) or (cursor in (None, "", 0))
        if done:
            break

    summary = {
        "ok": True,
        "user_id": user_id,
        "updated_total": total_updated,
        "iterations": iters,
        "last_cursor": cursor,
        "last_chunk": {
            "updated": int(last_result.get("updated", 0)),
            "cursor": last_result.get("cursor"),
            "done": bool(last_result.get("done")),
            # å‚è€ƒ: æœ€çµ‚ãƒãƒ£ãƒ³ã‚¯å˜ä½“ã®WPå®Ÿç¸¾ï¼ˆUIã§â€œç›´è¿‘ã®å‹•ãâ€ã‚’è¦‹ãŸã„å ´åˆã«ä½¿ç”¨å¯ï¼‰
            "wp_target_total": int(last_result.get("wp_target_total", 0) or 0),
            "wp_synced_ok":    int(last_result.get("wp_synced_ok", 0) or 0),
            "wp_unresolved":   int(last_result.get("wp_unresolved", 0) or 0),
            "wp_failed":       int(last_result.get("wp_failed", 0) or 0),
        },
        # â˜… åˆç®—ï¼ˆUIã®åˆ†å­/åˆ†æ¯ã¯ã“ã¡ã‚‰ã‚’åˆ©ç”¨ï¼‰
        "wp_target_total": wp_target_total_sum,   # åˆ†æ¯: WPåæ˜ å¯¾è±¡ï¼ˆpostedã®ã¿ï¼‰
        "wp_synced_ok":    wp_synced_ok_sum,      # åˆ†å­: å®Ÿéš›ã«WPã¸åæ˜ æˆåŠŸ
        "wp_unresolved":   wp_unresolved_sum,     # æœªè§£æ±ºï¼ˆwp_post_idè¦‹ã¤ã‹ã‚‰ãšç­‰ï¼‰
        "wp_failed":       wp_failed_sum,         # APIç­‰ã®å¤±æ•—
    }
    return jsonify(summary), 200


# --------------------------------------------------------------------
# ãƒ¦ãƒ¼ã‚¶ãƒ¼è¡Œï¼ˆä¸€è¦§ãƒ†ãƒ¼ãƒ–ãƒ«ï¼‰ã®è»½é‡API
#   - åˆå›ãƒ¬ãƒ³ãƒ€ã¯ç©ºHTML â†’ ã“ã®APIã§ãƒ‡ãƒ¼ã‚¿ã‚’é…å»¶å–å¾—
#   - æ¤œç´¢: ?q=ï¼ˆusername/email ã®éƒ¨åˆ†ä¸€è‡´ï¼‰
#   - ãƒšãƒ¼ã‚¸ãƒ³ã‚°: ?page=1&per_page=20
#   - é€²æ—ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆæœ¬ãƒ‘ãƒƒãƒã§åˆ·æ–°ï¼‰:
#       åˆ†æ¯: ã€ŒæŠ•ç¨¿è¨˜äº‹ã€æ•°ï¼ˆæ—¢å®š: published_only=1ï¼‰
#             â†’ posted_at IS NOT NULL ã¾ãŸã¯ posted_url <> ''
#       åˆ†å­: meta_description ãŒéç©ºï¼ˆCOALESCE(...,'') <> ''ï¼‰
# --------------------------------------------------------------------
@admin_bp.route("/admin/tools/title-meta-rows", methods=["GET"])
@admin_required_effective
def admin_title_meta_rows():
    if User is None or Site is None or Article is None:
        return jsonify({"items": [], "total": 0, "page": 1, "per_page": 20})

    q = (request.args.get("q") or "").strip()
    # æ—¢å®šã¯ã€Œå…¬é–‹è¨˜äº‹ã®ã¿ã€ã‚’åˆ†æ¯ã«ã™ã‚‹ï¼ˆUIã§ç·æ•°ãƒ™ãƒ¼ã‚¹ã«å¤‰ãˆãŸã„æ™‚ã¯ ?published_only=0ï¼‰
    published_only = (request.args.get("published_only", "1").strip().lower() in ("1", "true", "yes", "on"))
    try:
        page = max(1, int(request.args.get("page", "1")))
        per_page = max(1, min(50, int(request.args.get("per_page", "20"))))
    except Exception:
        page, per_page = 1, 20
    offset = (page - 1) * per_page

    # å¯¾è±¡ãƒ¦ãƒ¼ã‚¶ãƒ¼é›†åˆï¼ˆæ¤œç´¢ãƒ»ãƒšãƒ¼ã‚¸ãƒ³ã‚°ï¼‰
    uq = db.session.query(User.id, User.username, User.email).order_by(User.id.asc())
    if q:
        like = f"%{q}%"
        uq = uq.filter(
            func.lower(User.username).like(func.lower(like)) |
            func.lower(User.email).like(func.lower(like))
        )
    total_users = uq.count()
    users = uq.offset(offset).limit(per_page).all()
    user_ids = [int(u.id) for u in users]
    if not user_ids:
        return jsonify({"items": [], "total": total_users, "page": page, "per_page": per_page})

    # è¨˜äº‹ã®ä¸‹åœ°ï¼ˆåˆ†æ¯/åˆ†å­ã¨ã‚‚ã“ã®é›†åˆã‹ã‚‰ç®—å‡ºï¼‰
    # â† ã“ã“ã‚’()ã§æ‹¬ã£ã¦ãƒã‚§ãƒ¼ãƒ³ã‚’æ”¹è¡Œã€‚æ‰‹å‹•ãƒ¡ã‚¿ã¯åˆ†æ¯ã‹ã‚‰é™¤å¤–
    base_q = (
        db.session.query(
            Article.user_id.label("user_id"),
            Article.site_id.label("site_id"),
            func.coalesce(Article.meta_description, "").label("meta_description"),
            Article.posted_at.label("posted_at"),
            func.coalesce(Article.posted_url, "").label("posted_url"),
        )
        .filter(Article.user_id.in_(user_ids))
        .filter(Article.is_manual_meta == False)  # åˆ†æ¯ã‹ã‚‰æ‰‹å‹•ãƒ¡ã‚¿ã‚’å¤–ã™
    )

    if published_only:
        base_q = base_q.filter(
            or_(
                Article.posted_at.isnot(None),
                func.coalesce(Article.posted_url, "") != ""
            )
        )

    base_sub = base_q.subquery()
    applied_cond = (func.coalesce(base_sub.c.meta_description, "") != "")

    # --- ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥ é›†è¨ˆï¼ˆåˆ†æ¯/åˆ†å­/ç‡ï¼‰ ---
    u_rows = (
        db.session.query(
            base_sub.c.user_id.label("user_id"),
            func.count(base_sub.c.user_id).label("total_cnt"),
            func.sum(case((applied_cond, 1), else_=0)).label("applied_cnt"),
        )
        .group_by(base_sub.c.user_id)
        .all()
    )
    totals_map   = {int(r.user_id): int(r.total_cnt or 0)   for r in u_rows}
    applied_map  = {int(r.user_id): int(r.applied_cnt or 0) for r in u_rows}

    # --- ã‚µã‚¤ãƒˆåˆ¥ å†…è¨³ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã¾ã¨ã‚ã¦å–å¾—ï¼‰ ---
    s_rows = (
        db.session.query(
            base_sub.c.user_id.label("user_id"),
            base_sub.c.site_id.label("site_id"),
            func.count(base_sub.c.site_id).label("total"),
            func.sum(case((applied_cond, 1), else_=0)).label("applied"),
        )
        .group_by(base_sub.c.user_id, base_sub.c.site_id)
        .all()
    )

    # ã‚µã‚¤ãƒˆåã‚’ã¾ã¨ã‚ã¦å¼•ã
    site_ids = sorted({int(r.site_id) for r in s_rows if r.site_id is not None})
    site_map = {}
    if site_ids:
        for s in db.session.query(Site.id, Site.name, Site.url).filter(Site.id.in_(site_ids)).all():
            site_map[int(s.id)] = (s.name or s.url or f"site#{int(s.id)}")

    per_user_sites = {}
    for r in s_rows:
        uid = int(r.user_id)
        sid = int(r.site_id) if r.site_id is not None else 0
        if sid == 0:
            # site_id ç„¡ã—ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆé›†è¨ˆã¨ã—ã¦ã¯æ®‹ã™å ´åˆã¯ã“ã“ã‚’å¤–ã™ï¼‰
            continue
        per_user_sites.setdefault(uid, []).append({
            "site_id": sid,
            "name": site_map.get(sid, f"site#{sid}"),
            "total": int(r.total or 0),
            "applied": int(r.applied or 0),
            "percentage": float(round((float(r.applied or 0) / float(r.total)) * 100.0, 2)) if r.total else 0.0,
        })

    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ•´å½¢ï¼šæ•´å‚™å¯¾è±¡ãŒ0ã§ã‚‚ãƒ¦ãƒ¼ã‚¶ãƒ¼è¡Œã‚’è¿”ã™
    items = []
    for u in users:
        uid = int(u.id)
        total = int(totals_map.get(uid, 0))
        applied = int(applied_map.get(uid, 0))
        target = max(total - applied, 0)  # äº’æ›: æ—§UIç”¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
        pct = float(round((applied / total) * 100.0, 2)) if total else 0.0
        sites = sorted(per_user_sites.get(uid, []), key=lambda x: -x["total"])[:6]
        items.append({
            "user_id": uid,
            "username": u.username,
            "email": u.email,
            "total_cnt": total,
            "applied_cnt": applied,
            "percentage": pct,
            "target_cnt": target,   # â˜… äº’æ›ã®ãŸã‚æ®‹ã™ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬æ›´æ–°å¾Œã¯ä¸è¦ï¼‰
            "sites": sites,
        })

    return jsonify({"items": items, "total": total_users, "page": page, "per_page": per_page})


# ------------------------------------------------------------------------------
# ä¸€è¦§ãƒ†ãƒ¼ãƒ–ãƒ«ç”¨ã®è»½é‡APIï¼ˆ1ãƒ¦ãƒ¼ã‚¶ãƒ¼=1è¡Œï¼‰
#   - æ—¢å­˜ãƒšãƒ¼ã‚¸ã®åˆæœŸæç”»ã¯DBã‚¢ã‚¯ã‚»ã‚¹ãªã—ã‚’ç¶­æŒã€‚ãƒ•ãƒ­ãƒ³ãƒˆãŒæœ¬APIã‚’AJAXå‘¼ã³å‡ºã—
#   - é›†è¨ˆæ¡ä»¶:
#       is_manual_meta = false
#       status IN ('done','posted')
#       meta_desc_quality IN ('empty','too_short','too_long','duplicate')
#   - è¿”å´: ãƒ¦ãƒ¼ã‚¶ãƒ¼1è¡Œ + ã‚µã‚¤ãƒˆå†…è¨³ï¼ˆæ¨ªãƒãƒƒãƒ—å‘ã‘ï¼‰
# ------------------------------------------------------------------------------
@admin_bp.route("/admin/tools/title-meta-users", methods=["GET"])
@admin_required_effective
def admin_title_meta_users():
    if Article is None or User is None or Site is None:
        return jsonify({"users": []})

    # ã‚¯ã‚¨ãƒªãƒ»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆå¿…è¦æœ€å°é™ã®ã¿ï¼‰
    qualities = request.args.get("qualities")
    if qualities:
        quality_targets = tuple([q.strip() for q in qualities.split(",") if q.strip()])
    else:
        quality_targets = ("empty", "too_short", "too_long", "duplicate")

    try:
        limit_users = int(request.args.get("limit", "0"))  # 0=åˆ¶é™ãªã—
        limit_users = max(0, limit_users)
    except Exception:
        limit_users = 0

    # è¨˜äº‹å´ã®åŸºç¤é›†è¨ˆï¼ˆuser_id, site_id ã”ã¨ï¼‰
    base = (
        db.session.query(
            Article.user_id.label("user_id"),
            Article.site_id.label("site_id"),
            func.count(Article.id).label("targets"),
            func.sum(case((Article.status == "posted", 1), else_=0)).label("posted_targets"),
            func.sum(case((Article.status == "done",   1), else_=0)).label("done_targets"),
        )
        .filter(Article.is_manual_meta == False)  # noqa: E712
        .filter(Article.status.in_(("done", "posted")))
        .filter(Article.meta_desc_quality.in_(quality_targets))
        .group_by(Article.user_id, Article.site_id)
    )

    rows = base.all()
    if not rows:
        return jsonify({"users": []})

    # userâ†’siteå†…è¨³ ã¸æ•´å½¢
    per_user = {}
    user_ids = set()
    site_ids = set()
    for r in rows:
        uid = int(r.user_id)
        sid = int(r.site_id) if r.site_id is not None else 0
        user_ids.add(uid)
        if sid:
            site_ids.add(sid)
        item = per_user.setdefault(uid, {"user_id": uid, "targets": 0, "sites": []})
        item["targets"] += int(r.targets or 0)
        if sid:
            item["sites"].append({
                "site_id": sid,
                "targets": int(r.targets or 0),
                "posted":  int(r.posted_targets or 0),
                "done":    int(r.done_targets or 0),
            })

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚’æœ€å°é›†åˆã ã‘å–å¾—
    users_meta = {}
    if user_ids:
        q_users = (
            db.session.query(User.id, User.username)
            .filter(User.id.in_(list(user_ids)))
            .order_by(User.id.asc())
        )
        for u in q_users.all():
            users_meta[int(u.id)] = {"name": u.username}

    # ã‚µã‚¤ãƒˆè¡¨ç¤ºåã‚’æœ€å°é›†åˆã ã‘å–å¾—
    sites_meta = {}
    if site_ids:
        q_sites = (
            db.session.query(Site.id, Site.name, Site.url)
            .filter(Site.id.in_(list(site_ids)))
            .order_by(Site.id.asc())
        )
        for s in q_sites.all():
            sites_meta[int(s.id)] = {"name": (s.name or s.url or f"site#{s.id}")}
    # è¡¨ç¤ºç”¨ã«æ•´å½¢ï¼ˆã‚µã‚¤ãƒˆã¯åå‰ã‚’ä»˜ä¸ã—ã€targetsé™é †ã§ä¸¦ã¹ã‚‹ï¼‰
    users = []
    for uid, info in per_user.items():
        sites = info["sites"]
        # ã‚µã‚¤ãƒˆåä»˜ä¸
        for s in sites:
            meta = sites_meta.get(int(s["site_id"]), {})
            s["name"] = meta.get("name", f"site#{s['site_id']}")
        # é™é †
        sites.sort(key=lambda x: x["targets"], reverse=True)
        users.append({
            "user_id": uid,
            "name": users_meta.get(uid, {}).get("name", f"user#{uid}"),
            "targets": info["targets"],
            "sites": sites,
        })

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚‚ targets é™é †ã§ä¸¦ã¹ã‚‹
    users.sort(key=lambda x: x["targets"], reverse=True)
    if limit_users and len(users) > limit_users:
        users = users[:limit_users]

    current_app.logger.info("[admin:title-meta:list] users=%s (qualities=%s)", len(users), ",".join(quality_targets))
    return jsonify({"users": users})



# ------------------------------------------------------------------------------
# è»½é‡ã‚µã‚¸ã‚§ã‚¹ãƒˆAPI: ãƒ¦ãƒ¼ã‚¶ãƒ¼ / ã‚µã‚¤ãƒˆ
# ------------------------------------------------------------------------------
@admin_bp.route("/admin/tools/_users", methods=["GET"])
@admin_required_effective
def admin_tools_users_suggest():
    """
    ?q= ï¼ˆusername or email ã®éƒ¨åˆ†ä¸€è‡´ï¼‰, ?limit=ï¼ˆæ—¢å®š20ï¼‰
    """
    if User is None:
        return jsonify({"items": []})
    q = (request.args.get("q") or "").strip()
    try:
        limit = max(1, min(50, int(request.args.get("limit", "20"))))
    except Exception:
        limit = 20
    qry = db.session.query(User.id, User.username, User.email).order_by(User.id.asc())
    if q:
        like = f"%{q}%"
        qry = qry.filter(
            func.lower(User.username).like(func.lower(like)) |
            func.lower(User.email).like(func.lower(like))
        )
    rows = qry.limit(limit).all()
    items = [{"id": r.id, "label": f"#{r.id} {r.username} <{r.email}>" } for r in rows]
    return jsonify({"items": items})

@admin_bp.route("/admin/tools/_sites", methods=["GET"])
@admin_required_effective
def admin_tools_sites_suggest():
    """
    ?q= éƒ¨åˆ†ä¸€è‡´, ?user_id= ã§çµè¾¼, ?limit=ï¼ˆæ—¢å®š20ï¼‰
    """
    if Site is None:
        return jsonify({"items": []})
    q = (request.args.get("q") or "").strip()
    user_id = request.args.get("user_id")
    try:
        limit = max(1, min(50, int(request.args.get("limit", "20"))))
    except Exception:
        limit = 20
    qry = db.session.query(Site.id, Site.name, Site.url).order_by(Site.id.asc())
    if user_id:
        try:
            uid = int(user_id)
            qry = qry.filter(Site.user_id == uid)
        except Exception:
            pass
    if q:
        like = f"%{q}%"
        qry = qry.filter(
            func.lower(func.coalesce(Site.name, "")).like(func.lower(like)) |
            func.lower(Site.url).like(func.lower(like))
        )
    rows = qry.limit(limit).all()
    items = [{"id": r.id, "label": f"#{r.id} {r.name or r.url}"} for r in rows]
    return jsonify({"items": items})

# ------------------------------------------------------------------------------
# é€²æ—API: ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥ Title/Meta é©ç”¨çŠ¶æ³
#   åˆ†æ¯: å…¨è¨˜äº‹ï¼ˆstatus ä¸å•ï¼‰/ å…¬é–‹è¨˜äº‹ã®ã¿ã¯ ?published_only=1
#   åˆ†å­: meta_description ãŒéç©ºï¼ˆ+ ä»»æ„ã§ meta_desc_last_updated_at IS NOT NULLï¼‰
# ------------------------------------------------------------------------------
@admin_bp.route("/admin/tools/title-meta-progress", methods=["GET"])
@admin_required_effective
def admin_title_meta_progress():
    if Article is None:
        return jsonify({"ok": False, "error": "Article model not available"}), 500
    try:
        user_id = int(request.args.get("user_id", "0"))
    except Exception:
        return jsonify({"ok": False, "error": "user_id is required"}), 400
    if user_id <= 0:
        return jsonify({"ok": False, "error": "user_id is required"}), 400

    published_only = (request.args.get("published_only", "0") in ("1", "true", "yes", "on"))

    base = db.session.query(Article).filter(Article.user_id == user_id)
    if published_only:
        # å…¬é–‹æ¸ˆã¿åˆ¤å®š: posted_at ã¾ãŸã¯ posted_url ã®ã©ã¡ã‚‰ã‹ãŒå…¥ã£ã¦ã„ã‚Œã°å…¬é–‹ã¨ã¿ãªã™
        base = base.filter(or_(Article.posted_at.isnot(None), func.coalesce(Article.posted_url, "") != ""))

    # ä»¥é™ã§ã‚µãƒ–ã‚¯ã‚¨ãƒªåˆ—ã ã‘ã‚’å‚ç…§ã§ãã‚‹ã‚ˆã†ã€å¿…è¦åˆ—ã«çµã£ã¦åˆ¥åä»˜ã‘
    base_sub = (
        base.with_entities(
            Article.id.label("id"),
            Article.site_id.label("site_id"),
            Article.meta_description.label("meta_description"),
        ).subquery()
    )
    # ã‚µãƒ–ã‚¯ã‚¨ãƒªåˆ—ç‰ˆã®é©ç”¨æ¡ä»¶
    applied_cond_sub = func.coalesce(base_sub.c.meta_description, "") != ""

    # åˆ†æ¯ï¼šå…¨ä»¶æ•°
    total = db.session.query(func.count(base_sub.c.id)).scalar() or 0
    # åˆ†å­ï¼šmeta_description ãŒéç©º
    applied = (
        db.session.query(
            func.sum(case((applied_cond_sub, 1), else_=0))
        ).scalar() or 0
    )

    by_site_rows = (
        db.session.query(
            base_sub.c.site_id.label("site_id"),
            func.count(base_sub.c.id).label("total"),
            func.sum(case((applied_cond_sub, 1), else_=0)).label("applied"),
        )
        .select_from(base_sub)
        .group_by(base_sub.c.site_id)
        .order_by(base_sub.c.site_id)
        .limit(500)
        .all()
    )
    by_site = [{"site_id": int(r.site_id), "total": int(r.total), "applied": int(r.applied or 0)} for r in by_site_rows]

    pct = (applied / total * 100.0) if total else 0.0
    return jsonify({
        "ok": True,
        "user_id": user_id,
        "published_only": published_only,
        "total": total,
        "applied": applied,
        "percentage": round(pct, 2),
        "by_site": by_site,
    })


@bp.route('/robots.txt')
def robots_txt():
    return send_from_directory('static', 'robots.txt')

# routes.py ã¾ãŸã¯ api.py å†…

from app.models import User, ChatLog, GSCConfig
from datetime import datetime

@bp.route("/api/chat", methods=["POST"])
def chat_api():
    data = request.get_json()
    user_msg = data.get("message", "").strip()
    username = data.get("username", "ãƒ¦ãƒ¼ã‚¶ãƒ¼")

    if not user_msg:
        return jsonify({"reply": "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒç©ºã§ã™ã€‚"})

    try:
        user = User.query.filter_by(username=username).first()
        if not user:
            return jsonify({"reply": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"})

        # éå»ã®å±¥æ­´ï¼ˆæœ€æ–°10ä»¶ï¼‰
        logs = ChatLog.query.filter_by(user_id=user.id).order_by(ChatLog.timestamp.desc()).limit(10).all()
        logs = list(reversed(logs))  # æ™‚ç³»åˆ—é †ã«ã™ã‚‹

        # ä¼šè©±å±¥æ­´ã‚’æ§‹æˆ
        messages = [
            {
                "role": "system",
                "content": f"ã‚ãªãŸã¯VER12.AI-posting-toolã€site craftã€å°‚å±ã®AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼ˆ{username}ã•ã‚“ï¼‰ã‚’åå‰ã§å‘¼ã³ãªãŒã‚‰ã€è¦ªã—ã¿ã‚„ã™ãã‚µãƒãƒ¼ãƒˆã—ã¦ãã ã•ã„ã€‚"
            }
        ]
        for log in logs:
            messages.append({"role": log.role, "content": log.content})

        messages.append({"role": "user", "content": user_msg})

        # OpenAIå‘¼ã³å‡ºã—
        client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            max_tokens=300,
            temperature=0.7
        )
        reply = response.choices[0].message.content.strip()

        # âœ… DBã«ä¿å­˜
        db.session.add(ChatLog(user_id=user.id, role="user", content=user_msg))
        db.session.add(ChatLog(user_id=user.id, role="assistant", content=reply))
        db.session.commit()

        return jsonify({"reply": reply})

    except Exception as e:
        return jsonify({"reply": f"ã‚¨ãƒ©ãƒ¼ï¼š{str(e)}"})


import stripe
from app import db
from app.models import User, UserSiteQuota, PaymentLog

stripe_webhook_bp = Blueprint('stripe_webhook', __name__)

@stripe_webhook_bp.route("/stripe/webhook", methods=["POST"])
def stripe_webhook():
    payload = request.data
    sig_header = request.headers.get("stripe-signature")
    webhook_secret = current_app.config["STRIPE_WEBHOOK_SECRET"]

    # ãƒ­ã‚°å‡ºåŠ›ï¼šå—ä¿¡è¨˜éŒ²
    current_app.logger.info("ğŸ“© Stripe Webhook Received")
    current_app.logger.info(payload.decode("utf-8"))

    try:
        event = stripe.Webhook.construct_event(payload, sig_header, webhook_secret)
    except stripe.error.SignatureVerificationError:
        current_app.logger.error("âŒ Webhook signature verification failed")
        return "Webhook signature verification failed", 400
    except Exception as e:
        current_app.logger.error(f"âŒ Error parsing webhook: {str(e)}")
        return f"Error parsing webhook: {str(e)}", 400

    # PaymentIntentï¼ˆé€šå¸¸è³¼å…¥ã‚‚ç‰¹åˆ¥è³¼å…¥ã‚‚ã“ã“ã§å‡¦ç†ï¼‰
    if event["type"] == "payment_intent.succeeded":
        intent = event["data"]["object"]
        metadata = intent.get("metadata", {})

        user_id = metadata.get("user_id")
        site_count = int(metadata.get("site_count", 1))
        plan_type = metadata.get("plan_type", "affiliate")
        special = metadata.get("special", "no")
        stripe_payment_id = intent.get("id")

        # å€¤ã®ãƒã‚§ãƒƒã‚¯
        if special not in ["yes", "no"]:
            current_app.logger.warning(f"âš ï¸ ç„¡åŠ¹ãª special ãƒ•ãƒ©ã‚°ï¼š{special}")
            return jsonify({"message": "Invalid special flag"}), 400

        if not user_id:
            current_app.logger.warning("âš ï¸ metadata ã« user_id ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
            return jsonify({"message": "Missing user_id"}), 400

        # SiteQuotaLogã§ã®å†ªç­‰æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆé‡è¤‡å‡¦ç†é˜²æ­¢ï¼‰
        existing_quota_log = SiteQuotaLog.query.filter_by(stripe_payment_id=stripe_payment_id).first()
        if existing_quota_log:
            current_app.logger.warning("âš ï¸ ã“ã®æ”¯æ‰•ã„ã¯ã™ã§ã«Quotaã«åæ˜ æ¸ˆã¿ã§ã™")
            return jsonify({"message": "Quota already granted"}), 200

        user = User.query.get(int(user_id))
        if not user:
            current_app.logger.warning(f"âš ï¸ user_id={user_id} ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return jsonify({"message": "User not found"}), 400

        # QuotaåŠ ç®—å‡¦ç†
        quota = UserSiteQuota.query.filter_by(user_id=user.id).first()
        if not quota:
            quota = UserSiteQuota(user_id=user.id, total_quota=0, used_quota=0, plan_type=plan_type)
            db.session.add(quota)

        quota.total_quota += site_count
        quota.plan_type = plan_type
        db.session.commit()

        current_app.logger.info(
            f"âœ… QuotaåŠ ç®—: user_id={user.id}, plan={plan_type}, site_count={site_count}, special={special}"
        )

        # SiteQuotaLogã«å±¥æ­´ã‚’ä¿å­˜
        quota_log = SiteQuotaLog(
            user_id=user.id,
            stripe_payment_id=stripe_payment_id,
            site_count=site_count,
            reason="Stripeæ”¯æ‰•ã„"
        )
        db.session.add(quota_log)
        db.session.commit()

        # PaymentLogä¿å­˜å‡¦ç†
        amount = intent.get("amount")   # âœ… æ­£ç¢ºãªå°æ•°ã§ä¿æŒ
        email = intent.get("receipt_email") or intent.get("customer_email")

        charge_id = intent.get("latest_charge")
        charge = stripe.Charge.retrieve(charge_id)
        balance_tx_id = charge.get("balance_transaction")
        balance_tx = stripe.BalanceTransaction.retrieve(balance_tx_id)

        if not email:
            email = user.email

        fee = balance_tx.fee # âœ… å°æ•°ã§ä¿æŒ
        net = balance_tx.net

        log = PaymentLog(
            user_id=user.id,
            email=email,
            amount=amount,
            fee=fee,
            net_income=net,
            plan_type=plan_type,
            stripe_payment_id=stripe_payment_id,
            status="succeeded"
        )
        db.session.add(log)
        db.session.commit()

        current_app.logger.info(f"ğŸ’° PaymentLog ä¿å­˜ï¼š{email} Â¥{amount}")

    return jsonify(success=True)


# Stripe APIã‚­ãƒ¼ã‚’èª­ã¿è¾¼ã¿
stripe.api_key = os.getenv("STRIPE_SECRET_KEY")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ create-payment-intent
@bp.route("/create-payment-intent", methods=["POST"])
def create_payment_intent():
    try:
        data = request.get_json()

        # âœ… å€¤ã®å–å¾—ã¨ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        user_id = data.get("user_id")
        if user_id is None:
            raise ValueError("user_id is required")

        plan_type = data.get("plan_type", "affiliate")
        site_count = int(data.get("site_count", 1))
        special = data.get("special", "no")

        # âœ… special, plan_type ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        if special not in ["yes", "no"]:
            raise ValueError(f"Invalid special value: {special}")
        if plan_type not in ["affiliate", "business"]:
            raise ValueError(f"Invalid plan_type: {plan_type}")

        user_id = int(user_id)  # âœ… intå¤‰æ›ã¯å¾Œã«ã™ã‚‹ï¼ˆã‚¨ãƒ©ãƒ¼å¯¾å‡¦ã®ãŸã‚ï¼‰

        # ğŸ”¸ ç‰¹åˆ¥ãƒ—ãƒ©ãƒ³ã‹ã©ã†ã‹ã§ä¾¡æ ¼ã‚’è¨­å®š
        if special == "yes":
            unit_price = 1000
        else:
            unit_price = 5000 if plan_type == "affiliate" else 20000

        total_amount = unit_price * site_count

        # âœ… Stripe PaymentIntent ã‚’ä½œæˆ
        intent = stripe.PaymentIntent.create(
            amount=total_amount,
            currency="jpy",
            automatic_payment_methods={"enabled": True},
            payment_method_options={
                "card": {
                    "request_three_d_secure": "any"
                }
            },
            metadata={  # âœ… Webhookã§å¿…è¦ãªæƒ…å ±ã‚’ã™ã¹ã¦åŸ‹ã‚è¾¼ã‚€
                "user_id": str(user_id),
                "plan_type": plan_type,
                "site_count": str(site_count),
                "special": special
            }
        )

        # âœ… æˆåŠŸãƒ­ã‚°ï¼ˆãƒ‡ãƒãƒƒã‚°ã—ã‚„ã™ãï¼‰
        current_app.logger.info(
            f"âœ… PaymentIntent ä½œæˆ: user_id={user_id}, plan_type={plan_type}, site_count={site_count}, special={special}, amount={total_amount}"
        )

        return jsonify({"clientSecret": intent.client_secret})

    except Exception as e:
        import traceback
        current_app.logger.error(f"[create-payment-intent ã‚¨ãƒ©ãƒ¼] {e}")
        current_app.logger.error(traceback.format_exc())
        return jsonify(error=str(e)), 400

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ é€šå¸¸è³¼å…¥ãƒšãƒ¼ã‚¸
@bp.route("/purchase", methods=["GET", "POST"])
@login_required
def purchase():
    if request.method == "POST":
        plan_type = request.form.get("plan_type")
        site_count = int(request.form.get("site_count", 1))

        if plan_type == "affiliate":
            price_id = os.getenv("STRIPE_PRICE_ID_AFFILIATE")
        elif plan_type == "business":
            price_id = os.getenv("STRIPE_PRICE_ID_BUSINESS")
        else:
            price_id = None

        if not price_id:
            flash("ä¸æ­£ãªãƒ—ãƒ©ãƒ³ãŒé¸æŠã•ã‚Œã¾ã—ãŸã€‚", "error")
            return redirect(url_for("main.purchase"))

        session = stripe.checkout.Session.create(
            payment_method_types=["card"],
            customer_email=current_user.email,
            line_items=[{
                "price": price_id,
                "quantity": site_count,
            }],
            mode="payment" if plan_type == "affiliate" else "subscription",
            success_url=url_for("main.purchase", _external=True) + "?success=true",
            cancel_url=url_for("main.purchase", _external=True) + "?canceled=true",
            metadata={
                "user_id": current_user.id,
                "plan_type": plan_type,
                "site_count": site_count
            }
        )
        return redirect(session.url, code=303)

    return render_template("purchase.html")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ç‰¹åˆ¥ãƒ—ãƒ©ãƒ³ãƒšãƒ¼ã‚¸ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆè¡¨ç¤ºï¼‰
@bp.route("/<username>/special-purchase", methods=["GET"])
@login_required
def special_purchase(username):
    if current_user.username != username:
        abort(403)

    # ç®¡ç†è€… or ç®¡ç†è€…ãƒ¢ãƒ¼ãƒ‰ãªã‚‰å¸¸ã«è¨±å¯ / ãã‚Œä»¥å¤–ã¯ is_special_access å¿…é ˆ
    is_admin = bool(getattr(current_user, "is_admin", False) or session.get("admin_id"))
    if not is_admin and not getattr(current_user, "is_special_access", False):
        flash("ã“ã®ãƒšãƒ¼ã‚¸ã«ã¯ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ã€‚", "danger")
        return redirect(url_for("main.dashboard", username=username))

    return render_template(
        "special_purchase.html",
        stripe_public_key=os.getenv("STRIPE_PUBLIC_KEY"),
        username=username
    )


import traceback

@admin_bp.route("/admin/sync-stripe-payments", methods=["POST"])
@admin_required_effective
def sync_stripe_payments():

    try:
        response = stripe.PaymentIntent.list(limit=100)
        data = response.data
        print(f"ğŸ” å–å¾—ã—ãŸæ±ºæ¸ˆä»¶æ•°: {len(data)}")

        for pi in data:
            payment_id = pi.id
            amount = pi.amount
            created_at = datetime.datetime.fromtimestamp(pi.created).strftime("%Y-%m-%d %H:%M")
            charge_id = pi.latest_charge

            email = (
                pi.get("receipt_email")
                or pi.get("customer_email")
                or "ä¸æ˜"
            )

            print(f"ğŸ§¾ {created_at} | Â¥{amount} | {payment_id} | email: {email} | ãƒãƒ£ãƒ¼ã‚¸ID: {charge_id}")

        return jsonify({"message": f"{len(data)} ä»¶ã®æ±ºæ¸ˆã‚’å–å¾—ã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"})

    except Exception as e:
        print("âŒ ã‚¨ãƒ©ãƒ¼:", e)
        traceback.print_exc()
        return jsonify({"error": "å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"}), 500



@admin_bp.route("/admin/update-fee", methods=["POST"])
@admin_required_effective
def update_manual_fee():
    try:
        data = request.get_json()
        log_id = data.get("log_id")
        fee = data.get("manual_fee")

        if log_id is None or fee is None:
            return jsonify({"error": "ä¸æ­£ãªãƒªã‚¯ã‚¨ã‚¹ãƒˆ"}), 400

        log = PaymentLog.query.get(log_id)
        if not log:
            return jsonify({"error": "è©²å½“ã™ã‚‹ãƒ­ã‚°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}), 404

        fee_int = int(fee)
        log.manual_fee = fee_int
        log.net_income = log.amount - fee_int  # âœ… ç´”åˆ©ç›Šã‚’æ›´æ–°

        db.session.commit()

        return jsonify({"message": "æ‰‹æ•°æ–™ã‚’ä¿å­˜ã—ã¾ã—ãŸ"})
    except Exception as e:
        print("âŒ æ‰‹æ•°æ–™ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼:", e)
        return jsonify({"error": "ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼"}), 500



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ç®¡ç†è€…ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

from app.models import Article, User, PromptTemplate, Site
from os.path import exists, getsize

@admin_bp.route("/admin")
@admin_required_effective
def admin_dashboard():
    if not current_user.is_admin:
        flash("ã“ã®ãƒšãƒ¼ã‚¸ã«ã¯ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ã€‚", "error")
        return redirect(url_for("main.dashboard", username=current_user.username))

    # âœ… é‡ã„ç”»åƒãƒã‚§ãƒƒã‚¯å‡¦ç†ã‚’å‰Šé™¤ã—ã¦å³ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ
    return redirect(url_for("admin.admin_users"))


@admin_bp.route("/admin/prompts")
@admin_required_effective
def admin_prompt_list():

    users = User.query.order_by(User.last_name, User.first_name).all()
    return render_template("admin/prompts.html", users=users)


@admin_bp.route("/admin/keywords")
@admin_required_effective
def admin_keyword_list():

    # å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼å–å¾—ï¼ˆfirst_name/last_nameé †ã§è¡¨ç¤ºé †ãŒå®‰å®šï¼‰
    users = User.query.order_by(User.last_name, User.first_name).all()
    return render_template("admin/keywords.html", users=users)


@admin_bp.route("/admin/gsc-status")
@admin_required_effective
def admin_gsc_status():

    from app.models import Site, Article, User, GSCConfig
    from sqlalchemy import case

    # å„ã‚µã‚¤ãƒˆã®æŠ•ç¨¿æ•°ãƒ»GSCè¨­å®šã‚’å–å¾—
    results = (
        db.session.query(
            Site.id,
            Site.name,
            Site.url,
            Site.plan_type,
            User.name.label("user_name"),
            func.count(Article.id).label("article_count"),
            func.max(GSCConfig.id).label("gsc_configured")
        )
        .join(User, Site.user_id == User.id)
        .outerjoin(Article, Article.site_id == Site.id)
        .outerjoin(GSCConfig, GSCConfig.site_id == Site.id)
        .group_by(Site.id, User.id)
        .order_by(func.count(Article.id).desc())
        .all()
    )

    return render_template("admin/gsc_status.html", results=results)


# --- ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰å¼·åŒ–ç³»ãƒ«ãƒ¼ãƒˆ ---

# ğŸ“Š çµ±è¨ˆã‚µãƒãƒªï¼ˆæ—¢å­˜ï¼‰
@admin_bp.route('/admin/dashboard')
@admin_required_effective
def admin_summary():
    return render_template("admin/dashboard.html")

# ğŸ”„ å‡¦ç†ä¸­ã‚¸ãƒ§ãƒ–ä¸€è¦§
@admin_bp.route("/admin/job-status")
@admin_required_effective
def job_status():
    processing_articles = Article.query.filter_by(status="gen").order_by(Article.created_at.desc()).all()
    return render_template("admin/job_status.html", articles=processing_articles)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒªãƒ©ã‚¤ãƒˆ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆç®¡ç†ç”¨ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@admin_bp.route("/admin/rewrite", methods=["GET"])
def admin_rewrite_dashboard():
    """
    ç®¡ç†UIï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼è¡Œã”ã¨ã®ä¸€è¦§ï¼‰ã€‚ãƒ‡ãƒ¼ã‚¿ã¯ JSON API ã§å–å¾—ã€‚
    """
    # ä¸€è¦§ã¯ãƒ†ãƒ³ãƒ—ãƒ¬ï¼‹ãƒ•ãƒ­ãƒ³ãƒˆå´ã®AJAXã§æç”»
    return render_template("admin/rewrite.html")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å…¨ä½“ã‚µãƒãƒª APIï¼ˆçµ±ä¸€å®šç¾©ï¼šqueued/running=plans[is_active=TRUE], success/error/unknown=logs[è¨˜äº‹ã”ã¨ã®æœ€æ–°ç‰ˆ]ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from sqlalchemy import text as _sql_text  # â† raw SQL ç”¨
from sqlalchemy import func, case, text
@admin_bp.route("/admin/rewrite/summary", methods=["GET"])
def admin_rewrite_summary():
    from app import redis_client
    # å…¨æœŸé–“ãƒ»çµ±ä¸€å®šç¾©ï¼ˆæœŸé–“ãƒ•ã‚£ãƒ«ã‚¿ãªã—ï¼‰ã€‚å”¯ä¸€ã®çœŸå®Ÿæºã¯ vw_rewrite_state
    cache_key = "admin:rewrite:summary:v7:scope=all"
    cached = redis_client.get(cache_key)
    if cached:
        return jsonify(json.loads(cached))

    try:
        # çµ±ä¸€å®šç¾©ï¼švw_rewrite_state ã‹ã‚‰å…¨æœŸé–“é›†è¨ˆ
        agg_sql = _sql_text("""
            SELECT
              COUNT(*)                                                     AS target_articles,
              SUM((final_bucket='waiting')::int)                           AS queued,
              SUM((final_bucket='running')::int)                           AS running,
              SUM((final_bucket='success')::int)                           AS success,
              SUM((final_bucket='failed')::int)                            AS failed,
              SUM((final_bucket NOT IN ('waiting','running','success','failed')
                   OR final_bucket IS NULL)::int)                          AS unknown,
              MAX(GREATEST(COALESCE(log_executed_at, 'epoch'::timestamptz),
                           COALESCE(plan_created_at,'epoch'::timestamptz))) AS last_activity_at
            FROM vw_rewrite_state
        """)
        row = dict(db.session.execute(agg_sql).mappings().first() or {})
        totals = {
            "target_articles": int(row.get("target_articles", 0) or 0),
            "queued":          int(row.get("queued", 0) or 0),
            "running":         int(row.get("running", 0) or 0),
            "success":         int(row.get("success", 0) or 0),
            # æ—¢å­˜ãƒ•ãƒ­ãƒ³ãƒˆäº’æ›ã®ãŸã‚ã‚­ãƒ¼åã¯ "error" ã‚’ç¶­æŒï¼ˆfailed ã‚’ error ã«è¼‰ã›æ›¿ãˆï¼‰
            "error":           int(row.get("failed", 0) or 0),
        }
        unknown = int(row.get("unknown", 0) or 0)
        last_activity_at = row.get("last_activity_at").isoformat() if row.get("last_activity_at") else None
    except Exception as e:
        current_app.logger.warning("[rewrite_summary] fallback: %s", e)
        totals = {"queued": 0, "running": 0, "success": 0, "error": 0}
        unknown = 0
        last_activity_at = None

    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ•´å½¢ï¼ˆunknown ã‚’è¿½åŠ ã—ã¦ã‚‚æ—¢å­˜UIã«å½±éŸ¿ãªã—ï¼æ¬²ã—ã‘ã‚Œã°åˆ©ç”¨å¯èƒ½ï¼‰
    payload = {
        "totals": totals,
        "unknown": unknown,
        "last_activity_at": last_activity_at,
        "scope": "all",  # å…¨æœŸé–“
        "version": 7
    }
    # TTL ã¯çŸ­ã‚ï¼ˆä¸¦è¡Œå®Ÿè¡Œã®æºã‚Œå¸åï¼‹è² è·è»½æ¸›ï¼‰
    redis_client.set(cache_key, json.dumps(payload, ensure_ascii=False), ex=20)
    return jsonify(payload)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å…±é€šé›†è¨ˆãƒ˜ãƒ«ãƒ‘ï¼šã‚µã‚¤ãƒˆå˜ä½ã®é›†è¨ˆï¼ˆå…¨æœŸé–“ãƒ»çµ±ä¸€å®šç¾©ï¼‰
# queued/running = plans(is_active=TRUE)
# success/error/unknown = logs(è¨˜äº‹ã”ã¨ã®æœ€æ–°ãƒ­ã‚°)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _rewrite_counts_for_site(user_id: int, site_id: int):
    agg_sql = _sql_text("""
        WITH latest_log AS (
          SELECT DISTINCT ON (site_id, article_id)
                 user_id, site_id, article_id, wp_status, executed_at
          FROM public.article_rewrite_logs
          ORDER BY site_id, article_id, executed_at DESC
        )
        SELECT
          COUNT(*) FILTER (WHERE p.is_active AND p.status = 'queued')  AS queued,
          COUNT(*) FILTER (WHERE p.is_active AND p.status = 'running') AS running,
          COUNT(*) FILTER (WHERE ll.wp_status = 'success')             AS success,
          COUNT(*) FILTER (WHERE ll.wp_status = 'error')               AS error,
          COUNT(*) FILTER (WHERE ll.wp_status = 'unknown')             AS unknown
        FROM public.article_rewrite_plans p
        LEFT JOIN latest_log ll
          ON ll.user_id    = p.user_id
         AND ll.site_id    = p.site_id
         AND ll.article_id = p.article_id
        WHERE p.user_id = :uid
          AND p.site_id = :sid
    """)
    row = db.session.execute(agg_sql, {"uid": user_id, "sid": site_id}).mappings().first() or {}
    return {
        "queued":  int(row.get("queued", 0) or 0),
        "running": int(row.get("running", 0) or 0),
        "success": int(row.get("success", 0) or 0),
        "error":   int(row.get("error", 0) or 0),
        "unknown": int(row.get("unknown", 0) or 0),
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å…±é€šé›†è¨ˆãƒ˜ãƒ«ãƒ‘ï¼šãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥ã®ã‚µã‚¤ãƒˆé›†è¨ˆï¼ˆå…¨æœŸé–“ãƒ»çµ±ä¸€å®šç¾©ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _rewrite_counts_for_user_sites(user_id: int):
    # çµ±ä¸€å®šç¾©ï¼švw_rewrite_state ã‚’å”¯ä¸€ã®çœŸå®Ÿæºã«ã™ã‚‹
    from sqlalchemy import text as _sql  # â† æ—¢ã«ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä¸Šéƒ¨ã§å®šç¾©æ¸ˆã¿ãªã‚‰ä¸è¦
    agg_sql = _sql("""
       SELECT
         v.site_id,
         COALESCE(s.name, '') AS site_name,
         COUNT(*)                                                  AS target_articles,
         SUM((v.final_bucket = 'waiting')::int)                    AS waiting,
         SUM((v.final_bucket = 'running')::int)                    AS running,
         SUM((v.final_bucket = 'success')::int)                    AS success,
         SUM((v.final_bucket = 'failed')::int)                     AS failed,
         MAX(GREATEST(COALESCE(v.log_executed_at, 'epoch'::timestamp),
                      COALESCE(v.plan_created_at, 'epoch'::timestamp))) AS last_update
       FROM vw_rewrite_state v
       LEFT JOIN public.site s
         ON s.id = v.site_id
       WHERE v.user_id = :uid
       GROUP BY v.site_id, s.name
       ORDER BY v.site_id
     """)
    rows = db.session.execute(agg_sql, {"uid": user_id}).mappings().all()
    return [dict(r) for r in rows]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# è¿½åŠ : ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥ã‚µã‚¤ãƒˆä¸€è¦§ï¼ˆHTMLï¼‰
# URL: /admin/rewrite/user/<user_id>
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@admin_bp.route("/admin/rewrite/user/<int:user_id>", methods=["GET"])
def admin_rewrite_user_sites(user_id: int):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’ãƒ†ãƒ³ãƒ—ãƒ¬ã«æ¸¡ã™
    from app.models import User
    user = db.session.get(User, user_id)
    if not user:
        abort(404)
    # å…¨æœŸé–“ãƒ»çµ±ä¸€å®šç¾©ã§ã®é›†è¨ˆï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬è¦ä»¶ã«åˆã‚ã›ã¦ rows ã‚’æ¸¡ã™ï¼‰
    rows = _rewrite_counts_for_user_sites(user_id)
    return render_template(
        "admin/rewrite_user.html",
        user=user,
        rows=rows,
        back_url=url_for("admin.admin_rewrite_dashboard"),
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# è¿½åŠ : ã‚µã‚¤ãƒˆåˆ¥ã®ãƒªãƒ©ã‚¤ãƒˆè¨˜äº‹ä¸€è¦§ï¼ˆHTMLï¼‰
# URL: /admin/rewrite/user/<user_id>/site/<site_id>
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@admin_bp.route("/admin/rewrite/user/<int:user_id>/site/<int:site_id>", methods=["GET"])
@login_required
def admin_rewrite_site_articles(user_id: int, site_id: int):
    if not current_user.is_admin:
        abort(403)
    """
    æŒ‡å®šãƒ¦ãƒ¼ã‚¶ãƒ¼Ã—ã‚µã‚¤ãƒˆã® â€œæœ€æ–°çŠ¶æ…‹â€ ã‚’ä¸€è¦§è¡¨ç¤ºï¼ˆçµ±ä¸€ãƒ“ãƒ¥ãƒ¼åŸºæº–ï¼‰ã€‚
    ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹çµã‚Šè¾¼ã¿ãƒ»ç°¡æ˜“ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ã«å¯¾å¿œã€‚
    """
    from sqlalchemy import text as _sql
    from app.models import User, Site, Article

    user = db.session.get(User, user_id)
    site = db.session.get(Site, site_id)
    if not user or not site or site.user_id != user_id:
        abort(404)

    # å…¨æœŸé–“ãƒ»çµ±ä¸€å®šç¾©ã§ã®ãƒ˜ãƒƒãƒ€4æŒ‡æ¨™ï¼‹unknown
    header_counts = _rewrite_counts_for_site(user_id, site_id)
    scope = "all"  # å…¨æœŸé–“

    # ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    status = (request.args.get("status") or "").strip().lower()
    page   = max(1, request.args.get("page", type=int) or 1)
    per    = min(100, max(10, request.args.get("per", type=int) or 50))

    # è¨±å®¹ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ï¼ˆã¾ãšã¯ success / failed ã®2ç³»çµ±ã«å¯¾å¿œï¼‰
    allowed = {"success", "failed"}
    if status not in allowed:
        status = "success"

    # â”€â”€ çµ±ä¸€ãƒ“ãƒ¥ãƒ¼ã‹ã‚‰ã‚µã‚¤ãƒˆã®ã‚µãƒãƒªï¼ˆwaiting/running/success/failed/otherï¼‰
    from app.services.rewrite.state_view import fetch_site_totals
    totals = fetch_site_totals(user_id=user_id, site_id=site_id)
    stats = {
        "queued":  int(totals.get("waiting", 0)),
        "running": int(totals.get("running", 0)),
        "success": int(totals.get("success", 0)),
        "error":   int(totals.get("failed", 0)),
        "unknown": int(totals.get("other", 0)),
    }
    # äº’æ›ï¼šãƒ†ãƒ³ãƒ—ãƒ¬ãŒæœŸå¾…ã™ã‚‹ display_error ã‚’å¸¸ã«æ•°å€¤ã§æ¸¡ã™
    stats["display_error"] = stats.get("error", 0)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ä¸€è¦§ç”¨IDã‚’ final_bucket ã§æŠ½å‡ºï¼ˆæ–°ã—ã„é †ï¼‰
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    bucket = "success" if status == "success" else "failed"
    ids_sql = _sql("""
      SELECT article_id
      FROM vw_rewrite_state
      WHERE user_id = :uid AND site_id = :sid AND final_bucket = :bucket
      ORDER BY log_executed_at DESC NULLS LAST, plan_created_at DESC NULLS LAST, article_id DESC
      LIMIT :limit OFFSET :offset
    """)
    id_rows = db.session.execute(
        ids_sql,
        {"uid": user_id, "sid": site_id, "bucket": bucket, "limit": per, "offset": (page-1)*per}
    ).fetchall()
    article_ids = [int(r[0]) for r in id_rows]

    # ç·ä»¶æ•°ï¼ˆãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ç”¨ï¼‰
    total_sql = _sql("""
      SELECT COUNT(*) FROM vw_rewrite_state
       WHERE user_id = :uid AND site_id = :sid AND final_bucket = :bucket
    """)
    total_count = int(db.session.execute(
        total_sql, {"uid": user_id, "sid": site_id, "bucket": bucket}
    ).scalar() or 0)

    # è¡¨ç¤ºç”¨ã®è©³ç´°ï¼ˆæœ€æ–° success / å¤±æ•—ç³»ãƒ­ã‚°ï¼‰ã‚’å–å¾—
    rows = []
    if article_ids:
        if status == "success":
            # æœ€æ–° success ãƒ­ã‚°
            detail_sql = _sql("""
              WITH latest AS (
                SELECT
                  l.id         AS log_id,
                  l.article_id,
                  l.plan_id,
                  l.wp_post_id,
                  l.executed_at,
                  ROW_NUMBER() OVER (PARTITION BY l.article_id ORDER BY l.executed_at DESC, l.id DESC) AS rn
                FROM article_rewrite_logs l
                WHERE l.article_id = ANY(:ids) AND l.wp_status = 'success'
              )
              SELECT
                lt.log_id,
                a.id          AS article_id,
                a.title       AS title,
                lt.plan_id    AS plan_id,
                lt.wp_post_id AS wp_post_id,
                lt.executed_at AS executed_at
              FROM latest lt
              JOIN articles a ON a.id = lt.article_id
              WHERE lt.rn = 1
              ORDER BY lt.executed_at DESC NULLS LAST, a.id DESC
            """)
            rows = list(db.session.execute(detail_sql, {"ids": article_ids}).mappings())
        else:
            # æœ€æ–° failed ç³»ãƒ­ã‚°
            detail_sql = _sql("""
              WITH latest AS (
                SELECT
                  l.id         AS log_id,
                  l.article_id,
                  l.plan_id,
                  l.wp_post_id,
                  l.executed_at,
                  l.wp_status,
                  ROW_NUMBER() OVER (PARTITION BY l.article_id ORDER BY l.executed_at DESC, l.id DESC) AS rn
                FROM article_rewrite_logs l
                WHERE l.article_id = ANY(:ids)
                  AND l.wp_status IN ('failed','error','canceled','aborted','timeout','stale')
              )
              SELECT
                lt.log_id,
                a.id          AS article_id,
                a.title       AS title,
                lt.plan_id    AS plan_id,
                lt.wp_post_id AS wp_post_id,
                lt.executed_at AS executed_at,
                lt.wp_status  AS wp_status
              FROM latest lt
              JOIN articles a ON a.id = lt.article_id
              WHERE lt.rn = 1
              ORDER BY lt.executed_at DESC NULLS LAST, a.id DESC
            """)
            rows = list(db.session.execute(detail_sql, {"ids": article_ids}).mappings())

    # ãƒ†ãƒ³ãƒ—ãƒ¬äº’æ›ï¼šarticles é…åˆ—ã‚’ç”¨æ„ï¼ˆid/title/status/updated_at/wp_url/posted_urlâ€¦ï¼‰
    articles = []
    _last_dt = None
    for r in rows:
        dt = r.get("executed_at")
        if dt and (_last_dt is None or dt > _last_dt):
            _last_dt = dt

        # æˆåŠŸæ™‚ã®ã¿WPãƒªãƒ³ã‚¯ç”Ÿæˆã€‚å¤±æ•—ã¯ãƒªãƒ³ã‚¯ç„¡ã—ã€‚
        if status == "success" and r.get("wp_post_id"):
            base = (getattr(site, "site_url", None) or getattr(site, "url", "") or "").rstrip("/")
            wp_url = f"{base}/?p={r.get('wp_post_id')}" if base else None
        else:
            wp_url = None

        articles.append({
            "id": r.get("article_id"),              # ä¸€è¦§ã®IDåˆ—ã¯è¨˜äº‹IDã‚’è¡¨ç¤º
            "article_id": r.get("article_id"),
            "title": r.get("title"),
            "status": status,                       # â† å›ºå®š 'success' ã‹ã‚‰å®Ÿå€¤ã¸
            "attempts": None,
            "updated_at": (dt.isoformat() if dt else None),
            "posted_url": None,
            "wp_url": wp_url,
            "plan_id": r.get("plan_id"),
            "log_id": r.get("log_id"),
        })
    last_updated = _last_dt.isoformat() if _last_dt else None

    # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’æ§‹ç¯‰
    total_pages = (total_count + per - 1) // per if per > 0 else 1
    first_idx = ((page - 1) * per + 1) if total_count > 0 else 0
    last_idx  = min(page * per, total_count)
    prev_url = (url_for("admin.admin_rewrite_site_articles",
                        user_id=user_id, site_id=site_id,
                        status=status, page=page-1, per=per)
                if page > 1 else None)
    next_url = (url_for("admin.admin_rewrite_site_articles",
                        user_id=user_id, site_id=site_id,
                        status=status, page=page+1, per=per)
                if page * per < total_count else None)
    pagination = {
        "total": total_count,
        "page": page,
        "per": per,
        "pages": total_pages,
        "first": first_idx,
        "last": last_idx,
        "prev_url": prev_url,
        "next_url": next_url,
    }

    return render_template(
        "admin/rewrite_site_articles.html",
        user_id=user_id,
        site_id=site_id,
        site=site,
        articles=articles,
        header_counts=header_counts,
        scope=scope,
        stats=stats,
        last_updated=last_updated,
        status=status,      # â† ç¾åœ¨ã®è¡¨ç¤ºã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ãƒ†ãƒ³ãƒ—ãƒ¬ã¸
        pagination=pagination,  # â† è¿½åŠ 
        per=per,            # â† æ˜ç¤ºçš„ã«æ¸¡ã—ã¦ãŠãï¼ˆãƒªãƒ³ã‚¯å¼•ç¶™ãç”¨ï¼‰
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒªãƒ©ã‚¤ãƒˆè©³ç´°ï¼ˆä¿®æ­£æ–¹é‡ / ãƒ­ã‚°è©³ç´°ï¼‰
# URL: /admin/rewrite/log/<log_id>
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@admin_bp.route("/admin/rewrite/log/<int:log_id>", methods=["GET"])
@login_required
def admin_rewrite_log_detail(log_id: int):
    if not current_user.is_admin:
        abort(403)

    from app.models import ArticleRewriteLog, Article

    log = db.session.get(ArticleRewriteLog, log_id)
    if not log:
        abort(404)

    article = None
    if log.article_id:
        article = db.session.get(Article, log.article_id)

    # é–¢é€£ã¨ãƒ‘ãƒ³ããšç”¨ã®æ´¾ç”Ÿå€¤ã‚’æ˜ç¤ºçš„ã«æ¸¡ã™
    plan = getattr(log, "plan", None)
    user_id = getattr(article, "user_id", None) if article else None
    site_id = getattr(article, "site_id", None) if article else None

    return render_template(
        "admin/rewrite_log_detail.html",
        log=log,
        article=article,
        plan=plan,
        user_id=user_id,
        site_id=site_id,
    )

@admin_bp.route("/admin/rewrite/users", methods=["GET"])
def admin_rewrite_users():
    """
    JSON: ç®¡ç†UIç”¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§ï¼ˆã‚µã‚¤ãƒˆæ•° + ãƒªãƒ©ã‚¤ãƒˆé›†è¨ˆï¼‰
    å®šç¾©ï¼švw_rewrite_state ã‚’å”¯ä¸€ã®çœŸå®Ÿæºã¨ã™ã‚‹ã€‚
    """
    from sqlalchemy import text as _sql
    from app import redis_client
    from app.models import User, Site
    import json

    q = (request.args.get("q", type=str) or "").strip()
    nocache = request.args.get("nocache", type=int) == 1
    cache_key = f"admin:rewrite:users:v8:q={q}"
    if not nocache:
        cached = redis_client.get(cache_key)
        if cached:
            return jsonify({"ok": True, "items": json.loads(cached)})

    # --- è¡¨ç¤ºåç”Ÿæˆ ---
    full_name_expr = func.trim(
        func.concat(
            func.coalesce(func.nullif(User.last_name, ""), ""),
            " ",
            func.coalesce(func.nullif(User.first_name, ""), ""),
        )
    )
    name_expr = func.coalesce(func.nullif(full_name_expr, ""), User.username, User.email)

    # --- æ¤œç´¢ãƒ•ã‚£ãƒ«ã‚¿ ---
    filters = []
    if q:
        like = f"%{q}%"
        filters.append(name_expr.ilike(like) | User.username.ilike(like) | User.email.ilike(like))

    # --- vw_rewrite_state ã«ã‚ˆã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼å˜ä½é›†è¨ˆ ---
    agg_sql = _sql("""
        SELECT
          v.user_id AS uid,
          COUNT(*) AS target_articles,
          SUM((v.final_bucket='waiting')::int) AS queued,
          SUM((v.final_bucket='running')::int) AS running,
          SUM((v.final_bucket='success')::int) AS success,
          SUM((v.final_bucket='failed')::int)  AS error,
          MAX(GREATEST(
              COALESCE(v.log_executed_at, 'epoch'::timestamp),
              COALESCE(v.plan_created_at, 'epoch'::timestamp)
          )) AS last_activity_at
        FROM vw_rewrite_state v
        GROUP BY v.user_id
        ORDER BY v.user_id
    """)
    agg_rows = db.session.execute(agg_sql).mappings().all()
    agg_map = {r["uid"]: r for r in agg_rows}

    # --- ã‚µã‚¤ãƒˆæ•° ---
    site_sq = (
        db.session.query(Site.user_id.label("uid"), func.count(Site.id).label("site_count"))
        .group_by(Site.user_id)
        .subquery()
    )

    # --- ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’çµåˆ ---
    rows = (
        db.session.query(
            User.id.label("user_id"),
            name_expr.label("name"),
            func.coalesce(site_sq.c.site_count, 0).label("site_count"),
        )
        .outerjoin(site_sq, site_sq.c.uid == User.id)
        .filter(*filters)
        .order_by(User.id.asc())
        .all()
    )

    # --- çµæœæ•´å½¢ ---
    items = []
    for r in rows:
        uid = r.user_id
        a = agg_map.get(uid, {})
        items.append({
            "user_id": uid,
            "name": r.name,
            "site_count": int(r.site_count or 0),
            "queued": int(a.get("queued", 0) or 0),
            "running": int(a.get("running", 0) or 0),
            "success": int(a.get("success", 0) or 0),
            "error": int(a.get("error", 0) or 0),
            "last_activity_at": (
                a.get("last_activity_at").isoformat() if a.get("last_activity_at") else None
            ),
            "target_articles": int(a.get("target_articles", 0) or 0),
        })

    # --- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ ---
    if not nocache:
        try:
            redis_client.setex(cache_key, 5, json.dumps(items, ensure_ascii=False))
        except Exception:
            pass

    return jsonify({"ok": True, "items": items})


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# è¿½åŠ : å†…éƒ¨SEOé¢¨ã®ä¸€è¦§APIï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬äº’æ›ã®ã‚­ãƒ¼åã§è¿”å´ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@admin_bp.route("/admin/rewrite/users_progress", methods=["GET"])
def admin_rewrite_users_progress():
    """
    JSON: å„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚µã‚¤ãƒˆæ•°ã¨ãƒªãƒ©ã‚¤ãƒˆé€²æ—ï¼ˆqueued/running/success/error/last_activity_atï¼‰
    è¿”å´ã‚­ãƒ¼ã¯ { ok, users: [...] } ã§ãƒ†ãƒ³ãƒ—ãƒ¬ã¨ä¸€è‡´ã€‚
    å®Ÿä½“ã¯ /admin/rewrite/users ã¨åŒã˜é›†è¨ˆï¼ˆ5ç§’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰ã€‚
    """
    from sqlalchemy import case
    from app import redis_client
    # â˜… NameErrorå¯¾ç­–
    from app.models import User, Site, ArticleRewritePlan

    q = (request.args.get("q", type=str) or "").strip()
    nocache = request.args.get("nocache", type=int) == 1
    cache_key = f"admin:rewrite:users_progress:v3:q={q}"
    if not nocache:
        cached = redis_client.get(cache_key)
        if cached:
            return jsonify({"ok": True, "users": json.loads(cached)})

    # è¡¨ç¤ºå: (last_name + ' ' + first_name) -> username -> email
    full_name_expr = func.trim(
        func.concat(
            func.coalesce(func.nullif(User.last_name, ""), ""),
            " ",
            func.coalesce(func.nullif(User.first_name, ""), ""),
        )
    )
    name_expr = func.coalesce(func.nullif(full_name_expr, ""), User.username, User.email)

    site_sq = (
        db.session.query(Site.user_id.label("uid"), func.count(Site.id).label("site_count"))
        .group_by(Site.user_id)
        .subquery()
    )
    queued_cnt  = func.sum(case((ArticleRewritePlan.status == "queued", 1), else_=0))
    running_cnt = func.sum(case((ArticleRewritePlan.status.in_(["running","in_progress"]), 1), else_=0))
    last_act    = func.max(func.coalesce(ArticleRewritePlan.finished_at, ArticleRewritePlan.created_at))
    plan_sq = (
        db.session.query(
            ArticleRewritePlan.user_id.label("uid"),
            queued_cnt.label("queued"),
            running_cnt.label("running"),
            last_act.label("last_activity_at"),
        )
        .group_by(ArticleRewritePlan.user_id)
        .subquery()
    )

    # logs å´ï¼šãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥ success/error
    from sqlalchemy import text as _sql
    logs_user_sql = _sql("""
      WITH latest AS (
        SELECT
          l.article_id,
          l.wp_status,
          a.user_id,
          ROW_NUMBER() OVER (PARTITION BY l.article_id ORDER BY l.executed_at DESC) AS rn
        FROM article_rewrite_logs l
        JOIN articles a ON a.id = l.article_id
      )
      SELECT
        user_id AS uid,
        SUM(CASE WHEN wp_status = 'success' THEN 1 ELSE 0 END)               AS success,
        SUM(CASE WHEN wp_status IN ('error','failed') THEN 1 ELSE 0 END)     AS error
      FROM latest
      WHERE rn = 1
      GROUP BY user_id
    """)
    logs_user_sq = db.session.execute(logs_user_sql).mappings().all()
    logs_user_map = { r["uid"]: {"success": int(r["success"] or 0), "error": int(r["error"] or 0)} for r in logs_user_sq }

    filters = []
    if q:
        like = f"%{q}%"
        filters.append(
            name_expr.ilike(like) | User.username.ilike(like) | User.email.ilike(like)
        )

    try:
        rows = (
            db.session.query(
                User.id.label("user_id"),
                name_expr.label("name"),
                func.coalesce(site_sq.c.site_count, 0).label("site_count"),
                func.coalesce(plan_sq.c.queued, 0).label("queued"),
                func.coalesce(plan_sq.c.running, 0).label("running"),
                plan_sq.c.last_activity_at.label("last_activity_at"),
            )
            .outerjoin(site_sq, site_sq.c.uid == User.id)
            .outerjoin(plan_sq, plan_sq.c.uid == User.id)
            .filter(*filters)
            .order_by(
                func.coalesce(plan_sq.c.queued, 0).desc(),
                func.coalesce(plan_sq.c.running, 0).desc(),
                plan_sq.c.last_activity_at.desc().nullslast(),
                User.id.asc(),
            )
            .all()
        )
    except Exception as e:
        current_app.logger.exception("[admin/rewrite/users_progress] query failed: %s", e)
        return jsonify({"ok": False, "users": [], "error": str(e)}), 500

    users = [{
        "user_id": r.user_id,
        "name": r.name,
        "site_count": int(r.site_count or 0),
        "queued": int(r.queued or 0),
        "running": int(r.running or 0),
        "success": int(logs_user_map.get(r.user_id, {}).get("success", 0)),
        "error":   int(logs_user_map.get(r.user_id, {}).get("error", 0)),
        "last_activity_at": (r.last_activity_at.isoformat() if r.last_activity_at else None),
    } for r in rows]

    if not nocache:
        try:
            redis_client.setex(cache_key, 2, json.dumps(users, ensure_ascii=False))
        except Exception:
            pass
    return jsonify({"ok": True, "users": users})


@admin_bp.route("/admin/rewrite/enqueue", methods=["POST"])
def admin_rewrite_enqueue():
    """
    JSON: å…¨è¨˜äº‹ãƒªãƒ©ã‚¤ãƒˆã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼å˜ä½ã§ queued ã«æŠ•å…¥ã€‚
    body: { user_id, site_ids?: [..], article_ids?: [..], priority?: number }
    """
    try:
        payload = request.get_json(force=True, silent=True) or {}
        user_id = int(payload.get("user_id"))
        # "1,2,3" / [1,2] / "  " ã©ã‚Œã§ã‚‚å—ã‘ã‚‹
        def _to_int_list(v):
            if v is None or v == "":
                return None
            if isinstance(v, list):
                return [int(x) for x in v if str(x).strip().isdigit()]
            return [int(x) for x in str(v).replace("\n", ",").split(",") if x.strip().isdigit()]
        site_ids = _to_int_list(payload.get("site_ids"))
        article_ids = _to_int_list(payload.get("article_ids"))
        priority = float(payload.get("priority", 0.0))
        res = rewrite_enqueue_for_user(user_id, site_ids=site_ids, article_ids=article_ids, priority=priority)
        return jsonify({"ok": True, "result": res})
    except Exception as e:
        current_app.logger.exception("[admin/rewrite/enqueue] failed: %s", e)
        return jsonify({"ok": False, "error": str(e)}), 400


@admin_bp.route("/admin/rewrite/progress", methods=["GET"])
def admin_rewrite_progress():
    """
    JSON: é€²æ—ã‚µãƒãƒªã‚’è¿”ã™ã€‚
    query: user_id (optional)
    è¿”å´: { totals: {queued,running,success,error}, recent: [...], last_updated }
    """

    # ã“ã“ã§ç¢ºå®Ÿã«ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€ï¼ˆNameErrorå¯¾ç­–ï¼‰
    try:
        from app.models import ArticleRewritePlan, Article
    except Exception:
        ArticleRewritePlan = None
        Article = None

    uid = request.args.get("user_id", type=int)

    # ---- queued / running ã¯ plansï¼ˆis_active=TRUEï¼‰ã‹ã‚‰ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é›†è¨ˆ
    base_plans_q = db.session.query(ArticleRewritePlan).filter(ArticleRewritePlan.is_active.is_(True))
    if uid:
        base_plans_q = base_plans_q.filter(ArticleRewritePlan.user_id == uid)

    plan_agg = (
        db.session.query(
            func.sum(case((ArticleRewritePlan.status == "queued", 1), else_=0)).label("queued"),
            func.sum(case((ArticleRewritePlan.status.in_(["running","in_progress"]), 1), else_=0)).label("running"),
        )
        .filter(ArticleRewritePlan.is_active.is_(True))
        .filter(*( [ArticleRewritePlan.user_id == uid] if uid else [] ))
        .one()
    )

    # ---- success / error ã¯â€œæœ€æ–°ãƒ­ã‚°ã®ã¿â€ã§ã‚«ã‚¦ãƒ³ãƒˆï¼ˆuid ãŒã‚ã‚Œã°ãƒ¦ãƒ¼ã‚¶ãƒ¼ã® article ã«é™å®šï¼‰
    where_by_user = "JOIN articles a ON a.id = l.article_id" + (" AND a.user_id = :uid" if uid else "")
    logs_sql = _sql_text(f"""
      WITH latest AS (
        SELECT
          l.article_id,
          l.wp_status,
          l.executed_at,
          ROW_NUMBER() OVER (PARTITION BY l.article_id ORDER BY l.executed_at DESC) AS rn
        FROM article_rewrite_logs l
        {where_by_user}
      )
      SELECT
        SUM(CASE WHEN wp_status = 'success' THEN 1 ELSE 0 END)                   AS success,
        SUM(CASE WHEN wp_status IN ('error','failed') THEN 1 ELSE 0 END)         AS error,
        MAX(executed_at)                                                          AS last_log_ts
      FROM latest
      WHERE rn = 1
    """)
    logs_row = db.session.execute(logs_sql, {"uid": uid} if uid else {}).mappings().first() or {}

    totals = {
        "queued":  int(getattr(plan_agg, "queued", 0) or 0),
        "running": int(getattr(plan_agg, "running", 0) or 0),
        "success": int(logs_row.get("success", 0) or 0),
        "error":   int(logs_row.get("error", 0) or 0),
    }

    # --- ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥ã®å®Ÿè¡Œãƒ•ãƒ©ã‚°ï¼ˆä¸€è¦§ãƒœã‚¿ãƒ³ã®æ–‡è¨€åˆ‡æ›¿ææ–™ï¼‰
    users_snapshot = None
    user_snapshot  = None
    if uid:
        user_snapshot = {
            "user_id": uid,
            "queued":  totals["queued"],
            "running": totals["running"],
            "is_running": (totals["queued"] + totals["running"]) > 0,
        }
    else:
        # ä¸€è¦§ç”¨ï¼šis_active=TRUE ã‹ã¤ queued/running ã®ä»¶æ•°ã‚’ user_id ã”ã¨ã«é›†è¨ˆ
        rows = (
            db.session.query(
                ArticleRewritePlan.user_id.label("user_id"),
                func.sum(case((ArticleRewritePlan.status == "queued", 1), else_=0)).label("queued"),
                func.sum(case((ArticleRewritePlan.status.in_(["running","in_progress"]), 1), else_=0)).label("running"),
            )
            .filter(ArticleRewritePlan.is_active.is_(True))
            .group_by(ArticleRewritePlan.user_id)
            .all()
        )
        users_snapshot = [
            {
                "user_id": r.user_id,
                "queued":  int(r.queued or 0),
                "running": int(r.running or 0),
                "is_running": (int(r.queued or 0) + int(r.running or 0)) > 0,
            }
            for r in rows
        ]

    # æœ€è¿‘30ä»¶ã¯å¾“æ¥ã©ãŠã‚Š plans ã‚’è¡¨ç¤ºï¼ˆUIã®ãƒ†ãƒ¼ãƒ–ãƒ«äº’æ›ï¼‰
    try:
        recent_plans = (
            base_plans_q.order_by(
                func.coalesce(
                    ArticleRewritePlan.finished_at,
                    ArticleRewritePlan.started_at,
                    ArticleRewritePlan.scheduled_at,
                    ArticleRewritePlan.created_at
                ).desc(),
                ArticleRewritePlan.id.desc()
            ).limit(30).all()
        )
        # posted_url ã‚’ç´ä»˜ã‘
        a_ids = [p.article_id for p in recent_plans if getattr(p, "article_id", None)]
        art_map = {}
        if a_ids:
            arts = (db.session.query(Article.id, Article.posted_url)
                            .filter(Article.id.in_(a_ids)).all())
            art_map = {aid: url for (aid, url) in arts}
        recent = []
        for r in recent_plans:
            best_ts = r.finished_at or r.started_at or r.scheduled_at or r.created_at
            recent.append({
                "id": r.id,
                "article_id": r.article_id,
                "status": r.status,
                "attempts": getattr(r, "attempts", None),
                "updated_at": (best_ts.isoformat() if best_ts else None),
                "posted_url": art_map.get(r.article_id),
            })
    except Exception:
        # Fallback: ãƒ†ãƒ¼ãƒ–ãƒ«åã§ç´ ç›´ã«å©ã
        where = "WHERE user_id=:uid" if uid else ""
        agg_rows = db.session.execute(
            _sql_text(f"SELECT status, COUNT(*) FROM article_rewrite_plans {where} GROUP BY status"),
            {"uid": uid} if uid else {},
        ).fetchall()
        totals = {r[0] or "": int(r[1] or 0) for r in agg_rows}
        totals["success"] = int(totals.get("success", 0)) + int(totals.get("done", 0))
        recent_rows = db.session.execute(
            _sql_text(f"""
              SELECT
                  id,
                  article_id,
                  status,
                  attempts,
                  COALESCE(finished_at, started_at, scheduled_at, created_at) AS updated_at
              FROM article_rewrite_plans
              {where}
              ORDER BY updated_at DESC NULLS LAST, id DESC
              LIMIT 30
            """),
            {"uid": uid} if uid else {},
        ).fetchall()
        a_ids = [row[1] for row in recent_rows if row[1]]
        art_map = {}
        if a_ids:
            arts = (db.session.query(Article.id, Article.posted_url)
                            .filter(Article.id.in_(a_ids)).all())
            art_map = {aid: url for (aid, url) in arts}
        recent = []
        for r in recent_rows:
            best_ts = r[4]
            recent.append({
                "id": r[0],
                "article_id": r[1],
                "status": r[2],
                "attempts": r[3],
                "updated_at": (best_ts.isoformat() if best_ts else None),
                "posted_url": art_map.get(r[1]),
            })
    return jsonify({
        "ok": True,
        "totals": {
            "queued": int(totals.get("queued", 0)),
            "running": int(totals.get("running", 0)),
            "success": int(totals.get("success", 0)),
            "error": int(totals.get("error", 0)),
        },
        # è¿½åŠ ï¼šä¸€è¦§ã§ä½¿ã†ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆï¼ˆuidæŒ‡å®šæ™‚ã¯ user_snapshotã€æœªæŒ‡å®šæ™‚ã¯ users_snapshotï¼‰
        "user": user_snapshot,
        "users": users_snapshot,
        "recent": recent,
        "last_updated": datetime.utcnow().isoformat() + "Z",
    })


@admin_bp.route("/admin/rewrite/plans", methods=["GET"])
def admin_rewrite_plans():
    """
    JSON: è¨ˆç”»ä¸€è¦§ã‚’ãƒšãƒ¼ã‚¸ãƒ³ã‚°è¿”å´ã€‚
    query: user_id?<int>, status?<str>, page?<int>=1, per_page?<int>=50
    """
    uid = request.args.get("user_id", type=int)
    status = request.args.get("status", type=str)
    page = max(1, request.args.get("page", default=1, type=int))
    per_page = min(200, max(1, request.args.get("per_page", default=50, type=int)))

    where = []
    params = {}
    if uid:
        where.append("user_id=:uid")
        params["uid"] = uid
    if status:
        where.append("status=:st")
        params["st"] = status
    wsql = ("WHERE " + " AND ".join(where)) if where else ""

    rows = db.session.execute(
        _sql_text(f"""
          SELECT id, user_id, article_id, status, attempts, created_at, updated_at
            FROM article_rewrite_plans
           {wsql}
        ORDER BY updated_at DESC NULLS LAST, id DESC
           LIMIT :lim OFFSET :off
        """),
        {**params, "lim": per_page, "off": (page-1)*per_page},
    ).fetchall()
    data = [
        {
            "id": r[0], "user_id": r[1], "article_id": r[2], "status": r[3],
            "attempts": r[4],
            "created_at": (r[5].isoformat() if r[5] else None),
            "updated_at": (r[6].isoformat() if r[6] else None),
        }
        for r in rows
    ]
    return jsonify({"ok": True, "items": data, "page": page, "per_page": per_page})

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ç®¡ç†API: retry_failed / serp_warmup
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@admin_bp.route("/admin/rewrite/retry_failed", methods=["POST"])
def admin_rewrite_retry_failed():
    """
    å¤±æ•—ãƒ—ãƒ©ãƒ³ã®å†ã‚­ãƒ¥ãƒ¼ã‚’å³æ™‚ãƒˆãƒªã‚¬ã€‚ãƒãƒ³ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ã§å®Ÿè¡Œã€‚
    body: { user_id?:int, max_attempts?:int, min_age_minutes?:int, limit?:int }
    """
    payload = request.get_json(silent=True) or {}
    user_id      = payload.get("user_id")  # å—ã‘å–ã‚Šã®ã¿ï¼ˆã‚¸ãƒ§ãƒ–ãŒå¯¾å¿œã—ã¦ã„ã‚Œã°åˆ©ç”¨ï¼‰
    max_attempts = int(payload.get("max_attempts", 3))
    min_age_min  = int(payload.get("min_age_minutes", 30))
    limit        = int(payload.get("limit", 100))
    app_obj = current_app._get_current_object()
    def _run():
        try:
            # å†…éƒ¨ã¯ãƒ­ã‚°ã«çµæœã‚’å‡ºã™ï¼ˆuser_idå¯¾å¿œã®å®Ÿè£…ãŒã‚ã‚Œã°æ¸¡ã™ï¼‰
            try:
                _rewrite_retry_job(app_obj, user_id=user_id, max_attempts=max_attempts, min_age_minutes=min_age_min, limit=limit)
            except TypeError:
                # æ—§ã‚·ã‚°ãƒãƒãƒ£äº’æ›
                _rewrite_retry_job(app_obj)
        except Exception as e:
            current_app.logger.exception("[admin/rewrite/retry_failed] job error: %s", e)
    _ui_executor.submit(_run)
    return jsonify({"ok": True, "queued": True, "params": {
        "user_id": user_id, "max_attempts": max_attempts, "min_age_minutes": min_age_min, "limit": limit
    }})

@admin_bp.route("/admin/rewrite/serp_warmup", methods=["POST"])
def admin_rewrite_serp_warmup():
    """
    SERP æ¸©ã‚ã‚’å³æ™‚ãƒˆãƒªã‚¬ï¼ˆå¤œé–“ã‚¸ãƒ§ãƒ–ã®æ‰‹å‹•ç™ºç«ç›¸å½“ï¼‰ã€‚ãƒãƒ³ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ã€‚
    body: { user_id?:int, days?:int, limit?:int }
    """
    payload = request.get_json(silent=True) or {}
    user_id = payload.get("user_id")
    days  = int(payload.get("days", 45))
    limit = int(payload.get("limit", 30))
    app_obj = current_app._get_current_object()
    def _run():
        try:
            # å¤œé–“ã‚¸ãƒ§ãƒ–æœ¬ä½“ã‚’æµç”¨ï¼ˆuser_idå¯¾å¿œã®å®Ÿè£…ãŒã‚ã‚Œã°æ¸¡ã™ï¼‰
            try:
                _serp_warmup_nightly_job(app_obj, user_id=user_id, days=days, limit=limit)
            except TypeError:
                _serp_warmup_nightly_job(app_obj)
        except Exception as e:
            current_app.logger.exception("[admin/rewrite/serp_warmup] job error: %s", e)
    _ui_executor.submit(_run)
    return jsonify({"ok": True, "queued": True, "params": {"user_id": user_id, "days": days, "limit": limit}})

import subprocess
from flask import jsonify

@admin_bp.route("/admin/log-stream")
@admin_required_effective
def log_stream():
    """æœ€æ–°ã® system.log ã‚’èª­ã¿è¾¼ã‚“ã§JSONã§è¿”ã™ï¼ˆæœ€å¤§30è¡Œï¼‰"""
    try:
        from app.utils.log_utils import parse_logs
        log_path = os.path.join("logs", "system.log")

        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®æœ«å°¾ã‹ã‚‰æœ€å¤§30è¡Œã‚’å–å¾—
        with open(log_path, "r", encoding="utf-8") as f:
            lines = f.readlines()[-30:]

        # 1è¡Œã”ã¨ã«æ•´å½¢
        logs = parse_logs(lines)
        return jsonify({"logs": logs})

    except Exception as e:
        import traceback
        print("âŒ log_stream failed:", str(e))
        traceback.print_exc()
        return jsonify({"error": str(e)})




# ğŸ§  APIä½¿ç”¨é‡ï¼ãƒˆãƒ¼ã‚¯ãƒ³åˆ†æ
@admin_bp.route("/admin/api-usage")
@admin_required_effective
def api_usage():
    from app.models import TokenUsageLog, User
    from datetime import datetime
    # æ—¥åˆ¥é›†è¨ˆï¼ˆéå»30æ—¥ï¼‰
    today = datetime.utcnow().date()
    date_30_days_ago = today - timedelta(days=29)

    daily_data = (
        db.session.query(
            func.date(TokenUsageLog.created_at).label("date"),
            func.sum(TokenUsageLog.total_tokens).label("total_tokens")
        )
        .filter(TokenUsageLog.created_at >= date_30_days_ago)
        .group_by("date")
        .order_by("date")
        .all()
    )

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥é›†è¨ˆï¼ˆéå»30æ—¥ï¼‰
    user_data = (
        db.session.query(
            User.email,
            func.sum(TokenUsageLog.total_tokens).label("total_tokens")
        )
        .join(TokenUsageLog, TokenUsageLog.user_id == User.id)
        .filter(TokenUsageLog.created_at >= date_30_days_ago)
        .group_by(User.email)
        .order_by(func.sum(TokenUsageLog.total_tokens).desc())
        .all()
    )

    return render_template(
        "admin/api_usage.html",
        daily_data=daily_data,
        user_data=user_data
    )


# ğŸ’° ä»Šæœˆã®å£²ä¸Šï¼†å–ã‚Šåˆ†ã‚µãƒãƒª
@admin_bp.route("/admin/revenue-summary")
@admin_required_effective
def revenue_summary():
    from app.models import PaymentLog, User
    from datetime import datetime
    # ä»Šæœˆã®é–‹å§‹æ—¥ã‚’å–å¾—ï¼ˆUTCï¼‰
    today = datetime.utcnow()
    first_day = today.replace(day=1, hour=0, minute=0, second=0, microsecond=0)

    # ä»Šæœˆã®å£²ä¸Šï¼ˆæˆåŠŸã—ãŸæ±ºæ¸ˆã®ã¿ï¼‰
    logs = (
        db.session.query(
            User.email,
            func.sum(PaymentLog.amount).label("total_amount"),
            func.count(PaymentLog.id).label("count")
        )
        .join(User, PaymentLog.user_id == User.id)
        .filter(PaymentLog.status == "succeeded")
        .filter(PaymentLog.created_at >= first_day)
        .group_by(User.email)
        .order_by(func.sum(PaymentLog.amount).desc())
        .all()
    )

    # ç·å£²ä¸Š
    total = sum(row.total_amount for row in logs)

    return render_template(
        "admin/revenue_summary.html",
        logs=logs,
        total=total
    )


# ğŸ“ˆ å£²ä¸Šæ¨ç§»ã‚°ãƒ©ãƒ•ï¼‹CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
# ğŸ“ˆ æœˆåˆ¥å£²ä¸Šã‚°ãƒ©ãƒ• + CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
@admin_bp.route("/admin/revenue-graph")
@admin_required_effective
def revenue_graph():
    from app.models import PaymentLog
    from datetime import datetime, timedelta

    # éå»12ãƒ¶æœˆåˆ†ã®æœˆæ¬¡é›†è¨ˆ
    today = datetime.utcnow()
    first_day = today.replace(day=1) - timedelta(days=365)

    monthly_data = (
        db.session.query(
            func.to_char(PaymentLog.created_at, 'YYYY-MM').label("month"),
            func.sum(PaymentLog.amount).label("total")
        )
        .filter(PaymentLog.status == "succeeded")
        .filter(PaymentLog.created_at >= first_day)
        .group_by("month")
        .order_by("month")
        .all()
    )

    return render_template("admin/revenue_graph.html", monthly_data=monthly_data)

# ğŸ“¥ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ«ãƒ¼ãƒˆ
@admin_bp.route("/admin/download-revenue-log")
@admin_required_effective
def download_revenue_log():
    from app.models import PaymentLog, User
    import csv
    from io import StringIO
    from flask import Response

    logs = (
        db.session.query(
            PaymentLog.id,
            PaymentLog.amount,
            PaymentLog.status,
            PaymentLog.created_at,
            User.email
        )
        .join(User, PaymentLog.user_id == User.id)
        .order_by(PaymentLog.created_at.desc())
        .all()
    )

    output = StringIO()
    writer = csv.writer(output)
    writer.writerow(["ID", "Email", "é‡‘é¡ï¼ˆå††ï¼‰", "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", "æ—¥æ™‚"])

    for log_id, amount, status, created_at, email in logs:
        writer.writerow([log_id, email, amount // 100, status, created_at.strftime("%Y-%m-%d %H:%M:%S")])

    output.seek(0)
    return Response(
        output,
        mimetype='text/csv',
        headers={"Content-Disposition": "attachment;filename=revenue_log.csv"}
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ç®¡ç†è€…ï¼šã‚¸ãƒ£ãƒ³ãƒ«ç®¡ç†ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã”ã¨ã®ã‚¸ãƒ£ãƒ³ãƒ«è¡¨ç¤ºï¼‰
@admin_bp.route("/admin/genres", methods=["GET"])
@admin_required_effective
def manage_genres():
    if not current_user.is_admin:
        abort(403)

    from app.models import User  # å¿µã®ãŸã‚Userã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    users = User.query.order_by(User.last_name, User.first_name).all()

    return render_template("admin/genres.html", users=users)


@admin_bp.route("/admin/genres/delete/<int:genre_id>", methods=["POST"])
@admin_required_effective
def delete_genre(genre_id):

    genre = Genre.query.get_or_404(genre_id)
    db.session.delete(genre)
    db.session.commit()
    flash("ã‚¸ãƒ£ãƒ³ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ", "info")
    return redirect(url_for("admin.manage_genres"))


@admin_bp.route("/admin/users", methods=["GET", "POST"])  # âœ… POSTå¯¾å¿œã‚’è¿½åŠ 
@admin_required_effective
def admin_users():

    # âœ… ã‚µã‚¤ãƒˆæ è¿½åŠ ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†ï¼ˆPOSTã§æ¥ãŸã¨ãã®ã¿ï¼‰
    if request.method == "POST":
        if request.form.get("action") == "increase_quota":
            user_id = int(request.form.get("user_id"))
            plan_type = request.form.get("plan_type")

            # âœ… è©²å½“ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼†ãƒ—ãƒ©ãƒ³ã®æ ã‚’å–å¾— or ä½œæˆ
            quota = UserSiteQuota.query.filter_by(user_id=user_id, plan_type=plan_type).first()
            if quota:
                quota.total_quota += 1
            else:
                quota = UserSiteQuota(user_id=user_id, plan_type=plan_type, total_quota=1)
                db.session.add(quota)

            db.session.commit()
            flash("ã‚µã‚¤ãƒˆæ ã‚’ +1 ã—ã¾ã—ãŸ", "success")

            return redirect(url_for("admin.admin_users"))

    # âœ… å¿…è¦æœ€ä½é™ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã®ã¿å–å¾—ï¼ˆâ†’ Rowå½¢å¼ â†’ dictå½¢å¼ã«å¤‰æ›ï¼‰
    raw_users = db.session.query(
        User.id,
        User.first_name,
        User.last_name,
        User.email,
        User.is_admin,
        User.is_special_access,
        User.created_at
    ).order_by(User.id).all()

    users = [
        {
            "id": u.id,
            "first_name": u.first_name,
            "last_name": u.last_name,
            "email": u.email,
            "is_admin": u.is_admin,
            "is_special_access": u.is_special_access,
            "created_at": u.created_at.strftime("%Y-%m-%d %H:%M") if u.created_at else "ä¸æ˜"
        }
        for u in raw_users
    ]

    site_count    = Site.query.count()
    prompt_count  = PromptTemplate.query.count()
    article_count = Article.query.count()

    # âœ… ã“ã“ã«è¿½åŠ 
    stuck_counts = dict(
        db.session.query(
            Article.user_id,
            func.count()
        ).filter(
            Article.status.in_(["pending", "gen"])
        ).group_by(Article.user_id).all()
    )

    return render_template(
        "admin/users.html",
        users=users,  # â† JSONã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºå¯èƒ½ãªå½¢å¼ã«ä¿®æ­£æ¸ˆã¿
        site_count=site_count,
        prompt_count=prompt_count,
        article_count=article_count,
        user_count=len(users),
        stuck_counts=stuck_counts
    )


@admin_bp.route("/api/admin/user_stats/<int:user_id>")
@admin_required_effective
def api_user_stats(user_id):

    from collections import defaultdict

    # ğŸ”¸ è¨˜äº‹æ•°
    total_articles = db.session.query(func.count(Article.id)).filter_by(user_id=user_id).scalar()

    # ğŸ”¸ é€”ä¸­è¨˜äº‹ï¼ˆpending / genï¼‰
    stuck_articles = db.session.query(func.count(Article.id)).filter(
        Article.user_id == user_id,
        Article.status.in_(["pending", "gen"])
    ).scalar()

    # ğŸ”¸ ã‚µã‚¤ãƒˆæ ï¼ˆUserSiteQuota ã¨ Site ä½¿ç”¨æ•°ã®å·®ï¼‰
    quota_rows = db.session.query(
        UserSiteQuota.plan_type,
        UserSiteQuota.total_quota
    ).filter_by(user_id=user_id).all()

    site_counts = db.session.query(
        Site.plan_type,
        func.count(Site.id)
    ).filter_by(user_id=user_id).group_by(Site.plan_type).all()

    # æ•´å½¢ï¼šplan_type â†’ { used, total, remaining }
    summary = {}
    used_map = {pt: c for pt, c in site_counts}

    for plan_type, total_quota in quota_rows:
        used = used_map.get(plan_type, 0)
        remaining = max(total_quota - used, 0)
        summary[plan_type] = {
            "used": used,
            "total": total_quota,
            "remaining": remaining
        }

    return jsonify({
        "article_count": total_articles,
        "stuck_count": stuck_articles,
        "quota_summary": summary
    })



@admin_bp.route("/admin/user/<int:uid>")
@admin_required_effective
def admin_user_detail(uid):

    user = User.query.get_or_404(uid)

    # é–¢é€£æƒ…å ±ã‚’ã™ã¹ã¦å–å¾—
    sites = Site.query.filter_by(user_id=uid).all()
    prompts = PromptTemplate.query.filter_by(user_id=uid).all()
    keywords = Keyword.query.filter_by(user_id=uid).all()
    articles = Article.query.filter_by(user_id=uid).order_by(Article.created_at.desc()).limit(20).all()
    payments = PaymentLog.query.filter_by(user_id=uid).order_by(PaymentLog.created_at.desc()).all()

    return render_template(
        "admin/user_detail.html",
        user=user,
        sites=sites,
        prompts=prompts,
        keywords=keywords,
        articles=articles,
        payments=payments
    )


from app.forms import QuotaUpdateForm

@admin_bp.route("/admin/quota-edit/<int:uid>", methods=["GET", "POST"])
@admin_required_effective
def admin_quota_edit(uid):

    user = User.query.get_or_404(uid)
    form = QuotaUpdateForm()

    if form.validate_on_submit():
        plan_type = form.plan_type.data
        count = form.count.data

        # ã‚¯ã‚©ãƒ¼ã‚¿å–å¾— or ä½œæˆ
        quota = UserSiteQuota.query.filter_by(user_id=user.id, plan_type=plan_type).first()
        if not quota:
            quota = UserSiteQuota(user_id=user.id, plan_type=plan_type, total_quota=0, used_quota=0)
            db.session.add(quota)

        quota.total_quota += count

        log = SiteQuotaLog(
            user_id=user.id,
            plan_type=plan_type,
            site_count=count,
            reason="ç®¡ç†è€…æ‰‹å‹•è¿½åŠ ",
            created_at = datetime.utcnow()
        )
        db.session.add(log)
        db.session.commit()

        flash(f"âœ… {plan_type}ãƒ—ãƒ©ãƒ³ã«{count}æ è¿½åŠ ã—ã¾ã—ãŸ", "success")
        return redirect(url_for("admin.admin_users"))

    return render_template("admin/quota_edit.html", user=user, form=form)



@admin_bp.post("/admin/user/<int:uid>/toggle-special")
@admin_required_effective
def toggle_special_access(uid):
    # ç®¡ç†è€…ã®ã¿è¨±å¯

    # å¯¾è±¡ãƒ¦ãƒ¼ã‚¶ãƒ¼å–å¾—
    user = User.query.get_or_404(uid)

    # is_special_access ã‚’ãƒˆã‚°ãƒ«ï¼ˆON â‡” OFFï¼‰
    user.is_special_access = not user.is_special_access
    db.session.commit()

    flash(f"{user.email} ã®ç‰¹åˆ¥ã‚¢ã‚¯ã‚»ã‚¹ã‚’ {'âœ… æœ‰åŠ¹åŒ–' if user.is_special_access else 'âŒ ç„¡åŠ¹åŒ–'} ã—ã¾ã—ãŸã€‚", "success")
    return redirect(url_for("admin.admin_users"))



@admin_bp.route("/admin/sites")
@admin_required_effective
def admin_sites():
    if not current_user.is_admin:
        flash("ã“ã®ãƒšãƒ¼ã‚¸ã«ã¯ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ã€‚", "error")
        return redirect(url_for("main.dashboard", username=current_user.username))

    from sqlalchemy import case, literal, func
    from app.models import Site, Article, User, Genre, GSCConfig, GSCDailyTotal
    from datetime import datetime, timezone, timedelta
    from collections import defaultdict

    # ğŸ”¹ ã‚¸ãƒ£ãƒ³ãƒ«IDâ†’ã‚¸ãƒ£ãƒ³ãƒ«åã®è¾æ›¸ã‚’äº‹å‰å–å¾—
    genre_dict = {g.id: g.name for g in Genre.query.all()}

    # ğŸ”¹ GSCã¯ã€ŒJSTã®æ˜¨æ—¥ã¾ã§ã€ã®ç›´è¿‘28æ—¥ã§åˆè¨ˆã‚’å‡ºã™ï¼ˆçµåˆãªã—ãƒ»ç›¸é–¢ã‚µãƒ–ã‚¯ã‚¨ãƒªï¼‰
    JST = timezone(timedelta(hours=9))
    _today_jst = datetime.now(timezone.utc).astimezone(JST).date()
    _end_d = _today_jst - timedelta(days=1)      # æ˜¨æ—¥ã¾ã§
    _start_d = _end_d - timedelta(days=27)       # ç›´è¿‘28æ—¥
    _gsc_clicks_28d = (
        db.session.query(func.coalesce(func.sum(GSCDailyTotal.clicks), 0))
        .filter(GSCDailyTotal.site_id == Site.id,
                GSCDailyTotal.date >= _start_d,
                GSCDailyTotal.date <= _end_d)
        .correlate(Site).scalar_subquery()
    )
    _gsc_impr_28d = (
        db.session.query(func.coalesce(func.sum(GSCDailyTotal.impressions), 0))
        .filter(GSCDailyTotal.site_id == Site.id,
                GSCDailyTotal.date >= _start_d,
                GSCDailyTotal.date <= _end_d)
        .correlate(Site).scalar_subquery()
    )

    # ğŸ”¹ ã‚µã‚¤ãƒˆã”ã¨ã®çµ±è¨ˆæƒ…å ±ï¼ˆæŠ•ç¨¿æ•°ãªã©ï¼‰ï¼‹GSCæ¥ç¶šçŠ¶æ…‹ã‚’å–å¾—
    raw = (
        db.session.query(
            Site.id,
            Site.name,
            Site.url,
            Site.plan_type,
            Site.genre_id,
            Site.user_id,
            func.concat(User.last_name, literal(" "), User.first_name).label("user_name"),
            func.count(Article.id).label("total"),
            func.sum(case((Article.status == "done", 1), else_=0)).label("done"),
            func.sum(case((Article.status == "posted", 1), else_=0)).label("posted"),
            func.sum(case((Article.status == "error", 1), else_=0)).label("error"),
            _gsc_clicks_28d.label("clicks"),
            _gsc_impr_28d.label("impressions"),
            func.max(GSCConfig.id).isnot(None).label("gsc_connected")
        )
        .join(User, Site.user_id == User.id)
        .outerjoin(Article, Site.id == Article.site_id)
        .outerjoin(GSCConfig, Site.id == GSCConfig.site_id)
        .group_by(Site.id, User.id)
        .order_by(User.id, Site.id.desc())
        .all()
    )

    # ğŸ”¹ ãƒ¦ãƒ¼ã‚¶ãƒ¼å˜ä½ã§ã¾ã¨ã‚ã¦ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«æ¸¡ã™ãŸã‚ã®æ§‹é€ ã‚’æ§‹ç¯‰
    sites_by_user = defaultdict(lambda: {"user_id": None, "sites": [], "genres": set()})

    for row in raw:
        user_name = row.user_name
        genre_id = row.genre_id
        genre_name = genre_dict.get(genre_id, "") if genre_id else ""

        # å„ã‚µã‚¤ãƒˆã®æƒ…å ±
        site_info = {
            "id": row.id,  # â† âœ… ã“ã®è¡Œã‚’è¿½åŠ ã—ã¦ãã ã•ã„
            "name": row.name,
            "url": row.url,
            "plan_type": row.plan_type,
            "total": row.total or 0,
            "done": row.done or 0,
            "posted": row.posted or 0,
            "error": row.error or 0,
            "clicks": row.clicks or 0,
            "impressions": row.impressions or 0,
            "genre": genre_name,
            "gsc_connected": bool(row.gsc_connected)  # â† GSCæ¥ç¶šãƒ©ãƒ™ãƒ«ã«æ­£ã—ãå¯¾å¿œ
        }

        # åˆå›æ™‚ã®ã¿ user_id ã‚’ç™»éŒ²
        if sites_by_user[user_name]["user_id"] is None:
            sites_by_user[user_name]["user_id"] = row.user_id

        # ã‚µã‚¤ãƒˆæƒ…å ±ã‚’æ ¼ç´
        sites_by_user[user_name]["sites"].append(site_info)

        # ã‚¸ãƒ£ãƒ³ãƒ«åãŒã‚ã‚Œã°è¿½åŠ ï¼ˆé‡è¤‡å›é¿ã®ãŸã‚ setï¼‰
        if genre_name:
            sites_by_user[user_name]["genres"].add(genre_name)

    # ğŸ”¹ æœ€çµ‚çš„ã« genres ã‚’ã‚½ãƒ¼ãƒˆã•ã‚ŒãŸãƒªã‚¹ãƒˆã«å¤‰æ›ï¼ˆselectè¦ç´ ç”¨ï¼‰
    for user_data in sites_by_user.values():
        user_data["genres"] = sorted(user_data["genres"])

    # ğŸ”¹ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«æ¸¡ã™
    return render_template("admin/sites.html", sites_by_user=sites_by_user)

@admin_bp.route('/admin/delete_site/<int:site_id>', methods=['POST'])
@admin_required_effective
def delete_site(site_id):

    site = Site.query.get_or_404(site_id)

    # âœ… é–¢é€£è¨˜äº‹å‰Šé™¤
    Article.query.filter_by(site_id=site.id).delete()

    # âœ… é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å‰Šé™¤
    Keyword.query.filter_by(site_id=site.id).delete()

    # âœ… GSC èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³å‰Šé™¤
    GSCAuthToken.query.filter_by(site_id=site.id).delete()

    # âœ… GSC è¨­å®šãƒ‡ãƒ¼ã‚¿å‰Šé™¤
    GSCConfig.query.filter_by(site_id=site.id).delete()

    # âŒ ã‚¢ã‚¤ã‚­ãƒ£ãƒƒãƒç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã¯æ®‹ã™ï¼ˆ/static/images/...ï¼‰

    # âŒ Stripeã‚„Tokenãƒ­ã‚°ç­‰ã¯å‰Šé™¤ã—ãªã„ï¼ˆç›£æŸ»ç”¨ï¼‰

    # âœ… æœ€å¾Œã«ã‚µã‚¤ãƒˆæœ¬ä½“ã‚’å‰Šé™¤
    db.session.delete(site)
    db.session.commit()

    flash('ã‚µã‚¤ãƒˆã¨é–¢é€£ãƒ‡ãƒ¼ã‚¿ï¼ˆè¨˜äº‹ãƒ»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ»GSCæƒ…å ±ï¼‰ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚', 'success')
    return redirect(url_for('admin.admin_sites'))  # âœ… ä¿®æ­£æ¸ˆã¿



@admin_bp.route("/admin/user/<int:uid>/bulk-delete", methods=["POST"])
@admin_required_effective
def bulk_delete_articles(uid):

    # pending ã¾ãŸã¯ gen çŠ¶æ…‹ã®è¨˜äº‹ã‚’ä¸€æ‹¬å‰Šé™¤
    Article.query.filter(
        Article.user_id == uid,
        Article.status.in_(["pending", "gen"])
    ).delete()

    db.session.commit()
    flash("âœ… é€”ä¸­çŠ¶æ…‹ã®è¨˜äº‹ã‚’ä¸€æ‹¬å‰Šé™¤ã—ã¾ã—ãŸ", "success")
    return redirect(url_for("admin.user_articles", uid=uid))



@admin_bp.post("/admin/delete-stuck-articles")
@admin_required_effective
def delete_stuck_articles():

    stuck = Article.query.filter(Article.status.in_(["pending", "gen"])).all()

    deleted_count = len(stuck)
    for a in stuck:
        db.session.delete(a)
    db.session.commit()

    flash(f"{deleted_count} ä»¶ã®é€”ä¸­åœæ­¢è¨˜äº‹ã‚’å‰Šé™¤ã—ã¾ã—ãŸ", "success")
    return redirect(url_for("admin.admin_dashboard"))


from flask import render_template, request, redirect, url_for, flash, abort, current_app
from flask_login import login_required, current_user
from app.forms import RyunosukeDepositForm
from app.models import User, RyunosukeDeposit, Site, SiteQuotaLog, db
from collections import defaultdict
from datetime import datetime
from sqlalchemy import func, extract, text
import time

@admin_bp.route("/admin/accounting", methods=["GET", "POST"])
@admin_required_effective
def accounting():
    t0 = time.perf_counter()

    selected_month = request.args.get("month", "all")

    # âœ… å…¥é‡‘ãƒ•ã‚©ãƒ¼ãƒ å‡¦ç†ï¼ˆPOSTï¼‰
    form = RyunosukeDepositForm()
    if form.validate_on_submit():
        new_deposit = RyunosukeDeposit(
            deposit_date=form.deposit_date.data,
            amount=form.amount.data,
            memo=form.memo.data
        )
        db.session.add(new_deposit)
        db.session.commit()
        flash("é¾ä¹‹ä»‹ã®å…¥é‡‘è¨˜éŒ²ã‚’ä¿å­˜ã—ã¾ã—ãŸ", "success")
        return redirect(url_for("admin.accounting"))

    # â”€â”€ è¨ˆæ¸¬é–‹å§‹
    t0 = time.perf_counter()

    # âœ… å…¥é‡‘åˆè¨ˆã¨æ®‹é«˜
    paid_total = db.session.query(
        db.func.coalesce(db.func.sum(RyunosukeDeposit.amount), 0)
    ).scalar()
    logger.info("[accounting] t_sum_deposit=%.3f", time.perf_counter()-t0)
    current_app.logger.info("[/admin/accounting] paid_total in %.3fs", time.perf_counter()-t0); t0=time.perf_counter()

    # âœ… ã‚µã‚¤ãƒˆæ åˆè¨ˆã‚’SQLã²ã¨æ’ƒã¡ã§å–å¾—ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼é…åˆ—ã¯æœªä½¿ç”¨ãªã®ã§è¨ˆç®—ã®ã¿ï¼‰
    t1 = time.perf_counter()
    row = db.session.execute(text("""
        SELECT
          COALESCE(SUM(CASE
              WHEN u.is_admin = FALSE AND sq.plan_type = 'business' AND sq.total_quota > 0
              THEN sq.total_quota ELSE 0 END), 0) AS business_total,
          COALESCE(SUM(CASE
              WHEN u.is_admin = FALSE AND (u.is_special_access = TRUE OR u.id = 16)
                   AND COALESCE(sq.plan_type, '') <> 'business' AND sq.total_quota > 0
              THEN sq.total_quota ELSE 0 END), 0) AS tcc_1000_total,
          COALESCE(SUM(CASE
              WHEN u.is_admin = FALSE AND (u.is_special_access = FALSE AND u.id <> 16)
                   AND COALESCE(sq.plan_type, '') <> 'business' AND sq.total_quota > 0
              THEN sq.total_quota ELSE 0 END), 0) AS tcc_3000_total
        FROM "user" u
        JOIN user_site_quota sq ON sq.user_id = u.id
    """)).fetchone()
    business_total  = int(row.business_total)
    tcc_1000_total  = int(row.tcc_1000_total)
    tcc_3000_total  = int(row.tcc_3000_total)
    # ç”»é¢ã§ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼é…åˆ—ã‚’ä½¿ã£ã¦ã„ãªã„ãŸã‚ç©ºã§æ¸¡ã™ï¼ˆäº’æ›ç¶­æŒï¼‰
    student_users, member_users, business_users = [], [], []
    current_app.logger.info("[/admin/accounting] load quota sums in %.3fs", time.perf_counter()-t1)


    # âœ… é›†è¨ˆçµæœï¼ˆç¾çŠ¶ã®æ§‹æˆã¯å®Œå…¨ç¶­æŒï¼‰
    breakdown = {
        "unpurchased": {
            "count": tcc_3000_total,
            "ryu": tcc_3000_total * 1000,
            "take": tcc_3000_total * 2000,
        },
        "purchased": {
            "count": tcc_1000_total,
            "ryu": 0,
            "take": tcc_1000_total * 1000,
        },
        "business": {
            "count": business_total,
            "ryu": business_total * 16000,
            "take": business_total * 4000,
        },
        "total": {
            "count": tcc_3000_total + tcc_1000_total + business_total,
            "ryu": tcc_3000_total * 1000 + business_total * 16000,
            "take": tcc_3000_total * 2000 + tcc_1000_total * 1000 + business_total * 4000,
        },
    }

    # âœ… ã‚µã‚¤ãƒˆç™»éŒ²ãƒ‡ãƒ¼ã‚¿ã‚’æœˆåˆ¥ã«SQLã§ç›´æ¥é›†è¨ˆï¼ˆjoinæœ€é©åŒ–ï¼‹NULLé™¤å¤–ï¼‰
    t2 = time.perf_counter()
    site_data_raw = (
        db.session.query(
            func.date_trunc("month", Site.created_at).label("month"),
            func.count(Site.id)
        )
        .join(User, Site.user_id == User.id, isouter=False)
        .filter(
            Site.created_at.isnot(None),
            User.is_admin == False,
            User.is_special_access == False  # â† TCCç ”ç©¶ç”Ÿï¼ˆ3,000å††ï¼‰ã®ã¿
        )
        .group_by(func.date_trunc("month", Site.created_at))
        .all()
    )
    logger.info("[accounting] t_site_agg=%.3f", time.perf_counter()-t2)
    current_app.logger.info("[/admin/accounting] monthly site agg in %.3fs", time.perf_counter()-t0); t0=time.perf_counter()

    site_data_by_month = {}
    all_months_set = set()

    for month_obj, count in site_data_raw:
        month_key = month_obj.strftime("%Y-%m")
        all_months_set.add(month_key)
        site_data_by_month[month_key] = {
            "site_count": count,
            "ryunosuke_income": count * 1000,
            "takeshi_income": count * 2000
        }

    # âœ… é¸æŠæœˆã®ã¿è¡¨ç¤º or å…¨è¡¨ç¤º
    filtered_data = (
        site_data_by_month if selected_month == "all"
        else {
            selected_month: site_data_by_month.get(selected_month, {
                "site_count": 0,
                "ryunosuke_income": 0,
                "takeshi_income": 0
            })
        }
    )

    # âœ… å…¥é‡‘å±¥æ­´ã¨æœˆä¸€è¦§ï¼ˆå¤‰åŒ–ãªã—ï¼‰
    t3 = time.perf_counter()
    deposit_logs = RyunosukeDeposit.query.order_by(RyunosukeDeposit.deposit_date.desc()).all()
    current_app.logger.info("[/admin/accounting] load deposit_logs in %.3fs", time.perf_counter()-t0); t0=time.perf_counter()
    logger.info("[accounting] t_deposits=%.3f", time.perf_counter()-t3)
    all_months = sorted(all_months_set, reverse=True)

    # âœ… ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¸æ¸¡ã™ï¼ˆç¾çŠ¶ç¶­æŒï¼‰
    t4 = time.perf_counter()
    resp = render_template(
        "admin/accounting.html",
        form=form,
        paid_total=paid_total,
        remaining=breakdown["unpurchased"]["ryu"] - paid_total,
        site_data_by_month=dict(sorted(filtered_data.items())),
        selected_month=selected_month,
        all_months=all_months,
        deposit_logs=deposit_logs,
        breakdown=breakdown,
        student_users=student_users,
        member_users=member_users,
        business_users=business_users
    )
    logger.info("[accounting] t_render=%.3f  t_total=%.3f",
             time.perf_counter()-t4, time.perf_counter()-t0)
    current_app.logger.info("[/admin/accounting] render_template in %.3fs", time.perf_counter()-t0)
    return resp


@admin_bp.route("/admin/accounting/details", methods=["GET"])
@admin_required_effective
def accounting_details():

    selected_month = request.args.get("month", "all")

    # âœ… æœˆä¸€è¦§ã‚’æŠ½å‡ºï¼ˆNULLã‚’é™¤å¤–ã—ã¦é«˜é€Ÿã«ï¼‰
    all_months_raw = (
        db.session.query(func.date_trunc("month", SiteQuotaLog.created_at))
        .filter(SiteQuotaLog.created_at.isnot(None))
        .distinct()
        .all()
    )

    all_months = sorted(
        {month[0].strftime("%Y-%m") for month in all_months_raw},
        reverse=True
    )

    # âœ… æœˆãƒ•ã‚£ãƒ«ã‚¿ã«å¿œã˜ã¦ãƒ­ã‚°æŠ½å‡º
    logs_query = SiteQuotaLog.query.filter(SiteQuotaLog.created_at.isnot(None))

    if selected_month != "all":
        try:
            year, month = selected_month.split("-")
            logs_query = logs_query.filter(
                extract("year", SiteQuotaLog.created_at) == int(year),
                extract("month", SiteQuotaLog.created_at) == int(month)
            )
        except Exception:
            flash("ä¸æ­£ãªæœˆå½¢å¼ã§ã™", "error")
            return redirect(url_for("admin.accounting_details"))

    # âœ… ä¸¦ã³é †ï¼ˆæ–°ã—ã„é †ï¼‰
    logs = logs_query.order_by(SiteQuotaLog.created_at.desc()).all()

    # âœ… ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¸æ¸¡ã™ï¼ˆå¤‰åŒ–ãªã—ï¼‰
    return render_template(
        "admin/accounting_details.html",
        logs=logs,
        selected_month=selected_month,
        all_months=all_months
    )


@admin_bp.route("/admin/accounting/adjust", methods=["POST"])
@admin_required_effective
def adjust_quota():

    from flask import request, jsonify

    data = request.get_json()

    try:
        uid = int(data.get("uid"))
        delta = int(data.get("delta", 0))
    except (ValueError, TypeError):
        return jsonify({"error": "uid ã¾ãŸã¯ delta ã®å½¢å¼ãŒä¸æ­£ã§ã™"}), 400

    if delta == 0:
        return jsonify({"error": "delta ã¯ 0 ä»¥å¤–ã§æŒ‡å®šã—ã¦ãã ã•ã„"}), 400

    user = User.query.filter_by(id=uid, is_admin=False).first()
    if not user or not user.site_quota:
        return jsonify({"error": "å¯¾è±¡ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}), 404

    quota = user.site_quota
    quota.total_quota = max(quota.total_quota + delta, 0)

    # ãƒ­ã‚°è¨˜éŒ²
    quota_log = SiteQuotaLog(
        user_id=user.id,
        plan_type=quota.plan_type,
        site_count=delta,
        reason="ç®¡ç†è€…æ‰‹å‹•èª¿æ•´",
        created_at=datetime.utcnow()
    )
    db.session.add(quota_log)
    db.session.commit()

    # âœ… é›†è¨ˆå†æ§‹ç¯‰
    stu_cnt = mem_cnt = biz_cnt = 0
    for u in User.query.filter_by(is_admin=False).all():
        sq = u.site_quota
        if not sq or sq.total_quota == 0:
            continue
        if sq.plan_type == "business":
            biz_cnt += sq.total_quota
        elif u.is_special_access:
            mem_cnt += sq.total_quota
        else:
            stu_cnt += sq.total_quota

    PRICES = {
        "student":  {"ryu": 1000,  "take": 2000},
        "member":   {"ryu": 0,     "take": 1000},
        "business": {"ryu": 16000, "take": 4000},
    }

    def calc(cnt, key):
        return {
            "count": cnt,
            "ryu": cnt * PRICES[key]["ryu"],
            "take": cnt * PRICES[key]["take"],
        }

    res_student  = calc(stu_cnt, "student")
    res_member   = calc(mem_cnt, "member")
    res_business = calc(biz_cnt, "business")

    res_total = {
        "count": stu_cnt + mem_cnt + biz_cnt,
        "ryu":   res_student["ryu"] + res_member["ryu"] + res_business["ryu"],
        "take":  res_student["take"] + res_member["take"] + res_business["take"]
    }

    return jsonify({
        "student":  res_student,
        "member":   res_member,
        "business": res_business,
        "total":    res_total,
        "message": f"âœ… {user.last_name} {user.first_name} ã« {delta:+} ä»¶ èª¿æ•´ã—ã¾ã—ãŸ"
    })



# --- æ—¢å­˜: ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¨è¨˜äº‹è¡¨ç¤º ---
@admin_bp.route("/admin/user/<int:uid>/articles")
@admin_required_effective
def user_articles(uid):

    from collections import defaultdict
    from app.article_generator import _generate_slots_per_site
    from app.models import User, Article, Site
    from sqlalchemy.orm import selectinload
    from sqlalchemy import asc, nulls_last

    user = User.query.get_or_404(uid)
    status = request.args.get("status")
    sort_key = request.args.get("sort", "scheduled_at")
    sort_order = request.args.get("order", "desc")
    source = request.args.get("source", "all")

    # ğŸ”¹ æœªã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®è¨˜äº‹ã«slotè‡ªå‹•å‰²å½“
    unscheduled = Article.query.filter(
        Article.user_id == user.id,
        Article.scheduled_at.is_(None)
    ).all()

    if unscheduled:
        site_map = defaultdict(list)
        for art in unscheduled:
            if art.site_id:
                site_map[art.site_id].append(art)

        for sid, articles in site_map.items():
            slots = iter(_generate_slots_per_site(current_app, sid, len(articles)))
            for art in articles:
                art.scheduled_at = next(slots)
        db.session.commit()

    # ğŸ”¹ è¨˜äº‹å–å¾—ã‚¯ã‚¨ãƒª
    q = Article.query.filter_by(user_id=user.id)
    if status:
        q = q.filter_by(status=status)
    if source == "gsc":
        q = q.filter_by(source="gsc")

    q = q.options(selectinload(Article.site))
    q = q.order_by(nulls_last(asc(Article.scheduled_at)), Article.created_at.desc())
    articles = q.all()

    # ğŸ”½ ä¸¦ã³æ›¿ãˆï¼ˆPythonå´ï¼‰
    if sort_key == "clicks":
        articles.sort(key=lambda a: a.site.clicks or 0, reverse=(sort_order == "desc"))
    elif sort_key == "impr":
        articles.sort(key=lambda a: a.site.impressions or 0, reverse=(sort_order == "desc"))

    return render_template(
        "admin/user_articles.html",
        articles=articles,
        site=None,
        user=user,
        status=status,
        sort_key=sort_key,
        sort_order=sort_order,
        selected_source=source,
        jst=JST
    )


# --- âœ… è¿½åŠ : ã‚µã‚¤ãƒˆå˜ä½ã®è¨˜äº‹ä¸€è¦§è¡¨ç¤º ---
@admin_bp.route("/admin/site/<int:site_id>/articles")
@admin_required_effective
def site_articles(site_id):

    from app.models import Site, Article, User
    from sqlalchemy.orm import selectinload
    from sqlalchemy import asc, nulls_last

    site = Site.query.options(selectinload(Site.user)).get_or_404(site_id)
    user = site.user  # âœ… ã“ã“ã§ site ã«ç´ã¥ãæ­£ã—ã„ user ã‚’å–å¾—

    status = request.args.get("status")
    source = request.args.get("source", "all")

    q = Article.query.filter_by(site_id=site.id)
    if status:
        q = q.filter_by(status=status)
    if source == "gsc":
        q = q.filter_by(source="gsc")

    q = q.options(selectinload(Article.site))
    q = q.order_by(nulls_last(asc(Article.scheduled_at)), Article.created_at.desc())
    articles = q.all()

    return render_template(
        "admin/user_articles.html",
        articles=articles,
        site=site,
        user=user,  # âœ… ã“ã® user ã¯ site ã«ç´ã¥ã„ãŸã‚‚ã®
        status=status,
        sort_key=None,
        sort_order=None,
        selected_source=source,
        jst=JST
    )



@admin_bp.post("/admin/user/<int:uid>/delete-stuck")
@admin_required_effective
def delete_user_stuck_articles(uid):

    user = User.query.get_or_404(uid)

    stuck_articles = Article.query.filter(
        Article.user_id == uid,
        Article.status.in_(["pending", "gen"])
    ).all()

    count = len(stuck_articles)
    for art in stuck_articles:
        db.session.delete(art)
    db.session.commit()

    flash(f"{count} ä»¶ã®é€”ä¸­åœæ­¢è¨˜äº‹ã‚’å‰Šé™¤ã—ã¾ã—ãŸ", "success")
    return redirect(url_for("admin.user_articles", uid=uid))

@admin_bp.post("/admin/login-as/<int:user_id>")
@admin_required_effective
def admin_login_as(user_id):
    # æœ‰åŠ¹ç®¡ç†è€…ã®ãƒã‚§ãƒƒã‚¯ï¼ˆé€šå¸¸ç®¡ç†è€… or æ—¢ã«admin_idä¿æŒä¸­ï¼‰

    # ã„ã¾æœ¬å½“ã«ç®¡ç†è€…ã¨ã—ã¦ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ã„ã‚‹å ´åˆã€å…ƒã®ç®¡ç†è€…IDã‚’ä¿æŒ
    # ï¼ˆæ—¢ã«ä¿æŒã—ã¦ã„ã‚‹ãªã‚‰ä¸Šæ›¸ãã—ãªã„ï¼å¤šæ®µãªã‚Šã™ã¾ã—ã‚’é¿ã‘ã‚‹ï¼‰
    if ("admin_id" not in session) and getattr(current_user, "is_admin", False):
        session["admin_id"] = current_user.id

    # å¯¾è±¡ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å®Œå…¨åˆ‡æ›¿ï¼ˆï¼ä»¥å¾Œ current_user ã¯å¯¾è±¡ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼‰
    user = User.query.get_or_404(user_id)
    login_user(user)

    flash(f"{user.email} ã¨ã—ã¦ãƒ­ã‚°ã‚¤ãƒ³ã—ã¾ã—ãŸï¼ˆç®¡ç†è€…ãƒ¢ãƒ¼ãƒ‰ç¶­æŒï¼‰", "info")
    return redirect(url_for("main.dashboard", username=user.username))


@admin_bp.route("/admin/delete_user/<int:user_id>", methods=["POST"])
@admin_required_effective
def delete_user(user_id):

    user = User.query.get_or_404(user_id)

    db.session.delete(user)
    db.session.commit()

    flash("âœ… ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨é–¢é€£ãƒ‡ãƒ¼ã‚¿ã‚’ã™ã¹ã¦å‰Šé™¤ã—ã¾ã—ãŸã€‚", "success")
    return redirect(url_for("admin.admin_users"))


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ GSCã‚µã‚¤ãƒˆçŠ¶æ³ä¸€è¦§ï¼ˆç®¡ç†è€…ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@admin_bp.route("/admin/gsc_sites")
@admin_required_effective
def admin_gsc_sites():

    from sqlalchemy.orm import selectinload
    from collections import defaultdict
    from app.models import Site, User, Keyword, Article

    # å…¨ã‚µã‚¤ãƒˆã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼å˜ä½ã§å–å¾—ï¼ˆãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä»˜ãã§æœ€é©åŒ–ï¼‰
    users = User.query.options(selectinload(User.sites)).all()

    user_site_data = []

    for user in users:
        site_infos = []
        for site in user.sites:
            if not site.gsc_connected:
                continue  # GSCæœªæ¥ç¶šã‚µã‚¤ãƒˆã¯é™¤å¤–

            # GSCã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å…¨ä»¶
            keywords = Keyword.query.filter_by(site_id=site.id, source="gsc").all()
            done        = sum(1 for k in keywords if k.status == "done")
            generating  = sum(1 for k in keywords if k.status == "generating")
            unprocessed = sum(1 for k in keywords if k.status == "unprocessed")

            # æœ€æ–°å–å¾—ãƒ»ç”Ÿæˆæ—¥
            latest_keyword_date = max([k.created_at for k in keywords], default=None)

            # GSCè¨˜äº‹ã®æœ€æ–°ç”Ÿæˆæ—¥ï¼ˆArticleå‚ç…§ï¼‰
            latest_article = Article.query.filter_by(site_id=site.id, source="gsc").order_by(Article.created_at.desc()).first()
            latest_article_date = latest_article.created_at if latest_article else None

            site_infos.append({
                "site": site,
                "done": done,
                "generating": generating,
                "unprocessed": unprocessed,
                "total": done + generating + unprocessed,
                "latest_keyword_date": latest_keyword_date,
                "latest_article_date": latest_article_date
            })

        if site_infos:
            user_site_data.append({
                "user": user,
                "sites": site_infos
            })

    return render_template("admin/gsc_sites.html", user_site_data=user_site_data)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ NEW: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹é€²æ—ãƒ¢ãƒ‹ã‚¿ãƒ¼ï¼ˆé–²è¦§å°‚ç”¨ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@admin_bp.route("/admin/index_monitor")
@login_required
def admin_index_monitor():
    """å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ»å…¨ã‚µã‚¤ãƒˆã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç‡ã‚’é«˜é€Ÿé›†è¨ˆã—ã¦è¡¨ç¤º"""
    from datetime import date, timedelta
    from app.models import Site, Article, GSCDailyTotal, User

    # âœ… ç›´è¿‘28æ—¥ã®çª“ã‚’çµ±ä¸€ï¼ˆJSTã®æ˜¨æ—¥ âˆ§ DBæœ€æ–°æ—¥ï¼‰
    start_d, end_d = _gsc_window_by_latest_db(28)

    # ğŸ”¹ ç›´è¿‘28æ—¥é–“ã® GSCæ²è¼‰ãƒ‡ãƒ¼ã‚¿é›†è¨ˆï¼ˆsiteå˜ä½ï¼‰
    sub_gsc = (
        db.session.query(
            GSCDailyTotal.site_id,
            func.count(GSCDailyTotal.id).label("indexed_count")
        )
        .filter(GSCDailyTotal.date >= start_d, GSCDailyTotal.date <= end_d)
        .group_by(GSCDailyTotal.site_id)
        .subquery()
    )

    # ğŸ”¹ ã‚µã‚¤ãƒˆã”ã¨ã®è¨˜äº‹æ•°ï¼‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä»¶æ•°
    results = (
        db.session.query(
            Site.id, Site.url, Site.user_id,
            User.username,
            func.count(Article.id).label("article_count"),
            func.coalesce(sub_gsc.c.indexed_count, 0).label("indexed_count")
        )
        .join(User, User.id == Site.user_id)
        .outerjoin(Article, Article.site_id == Site.id)
        .outerjoin(sub_gsc, sub_gsc.c.site_id == Site.id)
        .group_by(Site.id, User.username, sub_gsc.c.indexed_count)
        .order_by(func.coalesce(sub_gsc.c.indexed_count, 0).asc())  # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å°‘ãªã„é †
        .limit(50)  # é€Ÿåº¦é‡è¦–
        .all()
    )

    # ğŸ”¹ è¡¨ç¤ºç”¨ã«æ•´å½¢
    data = []
    for site_id, url, user_id, username, total, indexed in results:
        rate = (indexed / total * 100) if total else 0
        data.append({
            "url": url,
            "username": username,
            "article_count": total,
            "indexed_count": indexed,
            "rate": round(rate, 1),
        })

    return render_template("admin/index_monitor.html", data=data)


@admin_bp.get("/admin/user/<int:uid>/stuck-articles")
@admin_required_effective
def stuck_articles(uid):

    user = User.query.get_or_404(uid)

    stuck_articles = Article.query.filter(
        Article.user_id == uid,
        Article.status.in_(["pending", "gen"])
    ).order_by(Article.created_at.desc()).all()

    return render_template("admin/stuck_articles.html", user=user, articles=stuck_articles)


@admin_bp.post("/admin/user/<int:uid>/regenerate-stuck")
@admin_required_effective
def regenerate_user_stuck_articles(uid):

    stuck_articles = Article.query.filter(
        Article.user_id == uid,
        Article.status.in_(["pending", "gen"])
    ).all()

    app = current_app._get_current_object()

    def _background_regeneration():
        with app.app_context():
            prompt = PromptTemplate.query.filter_by(user_id=uid).first()
            if not prompt:
                logging.warning(f"[å†ç”Ÿæˆä¸­æ­¢] user_id={uid} ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒã‚ã‚Šã¾ã›ã‚“")
                return

            for art in stuck_articles:
                try:
                    threading.Thread(
                        target=_generate,
                        args=(app, art.id, prompt.title_pt, prompt.body_pt),
                        daemon=True
                    ).start()
                except Exception as e:
                    logging.exception(f"[ç®¡ç†è€…å†ç”Ÿæˆå¤±æ•—] article_id={art.id} error={e}")

    threading.Thread(target=_background_regeneration, daemon=True).start()

    flash(f"{len(stuck_articles)} ä»¶ã®é€”ä¸­åœæ­¢è¨˜äº‹ã‚’å†ç”Ÿæˆã‚­ãƒ¥ãƒ¼ã«ç™»éŒ²ã—ã¾ã—ãŸï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†ï¼‰", "success")
    return redirect(url_for("admin.stuck_articles", uid=uid))



# å…ˆé ­ã® import ã‚’ä¿®æ­£
# æ—¢å­˜ã® import ã«è¿½åŠ ï¼ˆä¸Šã®æ–¹ï¼‰
from flask import Blueprint, request, jsonify, Response, redirect, url_for, render_template, current_app
from flask_login import login_required, current_user
from sqlalchemy import func, desc, asc, and_
from datetime import datetime, timedelta, timezone
from app import db
from app.models import User, Site, Article, GSCDailyTotal

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# GSC 28æ—¥ãªã©ã®é›†è¨ˆçª“ã‚’çµ±ä¸€ã™ã‚‹æ¥µå°ãƒ˜ãƒ«ãƒ‘ãƒ¼
# ãƒ»çµ‚ç«¯ã¯ã€ŒJSTã®æ˜¨æ—¥ã€ã¨ã€ŒDBã®æœ€æ–°æ—¥ã€ã®æ—©ã„æ–¹
# ãƒ»è¿”ã‚Šå€¤: (start_date, end_date) ã„ãšã‚Œã‚‚ date å‹ï¼ˆä¸¡ç«¯å«ã‚€ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _gsc_window_by_latest_db(days: int = 28):
    from app import db
    from app.models import GSCDailyTotal
    JST = timezone(timedelta(hours=9))
    today_jst = datetime.utcnow().replace(tzinfo=timezone.utc).astimezone(JST).date()
    end_by_yesterday = today_jst - timedelta(days=1)
    latest_db_date = db.session.query(func.max(GSCDailyTotal.date)).scalar()
    if latest_db_date:
        end_date = min(end_by_yesterday, latest_db_date)
    else:
        end_date = end_by_yesterday
    start_date = end_date - timedelta(days=max(1, int(days)) - 1)
    return start_date, end_date


# â† ã“ã‚Œã‚’å…ˆé ­ã® import ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«è¿½åŠ 
from app.utils.monitor import (
    get_memory_usage,
    get_cpu_load,
    get_latest_restart_log,
    get_last_restart_time,
)
import json

# â€» admin_bp ã¯æ—¢å­˜ã® Blueprint ã‚’ä½¿ç”¨

@admin_bp.route("/api/admin/rankings")
@admin_required_effective
def admin_rankings():

    # ==== ã‚¯ã‚¨ãƒªå–å¾— ====
    rank_type = (request.args.get("type") or "site").lower()        # site / impressions / clicks / posted_articles
    order     = (request.args.get("order") or "desc").lower()       # asc / desc
    period    = (request.args.get("period") or "3m").lower()        # 1d / 7d / 28d / 3m / 6m / 12m / 16m / custom / all
    start_str = request.args.get("start_date")
    end_str   = request.args.get("end_date")

    sort_func = asc if order == "asc" else desc

    # ==== JSTæ—¥ä»˜ã®å¢ƒç•Œã‚’ä½œã‚‹ï¼ˆGSCã«åˆã‚ã›ã‚‹ï¼‰ ====
    JST = timezone(timedelta(hours=9))
    now_utc = datetime.utcnow().replace(tzinfo=timezone.utc)
    now_jst = now_utc.astimezone(JST)

    # ãƒ—ãƒªã‚»ãƒƒãƒˆ â†’ JSTåŸºæº–ã®é–‹å§‹æ—¥æ™‚ã‚’æ±ºå®š
    def jst_date(d: datetime) -> datetime.date:
        return d.astimezone(JST).date()

    presets = {
        "1d":  now_jst - timedelta(days=1),
        "7d":  now_jst - timedelta(days=7),
        "28d": now_jst - timedelta(days=28),
        "3m":  now_jst - timedelta(days=90),
        "6m":  now_jst - timedelta(days=180),
        "12m": now_jst - timedelta(days=365),
        "16m": now_jst - timedelta(days=480),
        "all": None,
    }

    # æœŸé–“æ±ºå®šï¼ˆJSTæ—¥ä»˜ã§ä¿æŒï¼‰
    latest_db_date = db.session.query(func.max(GSCDailyTotal.date)).scalar()
    if period == "custom":
        try:
            # customã¯ yyyy-mm-ddï¼ˆãƒ­ãƒ¼ã‚«ãƒ«=JSTæƒ³å®šï¼‰ã‚’ãã®ã¾ã¾æ—¥ä»˜ã¨ã—ã¦ä½¿ã†
            start_jst_date = datetime.strptime(start_str, "%Y-%m-%d").date() if start_str else None
            end_jst_date   = datetime.strptime(end_str, "%Y-%m-%d").date()   if end_str   else jst_date(now_jst)
            # âœ… GSCé›†è¨ˆï¼ˆimpressions/clicksï¼‰ã¯ã€Œæ˜¨æ—¥ç· ã‚ã€ã«ä¸¸ã‚ã‚‹
            if rank_type in ("impressions", "clicks") and end_jst_date >= jst_date(now_jst):
                end_jst_date = end_jst_date - timedelta(days=1)
            # âœ… DBæœ€æ–°æ—¥ã«ã‚¯ãƒ©ãƒ³ãƒ—ï¼ˆæœªå–å¾—ãƒ»æœªç¢ºå®šæ—¥ã®é™¤å¤–ï¼‰
            if rank_type in ("impressions", "clicks") and latest_db_date:
                if end_jst_date and latest_db_date < end_jst_date:
                    end_jst_date = latest_db_date
                # startæœªæŒ‡å®šã‚„ start>end ã®å ´åˆã¯28æ—¥çª“ã‚’è£œå®Œ
                if (not start_jst_date) or (start_jst_date > end_jst_date):
                    start_jst_date = end_jst_date - timedelta(days=27)    
        except ValueError:
            return jsonify({"error": "æ—¥ä»˜å½¢å¼ãŒä¸æ­£ã§ã™ (YYYY-MM-DD)"}), 400
    else:
        if period == "all":
            start_jst_date, end_jst_date = None, None
        else:
            start_dt_jst = presets.get(period, now_jst - timedelta(days=90))  # ãƒ‡ãƒ•ã‚©ã¯3ã‹æœˆç›¸å½“
            # âœ… GSCé›†è¨ˆï¼ˆimpressions/clicksï¼‰ã¯æ˜¨æ—¥ã§ç· ã‚ã‚‹
            if rank_type in ("impressions", "clicks"):
                end_dt_jst   = now_jst - timedelta(days=1)
                # DBæœ€æ–°æ—¥ã§ã‚¯ãƒ©ãƒ³ãƒ—
                if latest_db_date and latest_db_date < jst_date(end_dt_jst):
                    end_dt_jst = datetime.combine(latest_db_date, datetime.min.time(), tzinfo=JST)
                start_jst_date = jst_date(start_dt_jst if start_dt_jst < end_dt_jst else end_dt_jst)
                end_jst_date   = jst_date(end_dt_jst)
            else:
                start_jst_date = jst_date(start_dt_jst)
                end_jst_date   = jst_date(now_jst)

    try:
        # ====== 1) ã‚µã‚¤ãƒˆæ•°ï¼ˆç·æ•°ï¼‰======
        if rank_type == "site":
            subq = (
                db.session.query(
                    User.id.label("user_id"),
                    User.last_name,
                    User.first_name,
                    func.count(Site.id).label("site_count")
                )
                .outerjoin(Site, Site.user_id == User.id)
                .group_by(User.id, User.last_name, User.first_name)
                .subquery()
            )
            rows = (
                db.session.query(subq.c.last_name, subq.c.first_name, subq.c.site_count)
                .order_by(sort_func(subq.c.site_count))
                .all()
            )
            data = [{"last_name": r.last_name, "first_name": r.first_name, "site_count": int(r.site_count or 0)} for r in rows]
            return Response(json.dumps(data, ensure_ascii=False), mimetype="application/json")

        # ====== 2) è¡¨ç¤ºå›æ•° / ã‚¯ãƒªãƒƒã‚¯æ•°ï¼šGSCMetricã‹ã‚‰æœŸé–“åˆç®— ======
                # ====== 2) è¡¨ç¤ºå›æ•° / ã‚¯ãƒªãƒƒã‚¯æ•°ï¼šGSCDailyTotal ã‹ã‚‰æœŸé–“SUM ======
        elif rank_type in ("impressions", "clicks"):
            metric_col = (
                func.coalesce(func.sum(GSCDailyTotal.impressions), 0)
                if rank_type == "impressions"
                else func.coalesce(func.sum(GSCDailyTotal.clicks), 0)
            ).label("value")

            # æœŸé–“ã¯ JST ã®æ—¥ä»˜ï¼ˆstart_jst_date / end_jst_dateï¼‰ãŒæ—¢ã«æ±ºã¾ã£ã¦ã„ã‚‹
            # GSCDailyTotal.date ã¯ Date ã‚«ãƒ©ãƒ ãªã®ã§ã€ãã®ã¾ã¾ inclusive ã§OK
            join_on = and_(
                GSCDailyTotal.site_id == Site.id,
                (GSCDailyTotal.date >= start_jst_date) if start_jst_date else True,
                (GSCDailyTotal.date <= end_jst_date) if end_jst_date else True,
            )

            q = (
                db.session.query(
                    Site.id.label("site_id"),
                    Site.name.label("site_name"),
                    Site.url.label("site_url"),
                    User.last_name,
                    User.first_name,
                    metric_col,
                )
                .join(User, Site.user_id == User.id)
                .outerjoin(GSCDailyTotal, join_on)
                .group_by(Site.id, Site.name, Site.url, User.last_name, User.first_name)
                .order_by(sort_func(metric_col))
            )

            rows = q.all()
            data = [
                {
                    "site_name": r.site_name,
                    "site_url": r.site_url,
                    "user_name": f"{r.last_name} {r.first_name}",
                    "value": int(r.value or 0),
                }
                for r in rows
            ]
            return Response(json.dumps(data, ensure_ascii=False), mimetype="application/json")


        # ====== 3) æŠ•ç¨¿å®Œäº†è¨˜äº‹æ•°ï¼šposted_at ã‚’JSTæœŸé–“ã§è¨ˆä¸Š ======
        elif rank_type == "posted_articles":
            # JSTæ—¥ä»˜ â†’ UTCã®å¢ƒç•Œã«å¤‰æ›ï¼ˆJST 00:00:00 ã‚’UTCã«ç›´ã™ï¼‰
            def jst_date_to_utc_start(d: datetime.date) -> datetime:
                # JST 00:00 -> UTCå‰æ—¥ 15:00
                return datetime(d.year, d.month, d.day, 0, 0, 0, tzinfo=JST).astimezone(timezone.utc)

            def jst_date_to_utc_end(d: datetime.date) -> datetime:
                # JST 23:59:59.999 -> ç¿Œæ—¥JST 00:00 ã®ç›´å‰ = UTCåŒæ—¥ 14:59:59.999...
                nxt = datetime(d.year, d.month, d.day, 0, 0, 0, tzinfo=JST) + timedelta(days=1)
                return nxt.astimezone(timezone.utc)

            q = (
                db.session.query(
                    Site.name.label("site_name"),
                    Site.url.label("site_url"),
                    User.last_name,
                    User.first_name,
                    func.count(Article.id).label("value")
                )
                .join(User, Site.user_id == User.id)
                .join(Article, Article.site_id == Site.id)
                .filter(Article.status == "posted")
            )

            if start_jst_date:
                q = q.filter(Article.posted_at >= jst_date_to_utc_start(start_jst_date))
            if end_jst_date:
                q = q.filter(Article.posted_at <  jst_date_to_utc_end(end_jst_date))  # endã¯ç¿Œæ—¥0æ™‚æœªæº€ã§é–‰åŒºé–“ç›¸å½“

            q = (
                q.group_by(Site.id, Site.name, Site.url, User.last_name, User.first_name)
                 .order_by(sort_func(func.count(Article.id)))
            )
            rows = q.all()
            data = [{
                "site_name": r.site_name,
                "site_url": r.site_url,
                "user_name": f"{r.last_name} {r.first_name}",
                "value": int(r.value or 0),
            } for r in rows]
            return Response(json.dumps(data, ensure_ascii=False), mimetype="application/json")

        else:
            return jsonify({"error": "ä¸æ­£ãªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¿ã‚¤ãƒ—ã§ã™"}), 400

    except Exception as e:
        current_app.logger.exception("[admin_rankings] server error")
        return jsonify({"error": "server_error", "detail": str(e)}), 500


@admin_bp.route("/admin/ranking-page")
@admin_required_effective
def admin_ranking_page():
    if not getattr(current_user, "is_admin", False):
        return redirect(url_for("main.dashboard", username=current_user.username))
    return render_template("admin/ranking_page.html")



# ç›£è¦–ãƒšãƒ¼ã‚¸
@admin_bp.route("/admin/monitoring")
@admin_required_effective
def admin_monitoring():

    memory = get_memory_usage()
    cpu = get_cpu_load()
    restart_logs = get_latest_restart_log()
    last_restart = get_last_restart_time()

    return render_template("admin/monitoring.html",
                           memory=memory,
                           cpu=cpu,
                           restart_logs=restart_logs,
                           last_restart=last_restart)


@admin_bp.route("/admin/captcha-dataset", methods=["POST"])
@admin_required_effective
def admin_captcha_label_update():
    from pathlib import Path

    image_file = request.form.get("image_file")
    new_label = request.form.get("label", "").strip()

    if not image_file or not new_label:
        return "ç„¡åŠ¹ãªå…¥åŠ›", 400

    dataset_dir = Path("data/captcha_dataset")
    txt_path = dataset_dir / Path(image_file).with_suffix(".txt")

    try:
        txt_path.write_text(new_label, encoding="utf-8")
        flash(f"{image_file} ã®ãƒ©ãƒ™ãƒ«ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚", "success")
    except Exception as e:
        flash(f"ãƒ©ãƒ™ãƒ«æ›´æ–°å¤±æ•—: {e}", "danger")

    return redirect(url_for("admin.admin_captcha_dataset"))

@admin_bp.route("/admin/captcha-dataset", methods=["GET"])
@admin_required_effective
def admin_captcha_dataset():
    from pathlib import Path
    from flask import render_template

    # âœ… å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿
    dataset_dir = Path("data/captcha_dataset")
    dataset_entries = []
    for path in sorted(dataset_dir.glob("*.png")):
        label_path = path.with_suffix(".txt")
        label = label_path.read_text(encoding="utf-8").strip() if label_path.exists() else ""
        dataset_entries.append({
            "image_file": path.name,
            "image_url": url_for('static', filename=f"../data/captcha_dataset/{path.name}"),
            "label": label
        })

    # âœ… æœ¬ç•ªä¿å­˜å¤±æ•—ç”»åƒï¼ˆapp/static/captchasï¼‰
    captchas_dir = Path("app/static/captchas")
    captcha_entries = []
    for path in sorted(captchas_dir.glob("*.png")):
        captcha_entries.append({
            "image_file": path.name,
            "image_url": url_for('static', filename=f"captchas/{path.name}"),
            "label": "ï¼ˆæœªè¨­å®šï¼‰"
        })

    # âœ… çµåˆã—ã¦ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¸æ¸¡ã™
    entries = dataset_entries + captcha_entries

    return render_template("admin/captcha_dataset.html", entries=entries)

# å†…éƒ¨SEOãƒ«ãƒ¼ãƒˆã‚³ãƒ¼ãƒ‰

# å†…éƒ¨SEOãƒ«ãƒ¼ãƒˆã‚³ãƒ¼ãƒ‰ï¼ˆadmin_bp é…ä¸‹ï¼‰
import os
from datetime import datetime, timedelta, timezone
from flask import render_template, request, redirect, url_for, flash, abort, jsonify, make_response
from flask_login import login_required, current_user
from sqlalchemy import desc, and_, or_, func
from sqlalchemy.orm import load_only, defer
from sqlalchemy import text

from app import db
from app.models import (
    Site,
    InternalSeoRun,
    InternalLinkAction,
    ContentIndex,
    User,
    InternalSeoUserSchedule,
    InternalSeoUserRun,
)
from sqlalchemy import func, and_, desc, text

# ğŸ†• å†…éƒ¨SEOã‚µãƒ¼ãƒ“ã‚¹ï¼ˆplanner / applierï¼‰
from app.services.internal_seo.applier import (
    preview_apply_for_post,
    apply_actions_for_post,
)
from app.services.internal_seo.planner import (
    plan_links_for_post,
)

# ğŸ†• ãƒ¦ãƒ¼ã‚¶ãƒ¼å˜ä½ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ï¼ˆã‚µãƒ¼ãƒ“ã‚¹å±¤ï¼‰
try:
    # å…ˆã«ä½œæˆã—ãŸ app/services/internal_seo/user_scheduler.py
    from app.services.internal_seo.user_scheduler import (
        enqueue_user_tick,
        run_user_tick,  # run_once ç”¨
    )
except Exception:
    # é–‹ç™ºä¸­ã§ã‚‚ routes ã® import ã§è½ã¡ãªã„ã‚ˆã†ã«ä¿é™º
    enqueue_user_tick = None
    run_user_tick = None

JST = timezone(timedelta(hours=9))


# ---- stats: 1ãƒ©ãƒ³åˆ†ã®è©³ç´° ----
@admin_bp.route("/admin/internal-seo/run/<int:run_id>/stats", methods=["GET"])
@admin_required_effective
def admin_internal_seo_run_stats(run_id: int):
    
    run = InternalSeoRun.query.get_or_404(run_id)
    payload = {"ok": True, "stats": run.stats or {}}
    resp = make_response(jsonify(payload))
    resp.headers["Cache-Control"] = "public, max-age=30"
    return resp

# ---- ç”»é¢æœ¬ä½“ ----
@admin_bp.route("/admin/internal-seo", methods=["GET"])
@admin_required_effective
def admin_internal_seo_index():

    # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆKPI + é€²æ— + ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ­ã‚°ï¼‰
    days = request.args.get("days", default=7, type=int)
    return render_template("admin/internal_seo.html", days=days)

# ---- æ¦‚è¦ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆç·æ•° / é©ç”¨æ¸ˆã¿ / ã‚­ãƒ¥ãƒ¼ / ç›´è¿‘ãƒ©ãƒ³ï¼‰----
@admin_bp.route("/admin/internal-seo/overview", methods=["GET"])
@admin_required_effective
def admin_internal_seo_overview():
    

    # ç·ã‚µã‚¤ãƒˆæ•°
    total_sites = Site.query.count()

    # 1ä»¶ä»¥ä¸Š "applied" ã®å†…éƒ¨ãƒªãƒ³ã‚¯ãŒã‚ã‚‹ã‚µã‚¤ãƒˆæ•°
    applied_sites = (
        db.session.query(InternalLinkAction.site_id)
        .filter(InternalLinkAction.status == "applied")
        .distinct()
        .count()
    )

    # ã‚¸ãƒ§ãƒ–ã‚­ãƒ¥ãƒ¼çŠ¶æ³
    rows = db.session.execute(
        text("SELECT status, COUNT(*) AS cnt FROM internal_seo_job_queue GROUP BY status")
    ).mappings().all()
    queue_summary = {r["status"]: int(r["cnt"]) for r in rows}

    # ç›´è¿‘ãƒ©ãƒ³ï¼ˆ20ä»¶ï¼‰
    recent_runs = (
        InternalSeoRun.query
        .order_by(InternalSeoRun.id.desc())
        .limit(20)
        .all()
    )

    return render_template(
        "admin/internal_seo_overview.html",
        total_sites=total_sites,
        applied_sites=applied_sites,
        queue_summary=queue_summary,
        recent_runs=recent_runs,
    )


@admin_bp.route("/admin/internal-seo/preview", methods=["GET"])
def admin_internal_seo_preview():
    """
    ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼ˆå®Ÿé©ç”¨ãªã—ï¼‰ã§ã€ã©ã®èªå¥ãŒã©ã®URLã«ãƒªãƒ³ã‚¯ã•ã‚Œã‚‹ã‹ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¿”ã™ã€‚
    ?site_id=...&post_id=...&format=json
    """
    site_id = request.args.get("site_id", type=int)
    post_id = request.args.get("post_id", type=int)
    fmt = (request.args.get("format") or "json").lower()
    if not site_id or not post_id:
        return jsonify({"ok": False, "error": "missing site_id or post_id"}), 400

    html, res, items = preview_apply_for_post(site_id, post_id)

    if fmt == "json":
        return jsonify({
            "ok": True,
            "result": {
                "applied": res.applied,
                "swapped": res.swapped,
                "skipped": res.skipped,
                "message": res.message,
            },
            "previews": [
                {
                    "position": it.position,
                    "anchor_text": it.anchor_text,
                    "target_post_id": it.target_post_id,
                    "target_url": it.target_url,
                    "paragraph_index": it.paragraph_index,
                    "paragraph_excerpt_before": it.paragraph_excerpt_before,
                    "paragraph_excerpt_after": it.paragraph_excerpt_after,
                }
                for it in items
            ],
        })
    elif fmt == "html":
        # HTMLãƒ“ãƒ¥ãƒ¼ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¯æ¬¡ã‚¹ãƒ†ãƒƒãƒ—ã§è¿½åŠ ï¼‰
        return render_template(
            "admin/internal_seo_preview.html",
            site_id=site_id,
            post_id=post_id,
            result=res,
            previews=items,
        )
    else:
        return jsonify({"ok": False, "error": "unsupported format"}), 400
    
# ---- ğŸ†• ç¾å½¹ãƒãƒ¼ã‚¸ãƒ§ãƒ³ / ä¸–ä»£é›†è¨ˆï¼ˆãƒã‚¹ãƒˆå˜ä½ï¼‰ ----
@admin_bp.route("/admin/internal-seo/post/<int:post_id>/versions", methods=["GET"])
@admin_required_effective
def admin_internal_seo_post_versions(post_id: int):
    """
    ç¾åœ¨ã® post_id ã«ã¤ã„ã¦ã€link_version ã®åˆ†å¸ƒã¨ç¾å½¹ï¼ˆmax appliedï¼‰ã‚’è¿”ã™ã€‚
    """
    site_row = (
        ContentIndex.query
        .with_entities(ContentIndex.site_id)
        .filter(ContentIndex.wp_post_id == post_id)
        .one_or_none()
    )
    if not site_row:
        return jsonify({"ok": False, "error": "post not found"}), 404
    site_id = int(site_row[0])

    # ãƒãƒ¼ã‚¸ãƒ§ãƒ³åˆ†å¸ƒ
    dist_rows = (
        db.session.query(
            InternalLinkAction.link_version,
            InternalLinkAction.status,
            func.count(InternalLinkAction.id),
        )
        .filter(
            InternalLinkAction.site_id == site_id,
            InternalLinkAction.post_id == post_id,
        )
        .group_by(InternalLinkAction.link_version, InternalLinkAction.status)
        .all()
    )
    dist = {}
    for ver, st, cnt in dist_rows:
        v = int(ver or 0)
        dist.setdefault(v, {})
        dist[v][st] = int(cnt or 0)

    # ç¾å½¹ï¼ˆapplied ã®æœ€å¤§ versionï¼‰
    current_row = (
        db.session.query(func.max(InternalLinkAction.link_version))
        .filter(
            InternalLinkAction.site_id == site_id,
            InternalLinkAction.post_id == post_id,
            InternalLinkAction.status == "applied",
        )
        .one()
    )
    current_version = int(current_row[0] or 0)
    return jsonify({"ok": True, "site_id": site_id, "post_id": post_id, "current_version": current_version, "distribution": dist})


# ---- ğŸ†• å†ãƒ“ãƒ«ãƒ‰ï¼ˆè¨ˆç”»ã®ã¿ï¼‰ ----
@admin_bp.route("/admin/internal-seo/rebuild/plan", methods=["POST"])
@admin_required_effective
def admin_internal_seo_rebuild_plan():
    """
    å…¨ç½®æ›ãƒ«ãƒ¼ãƒ«:
      - æ—§ max(link_version) ã‚’ç‰¹å®š
      - æ—§ 'applied' ã‚’ 'reverted' + reverted_at=now ã«æ›´æ–°ï¼ˆå±¥æ­´ä¿æŒï¼‰
      - æ–°è¦ 'pending' ã‚’ä½œæˆã—ã€link_version = æ—§max + 1 ã‚’ä»˜ä¸ï¼ˆplannerã§ç”Ÿæˆå¾Œã«ä»˜ä¸ï¼‰
    è¿”å´: æ–°è¦ pending ä»¶æ•°ã¨æ–°version
    """
    post_id = request.form.get("post_id", type=int) or (request.get_json(silent=True) or {}).get("post_id")
    if not post_id:
        return jsonify({"ok": False, "error": "post_id required"}), 400

    # post ã‹ã‚‰ site_id ã‚’è§£æ±º
    ci = (
        ContentIndex.query
        .with_entities(ContentIndex.site_id)
        .filter(ContentIndex.wp_post_id == post_id)
        .one_or_none()
    )
    if not ci:
        return jsonify({"ok": False, "error": "post not found"}), 404
    site_id = int(ci[0])

    now = datetime.utcnow()
    # æ—§ max ãƒãƒ¼ã‚¸ãƒ§ãƒ³
    old_max_row = (
        db.session.query(func.max(InternalLinkAction.link_version))
        .filter(
            InternalLinkAction.site_id == site_id,
            InternalLinkAction.post_id == post_id,
            InternalLinkAction.status.in_(["applied", "skipped", "pending", "reverted", "legacy_deleted"]),
        )
        .one()
    )
    old_max = int(old_max_row[0] or 0)
    new_version = old_max + 1

    # æ—¢å­˜ applied ã‚’ reverted ã«ï¼ˆå±¥æ­´ã¯æ®‹ã™ï¼‰
    db.session.query(InternalLinkAction)\
        .filter(
            InternalLinkAction.site_id == site_id,
            InternalLinkAction.post_id == post_id,
            InternalLinkAction.status == "applied",
        )\
        .update(
            {
                InternalLinkAction.status: "reverted",
                InternalLinkAction.reverted_at: now,
                InternalLinkAction.updated_at: now,
            },
            synchronize_session=False,
        )
    # æ—¢å­˜ pending ã¯ä¸€æ—¦æƒé™¤ï¼ˆå®Œå…¨ç½®æ›ã®ãŸã‚ï¼‰
    db.session.query(InternalLinkAction)\
        .filter(
            InternalLinkAction.site_id == site_id,
            InternalLinkAction.post_id == post_id,
            InternalLinkAction.status == "pending",
        ).delete(synchronize_session=False)
    db.session.commit()

    # planner ã§æ–°è¦ pending ã‚’ä½œæˆï¼ˆä½ç½®ã¯ h2:* ä»•æ§˜ï¼‰
    st = plan_links_for_post(
        site_id=site_id,
        src_post_id=post_id,
        mode_swap_check=False,  # å†ãƒ“ãƒ«ãƒ‰æ™‚ã¯ swap å€™è£œã¯ä¸è¦
    )

    # ç›´è¿‘ä½œæˆã® pending ã«æ–° version ã‚’ä»˜ä¸
    pending_q = (
        db.session.query(InternalLinkAction)
        .filter(
            InternalLinkAction.site_id == site_id,
            InternalLinkAction.post_id == post_id,
            InternalLinkAction.status == "pending",
        )
    )
    new_pending = pending_q.all()
    for a in new_pending:
        a.link_version = new_version
        a.updated_at = now
    db.session.commit()

    return jsonify({
        "ok": True,
        "site_id": site_id,
        "post_id": post_id,
        "planned": int(st.planned_actions or 0),
        "new_version": new_version,
    })


# ---- ğŸ†• å†ãƒ“ãƒ«ãƒ‰ï¼ˆé©ç”¨ã¾ã§ä¸€æ°—ã«ï¼‰ ----
@admin_bp.route("/admin/internal-seo/rebuild/apply", methods=["POST"])
@admin_required_effective
def admin_internal_seo_rebuild_apply():
    """
    plan ã¨åŒã˜æ‰‹é †ã§ä¸–ä»£ã‚’é€²ã‚ãŸä¸Šã§ã€applier ã‚’å®Ÿè¡Œã€‚
    ãƒ•ãƒ©ã‚° apply=true ã®ç°¡æ˜“ç‰ˆã¨ã—ã¦åˆ†é›¢ã€‚
    """
    post_id = request.form.get("post_id", type=int) or (request.get_json(silent=True) or {}).get("post_id")
    if not post_id:
        return jsonify({"ok": False, "error": "post_id required"}), 400

    # ã¾ãš planï¼ˆä¸Šã®é–¢æ•°ã‚’å†…éƒ¨å‘¼ã³å‡ºã—ã—ã¦ã‚‚ã„ã„ãŒã€åŒãƒ­ã‚¸ãƒƒã‚¯ã‚’è»½ãå†å®Ÿè£…ï¼‰
    plan_resp = admin_internal_seo_rebuild_plan()
    if isinstance(plan_resp, tuple):
        payload, code = plan_resp
        if code != 200:
            return plan_resp
        plan_data = payload.get_json() if hasattr(payload, "get_json") else {}
    else:
        plan_data = plan_resp.get_json() if hasattr(plan_resp, "get_json") else {}
    if not (plan_data or {}).get("ok"):
        return plan_resp

    # site_id è§£æ±º
    ci = (
        ContentIndex.query
        .with_entities(ContentIndex.site_id)
        .filter(ContentIndex.wp_post_id == post_id)
        .one_or_none()
    )
    site_id = int(ci[0]) if ci else None
    if not site_id:
        return jsonify({"ok": False, "error": "post not found"}), 404

    # applier å®Ÿè¡Œ
    res = apply_actions_for_post(site_id, post_id, dry_run=False)
    return jsonify({
        "ok": True,
        "site_id": site_id,
        "post_id": post_id,
        "applied": int(res.applied or 0),
        "swapped": int(res.swapped or 0),
        "skipped": int(res.skipped or 0),
        "legacy_deleted": int(getattr(res, "legacy_deleted", 0) or 0),
        "message": res.message or "",
        "new_version": plan_data.get("new_version"),
    })    
    

# ---- é€²æ—ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ Ã— ã‚µã‚¤ãƒˆï¼‰ ----
@admin_bp.route("/admin/internal-seo/progress", methods=["GET"])
@admin_required_effective
def admin_internal_seo_progress():
    """
    å„ãƒ¦ãƒ¼ã‚¶ãƒ¼ Ã— å„ã‚µã‚¤ãƒˆã®é€²æ—ï¼ˆæœŸé–“å†…ï¼‰
    - last_runï¼ˆç›´è¿‘å‡¦ç†æ—¥æ™‚ï¼‰
    - applied_links / skipped / removed_in_headings / legacy_removedï¼ˆæœŸé–“åˆè¨ˆï¼‰
    - queue_statusï¼ˆqueued/running/idleï¼‰
    """
    days = int(request.args.get("days", 7))
    since = (datetime.now(JST) - timedelta(days=days)).astimezone(timezone.utc)

    sql = text("""
      WITH site_info AS (
        SELECT s.id AS site_id, s.name AS site_name, s.user_id
        FROM site s
      ),
      user_info AS (
        SELECT u.id AS user_id, u.username
        FROM "user" u
      ),
      logs AS (
        SELECT
          l.site_id,
          l.status,
          COALESCE(l.applied_links, (l.details->>'applied_links')::int) AS applied_links,
          COALESCE(l.removed_in_headings, (l.details->>'removed_in_headings')::int) AS removed_in_headings,
          COALESCE(l.legacy_removed, (l.details->>'legacy_removed')::int) AS legacy_removed,
          l.created_at
        FROM internal_seo_job_log l
        WHERE l.created_at >= :since
      ),
      last_run AS (
        SELECT site_id, MAX(created_at) AS last_run_at
        FROM logs
        GROUP BY site_id
      ),
      agg AS (
        SELECT
          site_id,
          COALESCE(SUM(CASE WHEN status='applied' THEN applied_links ELSE 0 END),0) AS applied_links,
          COALESCE(SUM(CASE WHEN status='skipped' THEN 1 ELSE 0 END),0) AS skipped_count,
          COALESCE(SUM(removed_in_headings),0) AS removed_in_headings,
          COALESCE(SUM(legacy_removed),0)       AS legacy_removed
        FROM logs
        GROUP BY site_id
      ),
      qstat AS (
        SELECT site_id,
               MAX(CASE WHEN status='running' THEN 2
                        WHEN status='queued'  THEN 1
                        ELSE 0 END) AS st_rank
        FROM internal_seo_job_queue
        GROUP BY site_id
      )
      SELECT
        ui.user_id, ui.username,
        si.site_id, si.site_name,
        lr.last_run_at,
        COALESCE(a.applied_links,0)      AS applied_links,
        COALESCE(a.skipped_count,0)      AS skipped_count,
        COALESCE(a.removed_in_headings,0) AS removed_in_headings,
        COALESCE(a.legacy_removed,0)      AS legacy_removed,
        CASE COALESCE(q.st_rank,0)
          WHEN 2 THEN 'running'
          WHEN 1 THEN 'queued'
          ELSE 'idle'
        END AS queue_status
      FROM site_info si
      JOIN user_info ui ON ui.user_id = si.user_id
      LEFT JOIN last_run lr ON lr.site_id = si.site_id
      LEFT JOIN agg a      ON a.site_id  = si.site_id
      LEFT JOIN qstat q    ON q.site_id  = si.site_id
      ORDER BY ui.username ASC, si.site_name ASC
    """)
    rows = db.session.execute(sql, {"since": since}).mappings().all() or []

    data = []
    for r in rows:
        data.append({
            "user_id": r.get("user_id"),
            "username": r.get("username"),
            "site_id": r.get("site_id"),
            "site_name": r.get("site_name"),
            "last_run_at": (r.get("last_run_at").astimezone(JST).isoformat(timespec="seconds")
                            if r.get("last_run_at") else None),
            "applied_links": int(r.get("applied_links") or 0),
            "skipped_count": int(r.get("skipped_count") or 0),
            "removed_in_headings": int(r.get("removed_in_headings") or 0),
            "legacy_removed": int(r.get("legacy_removed") or 0),
            "queue_status": r.get("queue_status") or "idle",
        })
    return jsonify({"days": days, "rows": data})
    

# ---- NEW: ã‚ªãƒ¼ãƒŠãƒ¼ä¸€è¦§ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼‰ ----
@admin_bp.route("/admin/internal-seo/owners", methods=["GET"])
@admin_required_effective
def admin_internal_seo_owners():
    

    # Site.owner_id ã¾ãŸã¯ Site.user_id ã‚’å„ªå…ˆæ¡ç”¨
    owner_col = getattr(Site, "owner_id", None) or getattr(Site, "user_id", None)

    if owner_col is None:
        total_sites = db.session.query(func.count(Site.id)).scalar() or 0
        running_count = (
            db.session.query(func.count(func.distinct(InternalSeoRun.site_id)))
            .filter(InternalSeoRun.status == "running")
            .scalar() or 0
        )
        payload = {"ok": True, "rows": [
            {"id": None, "name": "å…¨ã‚µã‚¤ãƒˆ", "site_count": int(total_sites), "running_count": int(running_count)}
        ]}
        resp = make_response(jsonify(payload))
        resp.headers["Cache-Control"] = "public, max-age=30"
        return resp

    site_counts = (
        db.session.query(owner_col.label("owner_id"), func.count(Site.id).label("cnt"))
        .group_by(owner_col)
        .all()
    )
    running_counts = {
        owner_id: cnt
        for owner_id, cnt in (
            db.session.query(owner_col.label("owner_id"), func.count(func.distinct(InternalSeoRun.site_id)))
            .join(Site, Site.id == InternalSeoRun.site_id)
            .filter(InternalSeoRun.status == "running")
            .group_by(owner_col)
            .all()
        )
    }

    rows = []
    for r in site_counts:
        oid = r.owner_id
        rows.append(dict(
            id=(int(oid) if oid is not None else None),
            name=f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ {oid}" if oid is not None else "å…¨ã‚µã‚¤ãƒˆ",
            site_count=int(r.cnt or 0),
            running_count=int(running_counts.get(oid, 0)),
        ))

    payload = {"ok": True, "rows": rows}
    resp = make_response(jsonify(payload))
    resp.headers["Cache-Control"] = "public, max-age=30"
    return resp

# ---- ã‚µã‚¤ãƒˆä¸€è¦§ï¼ˆowner_id / æ¤œç´¢ / ã‚«ãƒ¼ã‚½ãƒ« / ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä»˜ãï¼‰ ----
# GET /admin/internal-seo/sites?q=&owner_id=&limit=&cursor_id=
@admin_bp.route("/admin/internal-seo/sites", methods=["GET"])
@admin_required_effective
def admin_internal_seo_sites():

    q = (request.args.get("q") or "").strip()
    owner_id = request.args.get("owner_id", type=int)
    limit = min(max(request.args.get("limit", type=int, default=24), 1), 200)
    cursor_id = request.args.get("cursor_id", type=int)

    base_q = Site.query
    owner_col = getattr(Site, "owner_id", None) or getattr(Site, "user_id", None)
    if owner_col is not None and owner_id is not None:
        base_q = base_q.filter(owner_col == owner_id)

    if q:
        if q.isdigit():
            base_q = base_q.filter(or_(Site.id == int(q), Site.name.ilike(f"%{q}%")))
        else:
            base_q = base_q.filter(Site.name.ilike(f"%{q}%"))

    if cursor_id:
        base_q = base_q.filter(Site.id > cursor_id)

    try:
        base_q = base_q.options(load_only(Site.id, Site.name))
    except Exception:
        base_q = base_q.options(load_only(Site.id))

    base_q = base_q.order_by(Site.id.asc())
    sites = base_q.limit(limit).all()

    site_ids = [s.id for s in sites]
    metrics_map = {}

    if site_ids:
        # InternalLinkAction ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥é›†è¨ˆ
        status_counts = (
            db.session.query(
                InternalLinkAction.site_id,
                InternalLinkAction.status,
                func.count(InternalLinkAction.id),
                func.max(InternalLinkAction.applied_at),
            )
            .filter(InternalLinkAction.site_id.in_(site_ids))
            .group_by(InternalLinkAction.site_id, InternalLinkAction.status)
            .all()
        )
        for sid in site_ids:
            metrics_map[sid] = dict(applied=0, pending=0, skipped=0, last_applied_at=None)

        for sid, st, cnt, max_applied in status_counts:
            if st == "applied":
                metrics_map[sid]["applied"] = int(cnt or 0)
                metrics_map[sid]["last_applied_at"] = max_applied
            elif st == "pending":
                metrics_map[sid]["pending"] = int(cnt or 0)
            elif st == "skipped":
                metrics_map[sid]["skipped"] = int(cnt or 0)

        # å®Ÿè¡Œä¸­ã‚µã‚¤ãƒˆ
        running_sites = {
            x[0] for x in db.session.query(InternalSeoRun.site_id)
            .filter(InternalSeoRun.site_id.in_(site_ids), InternalSeoRun.status == "running")
            .group_by(InternalSeoRun.site_id).all()
        }

        # ã‚µã‚¤ãƒˆæ¯ã®æœ€æ–°Run
        sub = (
            db.session.query(
                InternalSeoRun.site_id.label("sid"),
                func.max(InternalSeoRun.started_at).label("mx")
            )
            .filter(InternalSeoRun.site_id.in_(site_ids))
            .group_by(InternalSeoRun.site_id)
        ).subquery()

        last_runs = (
            db.session.query(
                InternalSeoRun.site_id,
                InternalSeoRun.status,
                InternalSeoRun.started_at,
                InternalSeoRun.ended_at,
                InternalSeoRun.duration_ms,
            )
            .join(sub, and_(InternalSeoRun.site_id == sub.c.sid, InternalSeoRun.started_at == sub.c.mx))
            .all()
        )

        for sid in site_ids:
            m = metrics_map.setdefault(sid, {})
            m["running"] = sid in running_sites

        for sid, st, st_at, ed_at, dur in last_runs:
            m = metrics_map.setdefault(sid, {})
            m.update(dict(
                last_run_status=st,
                last_run_started_at=st_at.isoformat() if st_at else None,
                last_run_ended_at=ed_at.isoformat() if ed_at else None,
                last_run_duration_ms=dur,
            ))

    def _row(site):
        m = metrics_map.get(site.id, {})
        return dict(
            id=site.id,
            name=getattr(site, "name", f"Site {site.id}") or f"Site {site.id}",
            metrics=dict(
                applied=int(m.get("applied") or 0),
                pending=int(m.get("pending") or 0),
                skipped=int(m.get("skipped") or 0),
                running=bool(m.get("running")),
                last_run_status=m.get("last_run_status"),
                last_run_started_at=m.get("last_run_started_at"),
                last_run_ended_at=m.get("last_run_ended_at"),
                last_run_duration_ms=m.get("last_run_duration_ms"),
            )
        )

    next_cursor_id = sites[-1].id if sites else None
    has_more = bool(sites) and (len(sites) == limit)

    return jsonify({
        "ok": True,
        "rows": [_row(s) for s in sites],
        "next_cursor_id": next_cursor_id,
        "has_more": has_more,
    })

# ---- å®Ÿè¡Œå±¥æ­´ï¼ˆã‚­ãƒ¼ã‚»ãƒƒãƒˆï¼‰ ----
@admin_bp.route("/admin/internal-seo/list", methods=["GET"])
@admin_required_effective
def admin_internal_seo_list():

    site_id = request.args.get("site_id", type=int)
    status  = request.args.get("status")  # e.g. 'error', 'success', 'running', 'queued'
    limit = min(max(request.args.get("limit", type=int, default=50), 1), 200)
    cursor_ts_str = request.args.get("cursor_ts")
    cursor_id = request.args.get("cursor_id", type=int)

    q = InternalSeoRun.query.options(
        load_only(
            InternalSeoRun.id,
            InternalSeoRun.site_id,
            InternalSeoRun.status,
            InternalSeoRun.job_kind,
            InternalSeoRun.started_at,
            InternalSeoRun.ended_at,
            InternalSeoRun.duration_ms,
        ),
        defer(InternalSeoRun.stats),
    )

    if site_id:
        q = q.filter(InternalSeoRun.site_id == site_id)
    # ä¾‹: /admin/internal-seo/list?status=error ã§å¤±æ•—ãƒ©ãƒ³ã®ã¿å–å¾—
    if status:
        # InternalSeoRun å´ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã§ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆ'running'|'success'|'error' ãªã©ï¼‰
        q = q.filter(InternalSeoRun.status == status)    

    q = q.order_by(desc(InternalSeoRun.started_at), desc(InternalSeoRun.id))

    if cursor_ts_str:
        try:
            cursor_ts = datetime.fromisoformat(cursor_ts_str.replace("Z", "+00:00"))
        except Exception:
            cursor_ts = None
        if cursor_ts is not None and cursor_id is not None:
            q = q.filter(
                or_(
                    InternalSeoRun.started_at < cursor_ts,
                    and_(InternalSeoRun.started_at == cursor_ts, InternalSeoRun.id < cursor_id),
                )
            )

    items = q.limit(limit).all()
    next_cursor_ts = items[-1].started_at.isoformat() if items else None
    next_cursor_id = items[-1].id if items else None
    has_more = bool(items) and (len(items) == limit)

    def _row(r):
        return dict(
            id=r.id,
            site_id=r.site_id,
            status=r.status,
            job_kind=r.job_kind,
            started_at=r.started_at.isoformat() if r.started_at else None,
            ended_at=r.ended_at.isoformat() if r.ended_at else None,
            duration_ms=r.duration_ms,
        )

    return jsonify(dict(
        ok=True,
        rows=[_row(r) for r in items],
        next_cursor_ts=next_cursor_ts,
        next_cursor_id=next_cursor_id,
        has_more=has_more,
    ))

# ---- å¤±æ•—ã‚¸ãƒ§ãƒ–ã®ä¸€æ‹¬ãƒªãƒˆãƒ©ã‚¤ï¼ˆerror -> queuedï¼‰â€»ä»»æ„API ----
@admin_bp.route("/admin/internal-seo/retry-failed", methods=["POST"])
@admin_required_effective
def admin_internal_seo_retry_failed():
    """
    internal_seo_job_queue ã® status='error' ã‚’ 'queued' ã«æˆ»ã™ã€‚
    - site_id ã‚’æŒ‡å®šã™ã‚Œã°ã€ãã®ã‚µã‚¤ãƒˆã ã‘ã‚’å¯¾è±¡ã«å†æŠ•å…¥ã§ãã‚‹ã€‚
    - running/queued ã®ã‚‚ã®ã¯å¯¾è±¡å¤–ã€‚
    è¿”å´: {"ok": true, "requeued": n}
    """

    site_id = None
    if request.is_json:
        site_id = (request.get_json(silent=True) or {}).get("site_id")
    if site_id is None:
        # ãƒ•ã‚©ãƒ¼ãƒ ã‹ã‚‰ã®POSTã‚‚è¨±å®¹
        site_id = request.form.get("site_id", type=int)
    try:
        if site_id is not None:
            res = db.session.execute(text("""
                UPDATE internal_seo_job_queue
                   SET status='queued', updated_at=now(), message=NULL, started_at=NULL, ended_at=NULL
                 WHERE status='error' AND site_id=:sid
            """), {"sid": int(site_id)})
        else:
            res = db.session.execute(text("""
                UPDATE internal_seo_job_queue
                   SET status='queued', updated_at=now(), message=NULL, started_at=NULL, ended_at=NULL
                 WHERE status='error'
            """))
        db.session.commit()
        cnt = int(res.rowcount or 0)
        return jsonify({"ok": True, "requeued": cnt})
    except Exception as e:
        db.session.rollback()
        return jsonify({"ok": False, "error": str(e)}), 500

# ---- æ‰‹å‹•å®Ÿè¡Œï¼ˆéåŒæœŸãƒˆãƒªã‚¬ï¼‰ ----
@admin_bp.route("/admin/internal-seo/run", methods=["POST"])
@admin_required_effective
def admin_internal_seo_run():

    site_id = request.form.get("site_id", type=int)
    if not site_id:
        flash("site_id ã¯å¿…é ˆã§ã™", "warning")
        return redirect(url_for("admin.admin_internal_seo_index"))

    def _env_int(key: str, default: int) -> int: return int(os.getenv(key, default))
    def _env_float(key: str, default: float) -> float: return float(os.getenv(key, default))

    pages         = request.form.get("pages",         type=int,   default=_env_int("INTERNAL_SEO_PAGES", 10))
    per_page      = request.form.get("per_page",      type=int,   default=_env_int("INTERNAL_SEO_PER_PAGE", 100))
    min_score     = request.form.get("min_score",     type=float, default=_env_float("INTERNAL_SEO_MIN_SCORE", 0.05))
    max_k         = request.form.get("max_k",         type=int,   default=_env_int("INTERNAL_SEO_MAX_K", 80))
    limit_sources = request.form.get("limit_sources", type=int,   default=_env_int("INTERNAL_SEO_LIMIT_SOURCES", 200))
    limit_posts   = request.form.get("limit_posts",   type=int,   default=_env_int("INTERNAL_SEO_LIMIT_POSTS", 50))
    incremental   = request.form.get("incremental", default="true").lower() != "false"

    db.session.execute(text("""
        INSERT INTO internal_seo_job_queue
          (site_id, pages, per_page, min_score, max_k, limit_sources, limit_posts,
           incremental, job_kind, status, created_at)
        VALUES
          (:site_id, :pages, :per_page, :min_score, :max_k, :limit_sources, :limit_posts,
           :incremental, 'admin-ui', 'queued', now())
    """), dict(
        site_id=site_id, pages=pages, per_page=per_page, min_score=min_score, max_k=max_k,
        limit_sources=limit_sources, limit_posts=limit_posts, incremental=incremental,
    ))
    db.session.commit()

    flash(f"Site {site_id} ã®å†…éƒ¨SEOã‚’ã‚¸ãƒ§ãƒ–ã‚­ãƒ¥ãƒ¼ã«ç™»éŒ²ã—ã¾ã—ãŸã€‚ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒé †æ¬¡å®Ÿè¡Œã—ã¾ã™ã€‚", "success")
    return redirect(url_for("admin.admin_internal_seo_index", site_id=site_id), code=303)

# ---- ã¾ã¨ã‚å®Ÿè¡Œï¼ˆâ€»ã“ã®UIã§ã¯å€‹åˆ¥å®Ÿè¡Œã‚’æ¨ã—ã€APIã¯äº’æ›ç¶­æŒï¼‰ ----
@admin_bp.route("/admin/internal-seo/run-batch", methods=["POST"])
@admin_required_effective
def admin_internal_seo_run_batch():

    if request.is_json:
        payload = request.get_json(silent=True) or {}
        site_ids = payload.get("site_ids") or payload.get("site_ids[]") or []
        params = payload
    else:
        site_ids = request.form.getlist("site_ids[]") or request.form.getlist("site_ids") or []
        params = request.form
    try:
        site_ids = [int(s) for s in site_ids if str(s).strip()]
    except Exception:
        return jsonify({"ok": False, "error": "invalid site_ids"}), 400
    if not site_ids:
        return jsonify({"ok": False, "error": "site_ids required"}), 400

    def _env_int(key: str, default: int) -> int: return int(os.getenv(key, default))
    def _env_float(key: str, default: float) -> float: return float(os.getenv(key, default))

    pages         = int(params.get("pages",         _env_int("INTERNAL_SEO_PAGES", 10)))
    per_page      = int(params.get("per_page",      _env_int("INTERNAL_SEO_PER_PAGE", 100)))
    min_score     = float(params.get("min_score",   _env_float("INTERNAL_SEO_MIN_SCORE", 0.05)))
    max_k         = int(params.get("max_k",         _env_int("INTERNAL_SEO_MAX_K", 80)))
    limit_sources = int(params.get("limit_sources", _env_int("INTERNAL_SEO_LIMIT_SOURCES", 200)))
    limit_posts   = int(params.get("limit_posts",   _env_int("INTERNAL_SEO_LIMIT_POSTS", 50)))
    incremental   = str(params.get("incremental", "true")).lower() != "false"

    existing_site_ids = {s.id for s in Site.query.with_entities(Site.id).filter(Site.id.in_(site_ids)).all()}
    enqueued, skipped, errors = 0, [], []

    for sid in site_ids:
        if sid not in existing_site_ids:
            skipped.append({"site_id": sid, "reason": "site-not-found"})
            continue
        try:
            db.session.execute(text("""
                INSERT INTO internal_seo_job_queue
                  (site_id, pages, per_page, min_score, max_k, limit_sources, limit_posts,
                   incremental, job_kind, status, created_at)
                VALUES
                  (:site_id, :pages, :per_page, :min_score, :max_k, :limit_sources, :limit_posts,
                   :incremental, 'admin-ui-batch', 'queued', now())
            """), dict(
                site_id=sid, pages=pages, per_page=per_page, min_score=min_score, max_k=max_k,
                limit_sources=limit_sources, limit_posts=limit_posts, incremental=incremental,
            ))
            enqueued += 1
        except Exception as e:
            errors.append({"site_id": sid, "error": str(e)})
    db.session.commit()

    return jsonify({"ok": True, "enqueued": enqueued, "skipped": skipped, "errors": errors})

# ---- å®¹é‡ãƒ¡ãƒ¼ã‚¿ãƒ¼ ----
@admin_bp.route("/admin/internal-seo/capacity", methods=["GET"])
@admin_required_effective
def admin_internal_seo_capacity():
    

    max_parallel = int(os.getenv("INTERNAL_SEO_WORKER_PARALLELISM", 3))

    running = db.session.execute(text("SELECT COUNT(*) FROM internal_seo_runs WHERE status='running'")).scalar() or 0
    queued = db.session.execute(text("SELECT COUNT(*) FROM internal_seo_job_queue WHERE status IN ('queued','running')")).scalar() or 0

    available = max(0, max_parallel - int(running))
    suggest_batch_size = min(available, 5)

    payload = {
        "ok": True,
        "max_parallel": int(max_parallel),
        "running": int(running),
        "queued": int(queued),
        "available": int(available),
        "suggest_batch_size": int(suggest_batch_size),
    }
    resp = make_response(jsonify(payload))
    resp.headers["Cache-Control"] = "no-cache, no-store"
    return resp

# ---- è©³ç´°ãƒ­ã‚°ï¼ˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼‰ ----
@admin_bp.route("/admin/internal-seo/actions", methods=["GET"])
@admin_required_effective
def admin_internal_seo_actions():
    
    site_id = request.args.get("site_id", type=int)
    post_id = request.args.get("post_id", type=int)
    status  = request.args.get("status")
    limit   = min(max(request.args.get("limit", type=int, default=50), 1), 100)

    cursor = request.args.get("cursor")
    cursor_ts = None
    cursor_id = None
    if cursor:
        try:
            ts_str, id_str = cursor.rsplit(".", 1)
            cursor_ts = datetime.fromisoformat(ts_str.replace("Z", "+00:00"))
            cursor_id = int(id_str)
        except Exception:
            cursor_ts = None
            cursor_id = None

    q = InternalLinkAction.query.options(
        load_only(
            InternalLinkAction.id,
            InternalLinkAction.site_id,
            InternalLinkAction.post_id,
            InternalLinkAction.target_post_id,
            InternalLinkAction.anchor_text,
            InternalLinkAction.position,
            InternalLinkAction.status,
            InternalLinkAction.applied_at,
            InternalLinkAction.diff_before_excerpt,
            InternalLinkAction.diff_after_excerpt,
        )
    )

    if site_id:
        q = q.filter(InternalLinkAction.site_id == site_id)
    if post_id:
        q = q.filter(InternalLinkAction.post_id == post_id)
    if status:
        q = q.filter(InternalLinkAction.status == status)

    q = q.order_by(desc(InternalLinkAction.applied_at), desc(InternalLinkAction.id))

    if cursor_ts is not None and cursor_id is not None:
        q = q.filter(
            or_(
                InternalLinkAction.applied_at < cursor_ts,
                and_(InternalLinkAction.applied_at == cursor_ts, InternalLinkAction.id < cursor_id),
            )
        )

    rows = q.limit(limit).all()

    post_ids   = {r.post_id for r in rows if r.post_id}
    target_ids = {r.target_post_id for r in rows if r.target_post_id}
    all_ids = list(post_ids | target_ids)
    url_map = {}
    if all_ids:
        cu = (
            ContentIndex.query
            .with_entities(ContentIndex.wp_post_id, ContentIndex.url)
            .filter(ContentIndex.wp_post_id.in_(all_ids))
            .all()
        )
        url_map = {int(pid): (url or "") for (pid, url) in cu}

    def _row(r: InternalLinkAction):
        return dict(
            id=r.id,
            site_id=r.site_id,
            post_id=r.post_id,
            post_url=url_map.get(r.post_id, ""),
            target_post_id=r.target_post_id,
            target_url=url_map.get(r.target_post_id, ""),
            anchor_text=r.anchor_text,
            position=r.position,
            status=r.status,
            applied_at=r.applied_at.isoformat() if r.applied_at else None,
            diff_before_excerpt=(r.diff_before_excerpt or "")[:280],
            diff_after_excerpt=(r.diff_after_excerpt or "")[:280],
        )

    next_cursor = None
    has_more = bool(rows) and (len(rows) == limit)
    if rows:
        last = rows[-1]
        ts = last.applied_at.isoformat() if last.applied_at else "1970-01-01T00:00:00+00:00"
        next_cursor = f"{ts}.{last.id}"

    return jsonify(dict(
        ok=True,
        rows=[_row(r) for r in rows],
        next_cursor=next_cursor,
        has_more=has_more,
    ))

# ---- å…¨ã‚µã‚¤ãƒˆä¸€æ‹¬ enqueueï¼ˆã¾ã  queued/running ã§ãªã„ã‚µã‚¤ãƒˆã®ã¿æŠ•å…¥ï¼‰----
@admin_bp.route("/admin/internal-seo/enqueue-all", methods=["POST"])
@admin_required_effective
def admin_internal_seo_enqueue_all():

    # å—ã‘å–ã‚Šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆæœªæŒ‡å®šãªã‚‰ .env / ç’°å¢ƒå¤‰æ•° â†’ æ—¢å®šå€¤ ã®é †ï¼‰
    def _env_int(key: str, default: int) -> int:
        try:
            return int(os.getenv(key, default))
        except Exception:
            return default

    def _env_float(key: str, default: float) -> float:
        try:
            return float(os.getenv(key, default))
        except Exception:
            return default

    # ãƒ•ãƒ­ãƒ³ãƒˆï¼ˆfetchï¼‰ã‹ã‚‰ JSON ã§ä»»æ„ã®æ—¢å®šå€¤ã‚’ä¸Šæ›¸ãå¯èƒ½
    params = request.get_json(silent=True) or {}
    pages         = int(params.get("pages",         _env_int("INTERNAL_SEO_PAGES", 10)))
    per_page      = int(params.get("per_page",      _env_int("INTERNAL_SEO_PER_PAGE", 100)))
    min_score     = float(params.get("min_score",   _env_float("INTERNAL_SEO_MIN_SCORE", 0.05)))
    max_k         = int(params.get("max_k",         _env_int("INTERNAL_SEO_MAX_K", 80)))
    limit_sources = int(params.get("limit_sources", _env_int("INTERNAL_SEO_LIMIT_SOURCES", 200)))
    limit_posts   = int(params.get("limit_posts",   _env_int("INTERNAL_SEO_LIMIT_POSTS", 50)))
    incremental   = str(params.get("incremental", "true")).lower() != "false"

    # ã™ã§ã« queued/running ã®ã‚µã‚¤ãƒˆã¯é™¤å¤–ã—ã¦ INSERT ... SELECT
    # â€» internal_seo_job_queue ã®å¿…é ˆã‚«ãƒ©ãƒ ã«åˆã‚ã›ã¦æ§‹æˆ
    sql = text("""
        INSERT INTO internal_seo_job_queue
          (site_id, pages, per_page, min_score, max_k, limit_sources, limit_posts,
           incremental, job_kind, status, created_at)
        SELECT
          s.id, :pages, :per_page, :min_score, :max_k, :limit_sources, :limit_posts,
          :incremental, 'admin-bulk', 'queued', NOW()
        FROM site s
        LEFT JOIN internal_seo_job_queue q
               ON q.site_id = s.id
              AND q.status IN ('queued','running')
        WHERE q.site_id IS NULL
    """)
    res = db.session.execute(sql, dict(
        pages=pages, per_page=per_page, min_score=min_score, max_k=max_k,
        limit_sources=limit_sources, limit_posts=limit_posts, incremental=incremental,
    ))
    db.session.commit()

    inserted = res.rowcount if res.rowcount is not None else 0
    return jsonify({"ok": True, "inserted": int(inserted)})

# ---- KPIï¼ˆå…¨ä½“ã‚µãƒãƒªï¼šç™»éŒ²/ã‚­ãƒ¥ãƒ¼/å®Ÿè¡Œ/æœ¬æ—¥ã®é©ç”¨/Hå†…é™¤å»/æ—§ä»•æ§˜å‰Šé™¤ï¼‰ ----
@admin_bp.route("/admin/internal-seo/kpis", methods=["GET"])
@admin_required_effective
def admin_internal_seo_kpis():
    days = int(request.args.get("days", 7))
    since = (datetime.now(JST) - timedelta(days=days)).astimezone(timezone.utc)

    # æ¦‚æ³ï¼ˆã‚µã‚¤ãƒˆæ•°/ã‚­ãƒ¥ãƒ¼/ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ï¼‰
    overview_sql = text("""
      SELECT
        (SELECT COUNT(*) FROM site) AS total_sites,
        (SELECT COUNT(*) FROM internal_seo_job_queue WHERE status='queued')  AS queued_sites,
        (SELECT COUNT(*) FROM internal_seo_job_queue WHERE status='running') AS running_sites
    """)
    overview = db.session.execute(overview_sql).mappings().first() or {}

    # é©ç”¨ãƒ»é™¤å»ã®é›†è¨ˆï¼ˆæœŸé–“åˆè¨ˆ + æœ¬æ—¥ï¼‰
    agg_sql = text("""
      WITH logs AS (
        SELECT
          l.id,
          l.status,
          COALESCE(l.applied_links, (l.details->>'applied_links')::int) AS applied_links,
          COALESCE(l.removed_in_headings, (l.details->>'removed_in_headings')::int) AS removed_in_headings,
          COALESCE(l.legacy_removed, (l.details->>'legacy_removed')::int) AS legacy_removed,
          l.created_at AT TIME ZONE 'UTC' AS created_utc
        FROM internal_seo_job_log l
        WHERE l.created_at >= :since
      )
      SELECT
        (SELECT COALESCE(SUM(applied_links),0)
           FROM logs
          WHERE status='applied'
            AND created_utc::date = (now() AT TIME ZONE 'UTC')::date) AS applied_today,
        (SELECT COALESCE(SUM(removed_in_headings),0) FROM logs) AS removed_in_h_total,
        (SELECT COALESCE(SUM(legacy_removed),0)       FROM logs) AS legacy_removed_total
    """)
    agg = db.session.execute(agg_sql, {"since": since}).mappings().first() or {}

    payload = {
        "total_sites": int(overview.get("total_sites") or 0),
        "queued_sites": int(overview.get("queued_sites") or 0),
        "running_sites": int(overview.get("running_sites") or 0),
        "applied_today": int(agg.get("applied_today") or 0),
        "removed_in_h_total": int(agg.get("removed_in_h_total") or 0),
        "legacy_removed_total": int(agg.get("legacy_removed_total") or 0),
        "days": days,
    }
    resp = make_response(jsonify(payload))
    resp.headers["Cache-Control"] = "no-cache, no-store"
    return resp

# ---- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ­ã‚°ï¼ˆå¢—åˆ†ï¼‰ ----
@admin_bp.route("/admin/internal-seo/logs", methods=["GET"])
@admin_required_effective
def admin_internal_seo_logs():
    """
    ã‚¯ã‚¨ãƒª:
      - limit: å–å¾—ä»¶æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ 50, æœ€å¤§ 200ï¼‰
      - since: ISO8601ï¼ˆJST/UTCå¯ï¼‰ã“ã‚Œä»¥é™ã®ãƒ­ã‚°ã‚’è¿”ã™
    è¿”å´: id é™é †ï¼ˆæ–°â†’å¤ï¼‰ã€‚ãƒ•ãƒ­ãƒ³ãƒˆã¯ä¸Šã«ç©ã‚€ã€‚
    """
    limit = min(int(request.args.get("limit", 50)), 200)
    since_str = request.args.get("since")
    since_dt = None
    if since_str:
        try:
            s = datetime.fromisoformat(since_str.replace("Z", "+00:00"))
            since_dt = s.astimezone(timezone.utc)
        except Exception:
            since_dt = None

    params = {"limit": limit}
    where_add = ""
    if since_dt:
        where_add = "AND l.created_at > :since"
        params["since"] = since_dt

    sql = text(f"""
      SELECT
        l.id,
        l.site_id,
        s.name     AS site_name,
        u.username AS username,
        l.status,
        COALESCE(l.reason, (l.details->>'reason')) AS reason,
        COALESCE(l.applied_links, (l.details->>'applied_links')::int) AS applied_links,
        COALESCE(l.removed_in_headings, (l.details->>'removed_in_headings')::int) AS removed_in_headings,
        COALESCE(l.legacy_removed, (l.details->>'legacy_removed')::int) AS legacy_removed,
        l.created_at
      FROM internal_seo_job_log l
      LEFT JOIN site  s ON s.id = l.site_id
      LEFT JOIN "user" u ON u.id = s.user_id
      WHERE 1=1
        {where_add}
      ORDER BY l.id DESC
      LIMIT :limit
    """)
    rows = db.session.execute(sql, params).mappings().all() or []

    out = []
    for r in rows:
        out.append({
            "id": int(r.get("id")),
            "site_id": r.get("site_id"),
            "site_name": r.get("site_name"),
            "username": r.get("username"),
            "status": r.get("status"),
            "reason": r.get("reason"),
            "applied_links": int(r.get("applied_links") or 0),
            "removed_in_headings": int(r.get("removed_in_headings") or 0),
            "legacy_removed": int(r.get("legacy_removed") or 0),
            "created_at": r.get("created_at").astimezone(JST).isoformat(timespec="seconds"),
        })
    return jsonify({"logs": out})


# ---------------------------------------------------------------------------
# ğŸ†• ç®¡ç†UI: ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥ å†…éƒ¨SEOã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ« å°ç·š & API
#    ãƒ‘ã‚¹ã¯ /admin/iseo/schedules/... ã«çµ±ä¸€ï¼ˆæ—¢å­˜ã® /admin/internal-seo/* ã¨åˆ†é›¢ï¼‰
# ---------------------------------------------------------------------------

@admin_bp.route("/admin/iseo/schedules")
@admin_required_effective
def admin_iseo_user_schedules_page():
    """
    ä¸€è¦§ãƒšãƒ¼ã‚¸ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¯åˆ¥PRã§ç”¨æ„ï¼‰
    """
    return render_template("admin/iseo_user_schedules.html")  # ãƒ†ãƒ³ãƒ—ãƒ¬ãŒç„¡ã‘ã‚Œã°ä¸€æ—¦ 500 ã§ã‚‚OK


def _get_or_create_user_schedule(uid: int) -> InternalSeoUserSchedule:
    sch = InternalSeoUserSchedule.query.filter_by(user_id=uid).one_or_none()
    if not sch:
        sch = InternalSeoUserSchedule(user_id=uid)
        from app import db
        db.session.add(sch)
        db.session.commit()
    return sch


@admin_bp.route("/admin/iseo/schedules/status")
@admin_required_effective
def admin_iseo_user_schedules_status():
    """
    ä¸€è¦§ãƒ†ãƒ¼ãƒ–ãƒ«ç”¨ã®JSONã€‚
    è¿”å´: pendingä»¶æ•° / çŠ¶æ…‹ / ã€Œé–‹å§‹æ¸ˆã¿ã€åˆ¤å®š / ç›´è¿‘å®Ÿè¡Œã®æ‰€è¦ / ç›´è¿‘7æ—¥ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ / äºˆæ¸¬æ¶ˆåŒ–æ—¥æ•° /
         ç´¯è¨ˆ applied/processedãƒ»å¹³å‡ãƒªãƒ³ã‚¯æ•°ãƒ»last_errorã€‚
    â€» äº’æ›ã®ãŸã‚ applied_24h / processed_24h ã‚‚å½“é¢è¿”ã™ï¼ˆåŒå€¤ã¾ãŸã¯åˆ¥é›†è¨ˆï¼‰ã€‚
    """
    from app import db
    from datetime import datetime, timedelta, timezone
    from sqlalchemy import func, text
    from app.models import User, Site, InternalSeoUserSchedule, InternalSeoUserRun
    now_utc = datetime.now(timezone.utc)
    since_7d = now_utc - timedelta(days=7)
    # å¯¾è±¡ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã€Œã‚µã‚¤ãƒˆã‚’1ã¤ä»¥ä¸ŠæŒã¤ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€ã‚’åŸºæœ¬ã«ã™ã‚‹
    user_rows = (
        db.session.query(
            User.id.label("user_id"),
            User.username,
            func.count(Site.id).label("site_cnt"),
        )
        .outerjoin(Site, Site.user_id == User.id)
        .group_by(User.id, User.username)
        .having(func.count(Site.id) > 0)
        .all()
    )

    # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«/ç›´è¿‘ãƒ©ãƒ³ã®ä»˜å¸¯æƒ…å ±
    result = []
    for u in user_rows:
        sch = InternalSeoUserSchedule.query.filter_by(user_id=u.user_id).one_or_none()
        last_run = (
            InternalSeoUserRun.query
            .filter_by(user_id=u.user_id)
            .order_by(InternalSeoUserRun.started_at.desc(), InternalSeoUserRun.id.desc())
            .first()
        )
        # ã€Œé–‹å§‹æ¸ˆã¿ã€åˆ¤å®šï¼ˆis_enabled ã‹ã¤ 1åº¦ã§ã‚‚å®Ÿè¡Œã—ãŸã“ã¨ãŒã‚ã‚‹ï¼‰
        is_started = bool(getattr(sch, "is_enabled", False) and (
            (last_run is not None) or getattr(sch, "last_run_at", None)
        ))
        # pending ä»¶æ•°ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼é…ä¸‹ã‚µã‚¤ãƒˆã® pending ã® distinct post_idï¼‰
        pending_cnt = db.session.execute(
            text("""
                SELECT COUNT(*) FROM (
                  SELECT DISTINCT a.post_id
                    FROM internal_link_actions a
                    JOIN site s ON s.id = a.site_id
                   WHERE s.user_id = :uid
                     AND a.status = 'pending'
                ) t
            """),
            {"uid": u.user_id}
        ).scalar() or 0
        # âœ… å…¨æœŸé–“ã®ç´¯è¨ˆï¼ˆæ™‚é–“æ¡ä»¶ã‚’å¤–ã™ï¼‰
        agg_all = (
            db.session.query(
                func.coalesce(func.sum(InternalSeoUserRun.applied), 0),
                func.coalesce(func.sum(InternalSeoUserRun.processed_posts), 0),
            )
            .filter(InternalSeoUserRun.user_id == u.user_id)
            .one()
        )
        applied_total = int(agg_all[0] or 0)
        processed_total = int(agg_all[1] or 0)

        # äº’æ›ï¼šå¾“æ¥ã®24hã‚­ãƒ¼ã¯å½“é¢è¿”ã™ï¼ˆå¿…è¦ã«å¿œã˜ã¦å¾Œã§å‰Šé™¤ï¼‰
        applied_24h = applied_total
        processed_24h = processed_total
        # ç›´è¿‘7æ—¥ã®å‡¦ç†è¨˜äº‹ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆï¼ˆå®Ÿç¸¾ãƒ™ãƒ¼ã‚¹ï¼‰
        agg_7d = (
            db.session.query(
                func.coalesce(func.sum(InternalSeoUserRun.processed_posts), 0)
            )
            .filter(
                InternalSeoUserRun.user_id == u.user_id,
                InternalSeoUserRun.started_at >= since_7d
            )
            .one()
        )
        throughput_7d = int(agg_7d[0] or 0)  # 7æ—¥é–“ã§å‡¦ç†ã—ãŸè¨˜äº‹æ•°
        avg_per_day = float(throughput_7d) / 7.0 if throughput_7d else 0.0
        # äºˆæ¸¬æ¶ˆåŒ–æ—¥æ•°ï¼špending ã‚’ 7æ—¥å¹³å‡/æ—¥ã®å‡¦ç†æ•°ã§å‰²ã‚‹ï¼ˆ0ãªã‚‰ Noneï¼‰
        pred_days = (float(pending_cnt) / avg_per_day) if avg_per_day > 0 else None

        # ç›´è¿‘å®Ÿè¡Œã®æ‰€è¦ï¼ˆåˆ†ï¼‰
        if last_run and getattr(last_run, "started_at", None) and getattr(last_run, "finished_at", None):
            dur_sec = (last_run.finished_at - last_run.started_at).total_seconds()
            duration_min = round(dur_sec / 60.0, 1)
        else:
            duration_min = None

        # å¹³å‡ãƒªãƒ³ã‚¯æ•°/è¨˜äº‹ï¼ˆç´¯è¨ˆï¼‰
        avg_links_per_post = (float(applied_total) / float(processed_total)) if processed_total > 0 else 0.0

        result.append({
            "user_id": u.user_id,
            "username": u.username,
            "sites": int(u.site_cnt or 0),
            "is_enabled": bool(getattr(sch, "is_enabled", False)),
            "is_started": is_started,
            "status": getattr(sch, "status", "idle") if sch else "idle",
            "last_run_at": getattr(sch, "last_run_at", None).isoformat() if sch and sch.last_run_at else None,
            "next_run_at": getattr(sch, "next_run_at", None).isoformat() if sch and sch.next_run_at else None,
            "tick_interval_sec": getattr(sch, "tick_interval_sec", None) if sch else None,
            "budget_per_tick": getattr(sch, "budget_per_tick", None) if sch else None,
            "rate_limit_per_min": getattr(sch, "rate_limit_per_min", None) if sch else None,
            "last_error": getattr(sch, "last_error", None) if sch else None,
            "pending": int(pending_cnt),
            # ç›´è¿‘7æ—¥ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã¨äºˆæ¸¬
            "throughput_7d": throughput_7d,
            "avg_per_day": avg_per_day,
            "pred_days": pred_days,
            # æ–°ï¼šå…¨æœŸé–“ç´¯è¨ˆ
            "applied_total": applied_total,
            "processed_total": processed_total,
            "avg_links_per_post": avg_links_per_post,
            # æ—§ï¼šå¾Œæ–¹äº’æ›ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ç§»è¡Œä¸­ã¯æ®‹ã™ï¼‰
            "applied_24h": applied_24h,
            "processed_24h": processed_24h,
            "last_result": {
                "status": getattr(last_run, "status", None) if last_run else None,
                "applied": getattr(last_run, "applied", None) if last_run else None,
                "processed_posts": getattr(last_run, "processed_posts", None) if last_run else None,
                "finished_at": getattr(last_run, "finished_at", None).isoformat() if last_run and last_run.finished_at else None,
                "duration_min": duration_min,
            },
        })
    return jsonify({"items": result})


def _parse_user_ids_from_request():
    data = request.get_json(silent=True) or {}
    ids = data.get("user_ids") or data.get("ids") or []
    # ãƒ•ã‚©ãƒ¼ãƒ POSTå¯¾å¿œ
    if not ids and "user_ids" in request.form:
        ids = request.form.getlist("user_ids")
    try:
        return [int(x) for x in ids]
    except Exception:
        return []


@admin_bp.route("/admin/iseo/schedules/bulk_enable", methods=["POST"])
@admin_required_effective
def admin_iseo_user_schedules_bulk_enable():
    """
    is_enabled=True, status=queued ã«ã—ã¦å³æ™‚1tickã‚’æŠ•å…¥
    """
    from app import db
    from flask import current_app
    from app.services.internal_seo.user_scheduler import run_user_tick
    app = current_app._get_current_object()
    ids = _parse_user_ids_from_request()
    if not ids:
        return jsonify({"ok": False, "error": "user_ids required"}), 400
    for uid in ids:
        sch = _get_or_create_user_schedule(uid)
        sch.is_enabled = True
        sch.status = "queued"
        db.session.add(sch)
    db.session.commit()
    # å³æ™‚ã«1å›ã ã‘åŒæœŸ tickï¼ˆè»½é‡ãƒ»å®‰å…¨ï¼‰
    for uid in ids:
        try:
            run_user_tick(app, uid, force=True)
        except Exception:
            current_app.logger.exception("[iseo] run_user_tick (bulk_enable) failed user_id=%s", uid)
    return jsonify({"ok": True, "enabled": ids})


@admin_bp.route("/admin/iseo/schedules/bulk_disable", methods=["POST"])
@admin_required_effective
def admin_iseo_user_schedules_bulk_disable():
    """
    å®Œå…¨åœæ­¢ï¼šis_enabled=False, status=idle, next_run_at=NULL
    """
    from app import db
    ids = _parse_user_ids_from_request()
    if not ids:
        return jsonify({"ok": False, "error": "user_ids required"}), 400
    q = InternalSeoUserSchedule.query.filter(InternalSeoUserSchedule.user_id.in_(ids))
    for sch in q.all():
        sch.is_enabled = False
        sch.status = "idle"
        sch.next_run_at = None
        db.session.add(sch)
    db.session.commit()
    return jsonify({"ok": True, "disabled": ids})


@admin_bp.route("/admin/iseo/schedules/bulk_pause", methods=["POST"])
@admin_required_effective
def admin_iseo_user_schedules_bulk_pause():
    """
    ä¸€æ™‚åœæ­¢ï¼šstatus=pausedï¼ˆis_enabledã¯ä¿æŒï¼‰
    """
    from app import db
    ids = _parse_user_ids_from_request()
    if not ids:
        return jsonify({"ok": False, "error": "user_ids required"}), 400
    q = InternalSeoUserSchedule.query.filter(InternalSeoUserSchedule.user_id.in_(ids))
    for sch in q.all():
        sch.status = "paused"
        db.session.add(sch)
    db.session.commit()
    return jsonify({"ok": True, "paused": ids})


@admin_bp.route("/admin/iseo/schedules/bulk_resume", methods=["POST"])
@admin_required_effective
def admin_iseo_user_schedules_bulk_resume():
    """
    å†é–‹ï¼šstatus=queued ã«æˆ»ã—ã€å³æ™‚ tick ã‚’æŠ•å…¥
    """
    from app import db
    from flask import current_app
    from app.services.internal_seo.user_scheduler import run_user_tick
    app = current_app._get_current_object()
    ids = _parse_user_ids_from_request()
    if not ids:
        return jsonify({"ok": False, "error": "user_ids required"}), 400
    q = InternalSeoUserSchedule.query.filter(InternalSeoUserSchedule.user_id.in_(ids))
    for sch in q.all():
        sch.status = "queued"
        db.session.add(sch)
    db.session.commit()
    # å³æ™‚ã«1å›ã ã‘åŒæœŸ tick
    for uid in ids:
        try:
            run_user_tick(app, uid, force=True)
        except Exception:
            current_app.logger.exception("[iseo] run_user_tick (bulk_resume) failed user_id=%s", uid)
    return jsonify({"ok": True, "resumed": ids})


@admin_bp.route("/admin/iseo/schedules/run_once", methods=["POST"])
@admin_required_effective
def admin_iseo_user_schedules_run_once():
    """
    å³æ™‚ã« 1 tick å®Ÿè¡Œï¼ˆis_enabled ç„¡è¦–ã§å˜ç™ºï¼‰
    """
    from flask import current_app
    from app.services.internal_seo.user_scheduler import run_user_tick
    app = current_app._get_current_object()
    uid = (request.get_json(silent=True) or {}).get("user_id") or request.form.get("user_id")
    try:
        uid = int(uid)
    except Exception:
        return jsonify({"ok": False, "error": "user_id required"}), 400
    # åŒæœŸå®Ÿè¡Œï¼ˆå®‰å…¨ãƒ»å³æ™‚ï¼‰
    try:
        res = run_user_tick(app, uid, force=True)
        # å®Ÿè¡Œç›´å¾Œã®æœ€æ–°ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å†é›†è¨ˆã—ã¦è¿”ã™ï¼ˆUIå³æ™‚åæ˜ ç”¨ï¼‰
        from app import db
        from sqlalchemy import func, text
        from app.models import InternalSeoUserRun, InternalSeoUserSchedule
        from datetime import datetime, timedelta, timezone
        now_utc = datetime.now(timezone.utc)
        since_24h = now_utc - timedelta(hours=24)

        pending_cnt = db.session.execute(
            text("""
                SELECT COUNT(*) FROM (
                  SELECT DISTINCT a.post_id
                    FROM internal_link_actions a
                    JOIN site s ON s.id = a.site_id
                   WHERE s.user_id = :uid
                     AND a.status = 'pending'
                ) t
            """),
            {"uid": uid}
        ).scalar() or 0

        agg_24h = (
            db.session.query(
                func.coalesce(func.sum(InternalSeoUserRun.applied), 0),
                func.coalesce(func.sum(InternalSeoUserRun.processed_posts), 0),
            )
            .filter(
                InternalSeoUserRun.user_id == uid,
                InternalSeoUserRun.started_at >= since_24h
            )
            .one()
        )
        applied_24h = int(agg_24h[0] or 0)
        processed_24h = int(agg_24h[1] or 0)

        sch = InternalSeoUserSchedule.query.filter_by(user_id=uid).one_or_none()
        last_error = getattr(sch, "last_error", None) if sch else None

        return jsonify({
            "ok": bool(res.get("ok", False)),
            "result": res,
            "pending": int(pending_cnt),
            "applied_24h": applied_24h,
            "processed_24h": processed_24h,
            "last_error": last_error,
        })
    except Exception as e:
        current_app.logger.exception("[iseo] run_user_tick failed: %s", e)
        return jsonify({"ok": False, "error": str(e)}), 500


@admin_bp.route("/admin/iseo/schedules/<int:user_id>/runs")
@admin_required_effective
def admin_iseo_user_runs(user_id: int):
    """
    ç›´è¿‘ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å®Ÿè¡Œå±¥æ­´ï¼ˆè»½é‡JSONï¼‰
    """
    from app.models import InternalSeoUserRun
    from sqlalchemy import func
    from datetime import datetime, timedelta, timezone
    now_utc = datetime.now(timezone.utc)
    since_24h = now_utc - timedelta(hours=24)
    q = (
        InternalSeoUserRun.query
        .filter_by(user_id=user_id)
        .order_by(InternalSeoUserRun.started_at.desc(), InternalSeoUserRun.id.desc())
        .limit(50)
    )
    items = [{
        "id": r.id,
        "status": r.status,
        "started_at": r.started_at.isoformat() if r.started_at else None,
        "finished_at": r.finished_at.isoformat() if r.finished_at else None,
        "applied": r.applied,
        "swapped": r.swapped,
        "skipped": r.skipped,
        "processed_posts": r.processed_posts,
    } for r in q.all()]
    # ç›´è¿‘24hã®åˆè¨ˆã‚‚ä¸€ç·’ã«è¿”ã™
    agg = (
        InternalSeoUserRun.query
        .with_entities(
            func.coalesce(func.sum(InternalSeoUserRun.applied), 0),
            func.coalesce(func.sum(InternalSeoUserRun.processed_posts), 0)
        )
        .filter(
            InternalSeoUserRun.user_id == user_id,
            InternalSeoUserRun.started_at >= since_24h
        )
        .one()
    )
    return jsonify({
        "user_id": user_id,
        "items": items,
        "applied_24h": int(agg[0] or 0),
        "processed_24h": int(agg[1] or 0),
    })

# ---- ğŸ†• é©ç”¨æ¸ˆã¿è¨˜äº‹ä¸€è¦§ï¼ˆãƒšãƒ¼ã‚¸æœ¬ä½“ï¼‰ ----
@admin_bp.route("/admin/iseo/applied_all", methods=["GET"])
@admin_required_effective
def admin_iseo_applied_all_page():
    # ä¸€è¦§ãƒšãƒ¼ã‚¸ã¯ user_id ã‚’å—ã‘å–ã‚Šã€ãƒ†ãƒ³ãƒ—ãƒ¬å´ã§æŒã¡å›ã™
    # â€» æœªæŒ‡å®šã§ã‚‚æç”»è‡ªä½“ã¯è¡Œã†ï¼ˆãƒ‡ãƒ¼ã‚¿APIå´ã§å¿…é ˆåŒ–ï¼‰
    user_id = request.args.get("user_id", type=int)
    return render_template("admin/iseo_applied_all.html", current_user_id=user_id)

# ---- ğŸ†• é©ç”¨æ¸ˆã¿è¨˜äº‹ä¸€è¦§ï¼šé›†è¨ˆãƒ‡ãƒ¼ã‚¿ï¼ˆè¨˜äº‹Ã—versionï¼‰ ----
@admin_bp.route("/admin/iseo/applied_all/data", methods=["GET"])
@admin_required_effective
def admin_iseo_applied_all_data():
    # ãƒ•ã‚£ãƒ«ã‚¿
    user_id = request.args.get("user_id", type=int)
    site_id = request.args.get("site_id", type=int)
    version = request.args.get("version", type=int)  # â† æœ€æ–°Versionã§ã®çµã‚Šè¾¼ã¿
    date_from = request.args.get("date_from")
    date_to   = request.args.get("date_to")
    limit = min(max(request.args.get("limit", default=50, type=int), 1), 200)

    # user_id ã¯å¿…é ˆã€‚æœªæŒ‡å®šãªã‚‰ 400
    if user_id is None:
        return jsonify({"ok": False, "error": "user_id required"}), 400

    # ã‚«ãƒ¼ã‚½ãƒ«ï¼ˆlast_applied_at, latest_ver ã®è¤‡åˆï¼‰
    cursor = request.args.get("cursor")  # "ISO8601.VER"
    cur_ts = None
    cur_ver = None
    if cursor:
        try:
            ts_s, ver_s = cursor.rsplit(".", 1)
            cur_ts = datetime.fromisoformat(ts_s.replace("Z", "+00:00"))
            cur_ver = int(ver_s)
        except Exception:
            cur_ts = None
            cur_ver = None

    params = {}
    params["user_id"] = user_id
    # å‹•çš„æ¡ä»¶ï¼ˆã“ã®æ®µéšã§ã¯ CTE å¾Œã®æœ€çµ‚SELECTã«é©ç”¨ï¼‰
    where_final = ["u.id = :user_id"]
    if site_id is not None:
        where_final.append("s.id = :site_id")
        params["site_id"] = site_id
    if version is not None:
        where_final.append("l.latest_ver = :version")
        params["version"] = version
    if date_from:
        where_final.append("l.last_applied_at >= :date_from")
        params["date_from"] = datetime.fromisoformat(f"{date_from}T00:00:00+00:00")
    if date_to:
        where_final.append("l.last_applied_at < :date_to")
        params["date_to"] = datetime.fromisoformat(f"{date_to}T23:59:59.999999+00:00")
    # ã‚«ãƒ¼ã‚½ãƒ«: (last_applied_at desc, latest_ver desc) ã® keyset
    if cur_ts is not None and cur_ver is not None:
        where_final.append("(l.last_applied_at < :cur_ts OR (l.last_applied_at = :cur_ts AND l.latest_ver < :cur_ver))")
        params["cur_ts"] = cur_ts
        params["cur_ver"] = cur_ver
    where_sql = " AND ".join(where_final) if where_final else "1=1"

    sql = text(f"""
      WITH latest AS (
        SELECT
          s.user_id,
          ila.site_id,
          ila.post_id,
          MAX(ila.link_version) AS latest_ver,
          MAX(ila.applied_at) FILTER (WHERE ila.status = 'applied') AS last_applied_at
        FROM internal_link_actions ila
        JOIN site s ON s.id = ila.site_id
        WHERE s.user_id = :user_id
        GROUP BY s.user_id, ila.site_id, ila.post_id
      )
      SELECT
        u.id   AS user_id,
        COALESCE(u.username, (u.last_name || u.first_name)) AS user_name,
        s.id   AS site_id,
        s.name AS site_name,
        ci.wp_post_id AS post_id,
        ci.title      AS src_title,
        ci.url        AS src_url,
        l.latest_ver  AS link_version,
        COUNT(a.*)    AS candidate_count,
        SUM(CASE WHEN a.status = 'applied' THEN 1 ELSE 0 END) AS applied_count,
        l.last_applied_at AS last_applied_at
      FROM latest l
      JOIN site s   ON s.id = l.site_id
      JOIN "user" u ON u.id = s.user_id
      LEFT JOIN content_index ci
        ON ci.site_id = l.site_id
       AND ci.wp_post_id = l.post_id
      LEFT JOIN internal_link_actions a
        ON a.site_id = l.site_id
       AND a.post_id = l.post_id
       AND a.link_version = l.latest_ver
      WHERE {where_sql}
      GROUP BY u.id, user_name, s.id, s.name, ci.wp_post_id, ci.title, ci.url, l.latest_ver, l.last_applied_at
      ORDER BY l.last_applied_at DESC NULLS LAST, l.latest_ver DESC
      LIMIT :limit
    """)
    params["limit"] = limit

    rows = db.session.execute(sql, params).mappings().all() or []

    def _row(r):
        return dict(
            user_id=r.get("user_id"),
            user_name=r.get("user_name"),
            site_id=r.get("site_id"),
            site_name=r.get("site_name"),
            post_id=r.get("post_id"),
            src_title=r.get("src_title"),
            src_url=r.get("src_url"),
            link_version=int(r.get("link_version") or 0),   # æœ€æ–°Version
            candidate_count=int(r.get("candidate_count") or 0),
            applied_count=int(r.get("applied_count") or 0),
            last_applied_at=(r.get("last_applied_at").isoformat() if r.get("last_applied_at") else None),
        )

    out_rows = [_row(r) for r in rows]
    # æ¬¡ã‚«ãƒ¼ã‚½ãƒ«
    next_cursor = None
    has_more = len(out_rows) == limit
    if has_more:
        last = out_rows[-1]
        next_cursor = f"{last['last_applied_at']}.{last['link_version']}"

    # ã‚µã‚¤ãƒˆã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼ˆãƒ‰ãƒ­ãƒƒãƒ—é–‹é–‰å¼ç”¨ï¼‰
    site_grouped = {}
    for r in out_rows:
        sid = r["site_id"]
        if sid not in site_grouped:
            site_grouped[sid] = {
                "site_id": sid,
                "site_name": r["site_name"],
                "articles": []
            }
        site_grouped[sid]["articles"].append(r)

    site_list = list(site_grouped.values())

    return jsonify({
        "ok": True,
        "rows": out_rows,
        "sites": site_list,
        "next_cursor": next_cursor,
        "has_more": has_more
    })


# ---- ğŸ†• æ˜ç´°ï¼šè¨˜äº‹Ã—version ã®ãƒªãƒ³ã‚¯ä¸€è¦§ ----
@admin_bp.route("/admin/iseo/applied_details", methods=["GET"])
@admin_required_effective
def admin_iseo_applied_details():
    site_id = request.args.get("site_id", type=int)
    post_id = request.args.get("post_id", type=int)
    version = request.args.get("version", type=int)
    if not (site_id and post_id and version is not None):
        return jsonify({"ok": False, "error": "site_id, post_id, version required"}), 400

    q = (
        InternalLinkAction.query
        .with_entities(
            InternalLinkAction.target_post_id,
            InternalLinkAction.anchor_text,
            InternalLinkAction.position,
            InternalLinkAction.applied_at,
            InternalLinkAction.status,
        )
        .filter_by(site_id=site_id, post_id=post_id, link_version=version)
        .filter(InternalLinkAction.status == "applied")
        .order_by(InternalLinkAction.applied_at.desc(), InternalLinkAction.id.desc())
    )
    rows = q.limit(500).all()

    # target_url è§£æ±º
    tgt_ids = [r[0] for r in rows if r[0]]
    url_map = {}
    if tgt_ids:
        for pid, url in (
            db.session.query(ContentIndex.wp_post_id, ContentIndex.url)
            .filter(ContentIndex.wp_post_id.in_(tgt_ids))
            .all()
        ):
            url_map[int(pid)] = url or ""

    items = []
    for tpid, atext, pos, ap_at, st in rows:
        items.append({
            "target_url": url_map.get(tpid, ""),
            "anchor_text": atext or "",
            "position": pos or "",
            "applied_at": ap_at.isoformat() if ap_at else None,
            "status": st or "",
        })
    return jsonify({"ok": True, "items": items})


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@bp.route("/<username>/keywords", methods=["GET", "POST"])
@login_required
def keywords(username):
    if current_user.username != username:
        abort(403)

    form = KeywordForm()

    user_sites = Site.query.filter_by(user_id=current_user.id).all()
    form.site_id.choices = [(0, "â€•â€• ã‚µã‚¤ãƒˆã‚’é¸æŠ â€•â€•")] + [(s.id, s.name) for s in user_sites]

    if form.validate_on_submit():
        site_id = form.site_id.data
        if site_id == 0:
            flash("ã‚µã‚¤ãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚", "danger")
            return redirect(url_for("main.keywords", username=username))

        lines = [line.strip() for line in form.keywords.data.splitlines() if line.strip()]
        for word in lines:
            keyword = Keyword(
                keyword=word,
                user_id=current_user.id,
                site_id=site_id
            )
            db.session.add(keyword)
        db.session.commit()
        flash(f"{len(lines)} ä»¶ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿½åŠ ã—ã¾ã—ãŸ", "success")
        return redirect(url_for("main.keywords", username=username, site_id=site_id))

    selected_site_id = request.args.get("site_id", type=int)
    status_filter = request.args.get("status")
    selected_site = Site.query.get(selected_site_id) if selected_site_id else None

    base_query = Keyword.query.filter_by(user_id=current_user.id)
    if selected_site_id:
        base_query = base_query.filter_by(site_id=selected_site_id)
    if status_filter == "used":
        base_query = base_query.filter_by(used=True)
    elif status_filter == "unused":
        base_query = base_query.filter_by(used=False)

    all_keywords = base_query.order_by(Keyword.site_id, Keyword.id.desc()).all()
    site_map = {s.id: s.name for s in user_sites}
    grouped_keywords = defaultdict(lambda: {"site_name": "", "keywords": [], "status_filter": status_filter})

    for kw in all_keywords:
        grouped_keywords[kw.site_id]["site_name"] = site_map.get(kw.site_id, "æœªè¨­å®š")
        grouped_keywords[kw.site_id]["keywords"].append(kw)

    return render_template(
        "keywords.html",
        form=form,
        selected_site=selected_site,
        sites=user_sites,
        grouped_keywords=grouped_keywords,
        site_map=site_map
    )


@bp.route("/api/keywords/<int:site_id>")
@login_required
def api_unused_keywords(site_id):
    offset = request.args.get("offset", 0, type=int)
    limit = 40
    keywords = Keyword.query.filter_by(user_id=current_user.id, site_id=site_id, used=False)\
        .order_by(Keyword.id.desc()).offset(offset).limit(limit).all()
    return jsonify([{"id": k.id, "keyword": k.keyword, "used": k.used} for k in keywords])


@bp.route("/api/keywords/all/<int:site_id>")
@login_required
def api_all_keywords(site_id):
    keywords = Keyword.query.filter_by(user_id=current_user.id, site_id=site_id)\
        .order_by(Keyword.id.desc()).limit(1000).all()
    return jsonify([{"id": k.id, "keyword": k.keyword} for k in keywords])


@bp.route("/<username>/keywords/edit/<int:keyword_id>", methods=["GET", "POST"])
@login_required
def edit_keyword(username, keyword_id):
    if current_user.username != username:
        abort(403)
    keyword = Keyword.query.get_or_404(keyword_id)
    if keyword.user_id != current_user.id:
        abort(403)

    form = EditKeywordForm(obj=keyword)
    form.site_id.choices = [(s.id, s.name) for s in Site.query.filter_by(user_id=current_user.id).all()]

    if form.validate_on_submit():
        keyword.keyword = form.keyword.data.strip()
        keyword.site_id = form.site_id.data
        db.session.commit()
        flash("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ›´æ–°ã—ã¾ã—ãŸ", "success")
        return redirect(url_for("main.keywords", username=username))

    return render_template("edit_keyword.html", form=form)


@bp.route("/<username>/keywords/view/<int:keyword_id>")
@login_required
def view_keyword(username, keyword_id):
    if current_user.username != username:
        abort(403)
    keyword = Keyword.query.get_or_404(keyword_id)
    if keyword.user_id != current_user.id:
        abort(403)
    return render_template("view_keyword.html", keyword=keyword)


@bp.route("/<username>/keywords/delete/<int:keyword_id>")
@login_required
def delete_keyword(username, keyword_id):
    if current_user.username != username:
        abort(403)
    keyword = Keyword.query.get_or_404(keyword_id)
    if keyword.user_id != current_user.id:
        abort(403)
    db.session.delete(keyword)
    db.session.commit()
    flash("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚", "success")
    return redirect(url_for("main.keywords", username=username))


@bp.post("/<username>/keywords/bulk-action")
@login_required
def bulk_action_keywords(username):
    if current_user.username != username:
        abort(403)
    action = request.form.get("action")
    keyword_ids = request.form.getlist("keyword_ids")

    if not keyword_ids:
        flash("å¯¾è±¡ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚", "warning")
        return redirect(request.referrer or url_for("main.keywords", username=username))

    if action == "delete":
        Keyword.query.filter(
            Keyword.id.in_(keyword_ids),
            Keyword.user_id == current_user.id
        ).delete(synchronize_session=False)
        db.session.commit()
        flash("é¸æŠã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚", "success")

    return redirect(request.referrer or url_for("main.keywords", username=username))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ chatgpt â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@bp.route("/<username>/chatgpt")
@login_required
def chatgpt(username):
    if current_user.username != username:
        abort(403)
    return render_template("chatgpt.html")




# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ èªè¨¼
@bp.route("/login", methods=["GET", "POST"])
def login():
    form = LoginForm()
    if form.validate_on_submit():
        identifier = form.identifier.data
        password = form.password.data

        user = User.query.filter(
            (User.email == identifier) | (User.username == identifier)
        ).first()

        if user and check_password_hash(user.password, password):
            login_user(user)
            flash("ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸï¼", "success")
            return redirect(url_for("main.dashboard", username=user.username))
        else:
            flash("ãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚", "danger")

    return render_template("login.html", form=form)

# æ—¢å­˜ import ã«è¿½åŠ 
from flask import render_template, request, redirect, url_for, flash, session, current_app
from werkzeug.security import generate_password_hash
import secrets, time, unicodedata
from app.models import User
from app import db
from sqlalchemy import func
from app.forms import RealNameEmailResetRequestForm, PasswordResetSimpleForm


def _norm_name(s: str) -> str:
    # å…¨è§’/åŠè§’ã®ã‚†ã‚‰ãå¸å + ç©ºç™½é™¤å»ï¼ˆåŠè§’/å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ä¸¡æ–¹ï¼‰
    if not s:
        return ""
    s = unicodedata.normalize("NFKC", s)
    return s.replace(" ", "").replace("\u3000", "")  # åŠè§’/å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹é™¤å»

@bp.route("/forgot-password", methods=["GET", "POST"])
def forgot_password_username_only():
    form = RealNameEmailResetRequestForm()
    if form.validate_on_submit():
        ln = form.last_name.data.strip()
        fn = form.first_name.data.strip()
        email = form.email.data.strip().lower()

        # ãƒ¡ãƒ¼ãƒ«ä¸€è‡´ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’å–å¾—ï¼ˆãƒ¡ãƒ¼ãƒ«ã¯å°æ–‡å­—æ¯”è¼ƒï¼‰
        user = User.query.filter(func.lower(User.email) == email).first()

        # æœ¬åä¸€è‡´ã‚’ã‚µãƒ¼ãƒå´ã§å³å¯†ãƒã‚§ãƒƒã‚¯ï¼ˆè¡¨è¨˜ã‚†ã‚Œã‚’è»½æ¸›ï¼‰
        if user and _norm_name(user.last_name) == _norm_name(ln) and _norm_name(user.first_name) == _norm_name(fn):
            grant = secrets.token_urlsafe(16)
            session["pw_reset_grant"] = {"uid": user.id, "grant": grant, "ts": time.time()}
            return redirect(url_for("main.reset_password_username_only", grant=grant))

        flash("æœ¬åã¨ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã®çµ„ã¿åˆã‚ã›ãŒç¢ºèªã§ãã¾ã›ã‚“ã§ã—ãŸã€‚", "danger")
        return render_template("forgot_username_only.html", form=form), 400

    return render_template("forgot_username_only.html", form=form)


# ---- Step2: æ–°ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰è¨­å®š
@bp.route("/reset-password-simple", methods=["GET", "POST"])
def reset_password_username_only():
    # TTLï¼ˆç§’ï¼‰â€¦æœªè¨­å®šãªã‚‰10åˆ†
    ttl = int(current_app.config.get("USERNAME_ONLY_RESET_TTL", 600))
    grant = request.args.get("grant") or request.form.get("grant")

    data = session.get("pw_reset_grant")
    if not data or data.get("grant") != grant or (time.time() - data.get("ts", 0)) > ttl:
        flash("æ“ä½œãŒç„¡åŠ¹ã¾ãŸã¯æœŸé™åˆ‡ã‚Œã§ã™ã€‚æœ€åˆã‹ã‚‰ã‚„ã‚Šç›´ã—ã¦ãã ã•ã„ã€‚", "danger")
        session.pop("pw_reset_grant", None)
        return redirect(url_for("main.forgot_password_username_only"))

    user = User.query.get(data["uid"])
    if not user:
        flash("ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚", "danger")
        session.pop("pw_reset_grant", None)
        return redirect(url_for("main.forgot_password_username_only"))

    form = PasswordResetSimpleForm()
    # hidden ã« grant ã‚’å…¥ã‚Œã‚‹
    if request.method == "GET":
        form.grant.data = grant

    if form.validate_on_submit():
        # ã“ã“ã¾ã§æ¥ã¦ã„ã‚Œã° EqualTo ã§ä¸€è‡´æ¤œè¨¼æ¸ˆã¿
        new_pw = form.password.data
        user.password = generate_password_hash(new_pw, method="pbkdf2:sha256", salt_length=16)
        db.session.commit()
        session.pop("pw_reset_grant", None)
        flash("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚æ–°ã—ã„ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã§ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„ã€‚", "success")
        return redirect(url_for("main.login"))

    return render_template("reset_username_only.html",
                           form=form, username=user.username, grant=grant)


@bp.route("/register", methods=["GET", "POST"])
def register():
    form = RegisterForm()
    if form.validate_on_submit():
        # ç™»éŒ²ç”¨ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒæ­£ã—ã„ã‹
        if form.register_key.data != "tcctool":
            flash("ç™»éŒ²å°‚ç”¨ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé–“é•ã£ã¦ã„ã¾ã™ã€‚", "danger")
            return render_template("register.html", form=form)

        # ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯
        if User.query.filter_by(email=form.email.data).first():
            flash("ã“ã®ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã¯æ—¢ã«ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã™ã€‚", "danger")
            return render_template("register.html", form=form)

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼åï¼ˆusernameï¼‰ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯
        if User.query.filter_by(username=form.username.data).first():
            flash("ã“ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¯ã™ã§ã«ä½¿ã‚ã‚Œã¦ã„ã¾ã™ã€‚", "danger")
            return render_template("register.html", form=form)

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆãƒ»ä¿å­˜
        new_user = User(
            email=form.email.data,
            password=generate_password_hash(form.password.data),
            username=form.username.data,
            user_type=form.user_type.data,
            company_name=form.company_name.data,
            company_kana=form.company_kana.data,
            last_name=form.last_name.data,
            first_name=form.first_name.data,
            last_kana=form.last_kana.data,
            first_kana=form.first_kana.data,
            postal_code=form.postal_code.data,
            address=form.address.data,
            phone=form.phone.data
        )
        db.session.add(new_user)
        db.session.commit()

        flash("ç™»éŒ²ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„ã€‚", "success")
        return redirect(url_for(".login"))

    return render_template("register.html", form=form)



@bp.route("/logout")
@login_required
def logout():
    logout_user()
    return redirect(url_for(".login"))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ« â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@bp.route("/<username>/profile", methods=["GET", "POST"])
@login_required
def profile(username):
    if current_user.username != username:
        abort(403)

    form = ProfileForm(obj=current_user)

    if form.validate_on_submit():
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼åãŒä»®åï¼ˆuser123ï¼‰ã®ã¾ã¾ã§ã€å¤‰æ›´ã•ã‚ŒãŸå ´åˆã®ã¿è¨±å¯
        if current_user.username.startswith("user") and form.username.data != current_user.username:
            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            if User.query.filter_by(username=form.username.data).first():
                flash("ã“ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¯ã™ã§ã«ä½¿ã‚ã‚Œã¦ã„ã¾ã™ã€‚", "danger")
                return render_template("profile.html", form=form)
            else:
                current_user.username = form.username.data

        # åŸºæœ¬æƒ…å ±ã®æ›´æ–°
        current_user.last_name  = form.last_name.data
        current_user.first_name = form.first_name.data
        current_user.last_kana  = form.last_kana.data
        current_user.first_kana = form.first_kana.data
        current_user.phone      = form.phone.data
        current_user.postal_code = form.postal_code.data
        current_user.address    = form.address.data  # â† çµ±åˆã•ã‚ŒãŸä½æ‰€ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«å¯¾å¿œ

        db.session.commit()
        flash("ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚", "success")

        return redirect(url_for("main.profile", username=current_user.username))

    return render_template("profile.html", form=form)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ãƒ„ãƒ¼ãƒ«æœ¬ä½“ã‚³ãƒ¼ãƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@bp.route("/")
@login_required
def root_redirect():
    return redirect(url_for("main.dashboard", username=current_user.username))


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Dashboard
from app.models import UserSiteQuota, Article, SiteQuotaLog, Site, User, GSCDailyTotal  # â† User ã‚’è¿½åŠ 
from app.utils.cache import cache_get_json, cache_set_json
from sqlalchemy import case, func  # â† func ã‚’è¿½åŠ 
from flask import g
from collections import defaultdict
from datetime import datetime, timedelta, timezone  # â† JSTè¨ˆç®—ã®ãŸã‚

@bp.route("/<username>/dashboard")
@login_required
def dashboard(username):
    if current_user.username != username:
        abort(403)

    user = current_user

    # ğŸ”¸ è¨˜äº‹çµ±è¨ˆï¼ˆSQL1ï¼‰
    article_stats = db.session.query(
        func.count(Article.id),
        func.sum(case((Article.status == "done", 1), else_=0)),
        func.sum(case((Article.status == "posted", 1), else_=0)),
        func.sum(case((Article.status == "error", 1), else_=0)),
        func.sum(case((Article.status.in_(["pending", "gen"]), 1), else_=0)),
    ).filter(Article.user_id == user.id).first()

    g.total_articles = article_stats[0]
    g.done = article_stats[1]
    g.posted = article_stats[2]
    g.error = article_stats[3]
    g.generating = article_stats[4]

    # ğŸ”¸ ãƒ—ãƒ©ãƒ³åˆ¥ã‚¯ã‚©ãƒ¼ã‚¿å–å¾—ï¼ˆSQL2ï¼‰
    quotas = UserSiteQuota.query.filter_by(user_id=user.id).all()

    # ğŸ”¸ ã‚µã‚¤ãƒˆä½¿ç”¨çŠ¶æ³ã‚’ä¸€æ‹¬å–å¾—ï¼ˆSQL3ï¼‰
    site_counts = db.session.query(
        Site.plan_type,
        func.count(Site.id)
    ).filter(Site.user_id == user.id).group_by(Site.plan_type).all()
    site_count_map = dict(site_counts)

    # ğŸ”¸ ãƒ­ã‚°ã‚’ä¸€æ‹¬å–å¾—ï¼ˆSQL4ï¼‰
    # ğŸ”¸ ãƒ­ã‚°ã‚’è»½é‡å–å¾—ï¼ˆå„ãƒ—ãƒ©ãƒ³æœ€å¤§10ä»¶ã¾ã§ï¼‰
    log_map = defaultdict(list)
    for plan in set([q.plan_type for q in quotas]):
        logs = SiteQuotaLog.query.filter_by(user_id=user.id, plan_type=plan) \
            .order_by(SiteQuotaLog.created_at.desc()) \
            .limit(10).all()
        log_map[plan] = logs


    # ğŸ”¸ ãƒ—ãƒ©ãƒ³åˆ¥æ§‹æˆ
    plans = {}
    for q in quotas:
        used = site_count_map.get(q.plan_type, 0)
        total = q.total_quota or 0
        remaining = max(total - used, 0)
        plans[q.plan_type] = {
            "used": used,
            "total": total,
            "remaining": remaining,
            "logs": log_map[q.plan_type]
        }

    total_quota = sum(q.total_quota for q in quotas)
    used_quota = sum(site_count_map.get(q.plan_type, 0) for q in quotas)
    remaining_quota = max(total_quota - used_quota, 0)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ç›´è¿‘28æ—¥ã®ã€Œè¡¨ç¤ºå›æ•°ï¼ã‚¯ãƒªãƒƒã‚¯æ•°ã€ã‚µã‚¤ãƒˆåˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆç®¡ç†ãƒšãƒ¼ã‚¸ã¨åŒã˜ï¼šJSTãƒ»å‰æ—¥ç· ã‚ï¼‰
    # âœ… çµ±ä¸€çª“
    start_date, end_date = _gsc_window_by_latest_db(28)
    rank_impr_28d = []
    rank_clicks_28d = []
    if end_date:
        # è¡¨ç¤ºå›æ•° Top50
        rank_impr_28d = (
            db.session.query(
                Site.id.label("site_id"),
                Site.name.label("site_name"),
                Site.url.label("site_url"),
                User.username.label("username"),
                func.coalesce(func.sum(GSCDailyTotal.impressions), 0).label("value"),
            )
            .join(GSCDailyTotal, GSCDailyTotal.site_id == Site.id)
            .join(User, User.id == Site.user_id)
            .filter(GSCDailyTotal.date >= start_date, GSCDailyTotal.date <= end_date)
            .group_by(Site.id, Site.name, Site.url, User.username)
            .order_by(func.coalesce(func.sum(GSCDailyTotal.impressions), 0).desc())
            .limit(50)
            .all()
        )
        # ã‚¯ãƒªãƒƒã‚¯æ•° Top50
        rank_clicks_28d = (
            db.session.query(
                Site.id.label("site_id"),
                Site.name.label("site_name"),
                Site.url.label("site_url"),
                User.username.label("username"),
                func.coalesce(func.sum(GSCDailyTotal.clicks), 0).label("value"),
            )
            .join(GSCDailyTotal, GSCDailyTotal.site_id == Site.id)
            .join(User, User.id == Site.user_id)
            .filter(GSCDailyTotal.date >= start_date, GSCDailyTotal.date <= end_date)
            .group_by(Site.id, Site.name, Site.url, User.username)
            .order_by(func.coalesce(func.sum(GSCDailyTotal.clicks), 0).desc())
            .limit(50)
            .all()
        )

    
    return render_template(
        "dashboard.html",
        gsc_win_start=start_date,
        gsc_win_end=end_date,
        plan_type=quotas[0].plan_type if quotas else "æœªå¥‘ç´„",
        total_quota=total_quota,
        used_quota=used_quota,
        remaining_quota=remaining_quota,
        total_articles=g.total_articles,
        done=g.done,
        posted=g.posted,
        error=g.error,
        plans=plans,
        # â–¼ ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç”¨ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ã®ã‚¿ãƒ–ã‹ã‚‰ä½¿ç”¨ï¼‰
        rank_impr_28d=rank_impr_28d,
        rank_clicks_28d=rank_clicks_28d,
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Error Details
from app.models import Error  # â† Error ãƒ¢ãƒ‡ãƒ«ã‚’è¿½åŠ 
from flask import render_template, request

@bp.route("/<username>/view_errors")
@login_required
def view_errors(username):
    if current_user.username != username:
        abort(403)

    # ãƒšãƒ¼ã‚¸ç•ªå·ã‚’å–å¾—
    page = request.args.get('page', 1, type=int)
    
    # ã‚¨ãƒ©ãƒ¼æƒ…å ±ã®å–å¾—ï¼ˆãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œï¼‰
    errors = Error.query.filter_by(user_id=current_user.id).order_by(Error.created_at.desc()).paginate(page=page, per_page=10)

    return render_template(
        "view_errors.html",
        errors=errors  # ã‚¨ãƒ©ãƒ¼è©³ç´°ã®ãƒªã‚¹ãƒˆã‚’ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«æ¸¡ã™
    )



@bp.route("/api/rankings")
@login_required
def api_rankings():
    # çŸ­æ™‚é–“ã§å¿…ãšå¿œç­”ã•ã›ã‚‹å®‰å…¨ç¶²ï¼ˆWebã ã‘ã€‚ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å†…ã§æœ‰åŠ¹ï¼‰
    try:
        db.session.execute("SET LOCAL statement_timeout = '5s'")
    except Exception:
        pass

    rank_type = (request.args.get("type") or "site").lower()
    limit = min(max(int(request.args.get("limit", 50)), 1), 50)

    # ---- Redisã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆã‚­ãƒ¼ã«â€œãƒ©ãƒ³ã‚­ãƒ³ã‚°ç¨®åˆ¥ï¼‹æœŸé–“â€ã‚’å«ã‚ã‚‹ï¼‰----
    from app import redis_client
    from flask import current_app
    import json
    from datetime import datetime, timezone, timedelta

    JST = timezone(timedelta(hours=9))
    today_jst = datetime.utcnow().replace(tzinfo=timezone.utc).astimezone(JST).date()
    end_date = today_jst - timedelta(days=1)         # å‰æ—¥ç· ã‚
    start_date = end_date - timedelta(days=27)       # 28æ—¥çª“
    cache_key = f"rankings:{rank_type}:{limit}:{start_date.isoformat()}:{end_date.isoformat()}"

    try:
        cached = redis_client.get(cache_key)
        if cached:
            return jsonify(json.loads(cached))
    except Exception as e:
        current_app.logger.warning(f"[rankings] redis GET failed: {e}")

    # ========== 1) ãƒ¦ãƒ¼ã‚¶ãƒ¼æ¯ã®ç™»éŒ²ã‚µã‚¤ãƒˆæ•°ãƒ©ãƒ³ã‚­ãƒ³ã‚° ==========
    if rank_type == "site":
        # ã“ã“ã¯ â€œã‚µã‚¤ãƒˆæ•°ï¼Siteã®ä»¶æ•°â€ ã‚’æ•°ãˆã‚‹ã ã‘ã€‚é‡ã„åˆ—ã¯æŒãŸãªã„ã€‚
        excluded_user_ids = [1, 2, 14, 24]

        # Site.user_id ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒå¿…è¦ï¼ˆä¸‹ã§ã‚³ãƒãƒ³ãƒ‰æ¡ˆã‚’å‡ºã—ã¾ã™ï¼‰
        subq = (
            db.session.query(
                User.id.label("user_id"),
                User.last_name,
                User.first_name,
                func.count(Site.id).label("site_count")
            )
            .filter(~User.id.in_(excluded_user_ids))
            .outerjoin(Site, Site.user_id == User.id)
            .group_by(User.id, User.last_name, User.first_name)
        ).subquery()

        rows = (
            db.session.query(
                subq.c.user_id,
                subq.c.last_name,
                subq.c.first_name,
                subq.c.site_count
            )
            .order_by(subq.c.site_count.desc())
            .limit(limit)
            .all()
        )

        data = [
            {
                "user_id": int(r.user_id),
                "last_name": r.last_name or "",
                "first_name": r.first_name or "",
                "site_count": int(r.site_count or 0),
            }
            for r in rows
        ]

        try:
            redis_client.setex(cache_key, 60, json.dumps(data))  # 60ç§’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        except Exception as e:
            current_app.logger.warning(f"[rankings] redis SETEX failed: {e}")
        return jsonify(data)

    # ========== 2) 28æ—¥åˆè¨ˆï¼šã‚µã‚¤ãƒˆåˆ¥ã®è¡¨ç¤ºå›æ•° or ã‚¯ãƒªãƒƒã‚¯æ•° ==========
    # ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ã¯ â€œå¿…è¦ãªåˆ—ã ã‘â€ å–ã‚Šå‡ºã™ã€‚é‡ã„åˆ—ï¼ˆbody, *_prompt ãªã©ï¼‰ã¯å‚ç…§ã—ãªã„ã€‚
    from app.models import GSCDailyTotal

    metric_col = GSCDailyTotal.impressions if rank_type in ("impressions", "impr") else GSCDailyTotal.clicks

    rows = (
        db.session.query(
            Site.id.label("site_id"),
            Site.name.label("site_name"),
            Site.url.label("site_url"),
            User.last_name.label("last_name"),
            User.first_name.label("first_name"),
            User.username.label("username"),
            func.coalesce(func.sum(metric_col), 0).label("value"),
        )
        .join(GSCDailyTotal, GSCDailyTotal.site_id == Site.id)
        .join(User, User.id == Site.user_id)
        .filter(~User.id.in_([1, 14, 24]))  # è¿½åŠ ï¼šID14ãƒ»24ã‚‚é™¤å¤–
        # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‹ã‚‰é™¤å¤–ã™ã‚‹ã‚µã‚¤ãƒˆå
        .filter(~Site.name.in_(["å¤©è‰ç”Ÿã†ã«æœ¬èˆ— ä¸¸å¥æ°´ç”£ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚·ãƒ§ãƒƒãƒ—"]))
        .filter(~Site.url.like("https://shopping-douko.com%"))
        .filter(GSCDailyTotal.date >= start_date, GSCDailyTotal.date <= end_date)
        .group_by(Site.id, Site.name, Site.url, User.last_name, User.first_name, User.username)
        .order_by(func.coalesce(func.sum(metric_col), 0).desc())
        .limit(limit)
        .all()
    )

    def _display_name(r):
        ln = (r.last_name or "").strip()
        fn = (r.first_name or "").strip()
        full = f"{ln}{fn}"
        return full if full else (r.username or "")

    data = [
        {
            "site_id": r.site_id,
            "site_name": r.site_name,
            "site_url": r.site_url,
            "last_name": r.last_name or "",
            "first_name": r.first_name or "",
            "name": _display_name(r),          # äº’æ›ã‚­ãƒ¼
            "display_name": _display_name(r),  # äº’æ›ã‚­ãƒ¼
            "username": r.username,
            "value": int(r.value or 0),
        }
        for r in rows
    ]

    try:
        redis_client.setex(cache_key, 60, json.dumps(data))
    except Exception as e:
        current_app.logger.warning(f"[rankings] redis SETEX failed: {e}")
    return jsonify(data)




# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ CRUDï¼ˆæ–°è¦ç™»éŒ²ã®ã¿ï¼‰
@bp.route("/<username>/prompts", methods=["GET", "POST"])
@login_required
def prompts(username):
    if current_user.username != username:
        abort(403)

    form = PromptForm()

    if form.validate_on_submit():
        db.session.add(PromptTemplate(
            genre    = form.genre.data,
            title_pt = form.title_pt.data,
            body_pt  = form.body_pt.data,
            user_id  = current_user.id
        ))
        db.session.commit()
        flash("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ", "success")
        return redirect(url_for(".prompts", username=username))

    plist = PromptTemplate.query.filter_by(user_id=current_user.id).all()
    return render_template("prompts.html", form=form, prompts=plist)



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç·¨é›†ãƒšãƒ¼ã‚¸ï¼ˆå°‚ç”¨ãƒšãƒ¼ã‚¸ï¼‰
@bp.route("/prompt/edit/<int:pid>", methods=["GET", "POST"])
@login_required
def edit_prompt(pid: int):
    pt = PromptTemplate.query.get_or_404(pid)
    if pt.user_id != current_user.id:
        abort(403)

    form = PromptForm(obj=pt)
    if form.validate_on_submit():
        pt.genre    = form.genre.data
        pt.title_pt = form.title_pt.data
        pt.body_pt  = form.body_pt.data
        db.session.commit()
        flash("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ›´æ–°ã—ã¾ã—ãŸ", "success")
        return redirect(url_for(".prompts", username=current_user.username))

    return render_template("prompt_edit.html", form=form, prompt=pt)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå‰Šé™¤
@bp.post("/prompts/delete/<int:pid>")
@login_required
def delete_prompt(pid: int):
    pt = PromptTemplate.query.get_or_404(pid)
    if pt.user_id != current_user.id:
        abort(403)
    db.session.delete(pt)
    db.session.commit()
    flash("å‰Šé™¤ã—ã¾ã—ãŸ", "success")
    return redirect(url_for(".prompts", username=current_user.username))


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå–å¾—APIï¼ˆè¨˜äº‹ç”Ÿæˆç”¨ï¼‰
@bp.route("/api/prompt/<int:pid>")
@login_required
def api_prompt(pid: int):
    pt = PromptTemplate.query.get_or_404(pid)
    if pt.user_id != current_user.id:
        abort(403)
    return jsonify({
        "title_pt": pt.title_pt,
        "body_pt": pt.body_pt
    })

@bp.route("/purchase-history")
@login_required
def purchase_history():
    user = current_user

    # SiteQuotaLogã‹ã‚‰ç™»éŒ²æ å±¥æ­´ï¼ˆã™ã¹ã¦ã®ãƒ—ãƒ©ãƒ³åˆ†ï¼‰
    logs = SiteQuotaLog.query.filter_by(user_id=user.id).order_by(SiteQuotaLog.created_at.desc()).all()

    return render_template("purchase_history.html", logs=logs)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ NEW: ãƒ¦ãƒ¼ã‚¶ãƒ¼ç”¨ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç”³è«‹ï¼ˆUIè£œåŠ©ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@bp.route("/<username>/index-monitor")
@login_required
def index_monitor(username):
    """
    è‡ªåˆ†ã®ã‚µã‚¤ãƒˆã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹çŠ¶æ³ã‚µãƒãƒªï¼ˆç›´è¿‘28æ—¥ï¼‰ï¼‹
    ç”³è«‹UIè£œåŠ©ï¼ˆGSCã§é–‹ããƒœã‚¿ãƒ³ï¼‰ã‚’æœ€é€Ÿè¡¨ç¤ºã€‚
    â€»GSC APIã¯å©ã‹ãšã€DBã®é›†è¨ˆå€¤ã®ã¿ã‚’ä½¿ã†ï¼ˆ1ç§’ä»¥å†…ï¼‰ã€‚
    """
    from datetime import date, timedelta
    from app.models import Site, Article, GSCDailyTotal, GSCConfig, User

    # èªå¯ï¼šè‡ªåˆ†ã®ãƒšãƒ¼ã‚¸ã®ã¿ï¼ˆç®¡ç†è€…ã®ä»£ç†ãƒ­ã‚°ã‚¤ãƒ³ã¯æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ã«æº–æ‹ ï¼‰
    if current_user.username != username and not (getattr(current_user, "is_admin", False) or session.get("admin_id")):
        flash("æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“ã€‚", "danger")
        return redirect(url_for("main.dashboard", username=current_user.username))

    date_28d_ago = date.today() - timedelta(days=28)

    # å¯¾è±¡ã‚µã‚¤ãƒˆï¼ˆè‡ªãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚µã‚¤ãƒˆã®ã¿ï¼‰
    sites = Site.query.filter_by(user_id=current_user.id).order_by(Site.id.asc()).all()
    site_ids = [s.id for s in sites]

    # æœ€æ–°ã® GSCConfigï¼ˆproperty_uriï¼‰ã‚’ã‚µã‚¤ãƒˆã”ã¨ã«1ä»¶å–å¾—ã™ã‚‹ã‚µãƒ–ã‚¯ã‚¨ãƒª
    # ï¼ˆé«˜é€Ÿï¼šã‚µã‚¤ãƒˆæ•°ãŒå¤šãã¦ã‚‚1ã‚¯ã‚¨ãƒªã§å–ã‚‹ï¼‰
    sub_cfg_max = (
        db.session.query(
            GSCConfig.site_id,
            func.max(GSCConfig.id).label("max_id")
        )
        .filter(GSCConfig.site_id.in_(site_ids))
        .group_by(GSCConfig.site_id)
        .subquery()
    )
    latest_cfg = {
        cfg.site_id: cfg.property_uri
        for cfg in db.session.query(GSCConfig)
                .join(sub_cfg_max, (GSCConfig.site_id == sub_cfg_max.c.site_id) & (GSCConfig.id == sub_cfg_max.c.max_id))
                .all()
    } if site_ids else {}

    # ç›´è¿‘28æ—¥é–“ã®GSCæ²è¼‰ï¼ˆã‚µã‚¤ãƒˆå˜ä½ã§ä½•æ—¥åˆ†ã®è¡ŒãŒã‚ã‚‹ã‹ï¼‰= æ²è¼‰ã®â€œå¼·ã•â€è¿‘ä¼¼
    sub_gsc = (
        db.session.query(
            GSCDailyTotal.site_id,
            func.count(GSCDailyTotal.id).label("indexed_days")  # è¡¨ç¤ºã®ã‚ã£ãŸæ—¥æ•°è¿‘ä¼¼
        )
        .filter(GSCDailyTotal.site_id.in_(site_ids), GSCDailyTotal.date >= date_28d_ago)
        .group_by(GSCDailyTotal.site_id)
        .subquery()
    )

    # ã‚µã‚¤ãƒˆåˆ¥ã‚µãƒãƒªï¼ˆè¨˜äº‹æ•°ãƒ»æ²è¼‰æ—¥æ•°è¿‘ä¼¼ãƒ»ç‡ï¼‰
    summary = []
    for s in sites:
        total_articles = db.session.query(func.count(Article.id)).filter(Article.site_id == s.id).scalar() or 0
        # å·¦å´ã® FROM ã‚’ sub_gsc ã«æ˜ç¤ºã—ã€è©²å½“ site_id ã§çµã‚Šè¾¼ã‚€ï¼ˆJOIN ã®æ›–æ˜§ã•ã‚’è§£æ¶ˆï¼‰
        indexed_days = (
            db.session.query(func.coalesce(sub_gsc.c.indexed_days, 0))
            .select_from(sub_gsc)
            .filter(sub_gsc.c.site_id == s.id)
            .scalar() or 0
        )
        rate = round((indexed_days / 28.0) * 100.0, 1) if 28 > 0 else 0.0
        summary.append({
            "site_id": s.id,
            "site_url": s.url,
            "gsc_connected": s.gsc_connected,
            "article_count": total_articles,
            "indexed_days": int(indexed_days),
            "rate": rate,
            "property_uri": latest_cfg.get(s.id)  # GSCæ¤œæŸ»URLã‚’ä½œã‚‹ã®ã«ä½¿ç”¨
        })

    # gsc_url_status ã«ã€Œindexed=TRUEã€ã®è¡ŒãŒã‚ã‚‹ URL ã¯é™¤å¤–ã—ã€
    # FALSE ã¾ãŸã¯ NULLï¼ˆï¼æœªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹/æœªæ¤œæŸ»ç›¸å½“ï¼‰ã®ã¿ã‚’å‡ºã™ã€‚
    # çµåˆã‚­ãƒ¼ã¯ article_id ãŒå…¥ã£ã¦ã„ã‚Œã°ãã‚Œã‚’å„ªå…ˆã—ã€ãªã‘ã‚Œã° (site_id, url) ã§ãƒãƒƒãƒã€‚
    from app.models import GSCUrlStatus  # æ—¢ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ¸ˆã¿ãªã‚‰ã“ã®è¡Œã¯è‡ªå‹•çš„ã«å†—é•·ã ãŒç„¡å®³

    recent_articles = (
        db.session.query(
            Article.id, Article.title, Article.posted_url, Article.site_id, Article.posted_at
        )
        # URLã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã¨å¤–éƒ¨çµåˆï¼ˆé‡è¤‡ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚Šå¾—ã‚‹ãŸã‚ã€å¾Œæ®µã§GROUP BYï¼‰
        .outerjoin(
            GSCUrlStatus,
            (
                (GSCUrlStatus.article_id == Article.id)
                | (
                    (GSCUrlStatus.site_id == Article.site_id)
                    & (GSCUrlStatus.url == Article.posted_url)
                )
            ),
        )
        .filter(
            Article.site_id.in_(site_ids),
            Article.posted_url.isnot(None),
            ((GSCUrlStatus.indexed == False) | (GSCUrlStatus.indexed.is_(None))),
        )
        # é‡è¤‡ã‚’é˜²ãï¼ˆPostgreSQLäº’æ›ï¼‰ï¼šè¡¨ç¤ºåˆ—ã§ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°
        .group_by(Article.id, Article.title, Article.posted_url, Article.site_id, Article.posted_at)
        .order_by(Article.posted_at.desc().nullslast(), Article.id.desc())
        .limit(50)
        .all()
    )

    # ğŸ”§ æ¤œæŸ»URLç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ï¼ˆæ¡ˆB: ã‚µãƒ¼ãƒå´ã§æ­£ç¢ºã«æ§‹ç¯‰ï¼‰
    from urllib.parse import quote

    for art in recent_articles:
        prop = latest_cfg.get(art.site_id)
        if not prop:
            inspect_url = None
        else:
            # property_uri ãŒ sc-domain: ã‹ URL ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‹ã§åˆ†å²
            # ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã¯éã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã€URLãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã¯ : / ã‚’ä¿æŒã—ã¦æ¸¡ã™
            if prop.startswith("sc-domain:"):
                resource_id = prop  # e.g. sc-domain:example.com
            else:
                p = prop if prop.endswith("/") else (prop + "/")
                resource_id = quote(p, safe=":/")  # å®Ÿè³ªãã®ã¾ã¾ã€: ã¨ / ã¯ä¿æŒ

            url_encoded = quote(art.posted_url or "", safe="")
            inspect_url = (
                f"https://search.google.com/search-console/inspect"
                f"?resource_id={resource_id}&url={url_encoded}&page=inspect"
            )
        # Row ã¯ä¸å¤‰ãªã®ã§ã€6è¦ç´ ã‚¿ãƒ—ãƒ«ã¸è©°ã‚æ›¿ãˆã‚‹
        # (id, title, url, site_id, posted_at, inspect_url)
        # å¾Œæ®µãƒ†ãƒ³ãƒ—ãƒ¬ã§ã“ã®é †åºã‚’ãã®ã¾ã¾ä½¿ã†
        pass

    # â†‘ã® pass ã¯ for ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹ãŸã‚ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ã§ã¯ãªã„ã®ã§æ³¨æ„ã€‚
    # å®Ÿéš›ã«ã¯ recent_articles ã‚’æ–°ã—ã„é…åˆ—ã«è©°ã‚æ›¿ãˆã‚‹ï¼š
    from urllib.parse import quote  # å¿µã®ãŸã‚ã‚¹ã‚³ãƒ¼ãƒ—ç¶­æŒ
    recent_articles_with_inspect = []
    for (aid, title, url, site_id, posted_at) in recent_articles:
        prop = latest_cfg.get(site_id)
        if prop and url:
            if prop.startswith("sc-domain:"):
                resource_id = prop  # éã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã§ãã®ã¾ã¾
            else:
                p = prop if prop.endswith("/") else (prop + "/")
                resource_id = quote(p, safe=":/")  # : / ã‚’ä¿æŒ
            inspect_url = (
                "https://search.google.com/search-console/inspect"
                "?resource_id={}&url={}&page=inspect"
            ).format(resource_id, quote(url, safe=""))
        else:
            inspect_url = None
        recent_articles_with_inspect.append((aid, title, url, site_id, posted_at, inspect_url))
 

    return render_template(
        "index_monitor.html",
        summary=summary,
        recent_articles=recent_articles_with_inspect,
        username=username,
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ç™»éŒ²ã‚µã‚¤ãƒˆç®¡ç† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

from os import getenv
from app.forms import SiteForm
from app.models import SiteQuotaLog
from app.services.internal_seo.enqueue import enqueue_new_site
from app.services.internal_seo.applier import preview_apply_for_post
from flask import render_template

@bp.route("/<username>/sites", methods=["GET", "POST"])
@login_required
def sites(username):
    if current_user.username != username:
        abort(403)

    form = SiteForm()
    user = current_user

    # âœ… ã‚¸ãƒ£ãƒ³ãƒ«ã®é¸æŠè‚¢ã‚’ã‚»ãƒƒãƒˆï¼ˆè‡ªåˆ†ãŒè¿½åŠ ã—ãŸã‚¸ãƒ£ãƒ³ãƒ«ã®ã¿ï¼‰
    genre_list = Genre.query.filter_by(user_id=current_user.id).order_by(Genre.name).all()
    form.genre_id.choices = [(0, "ã‚¸ãƒ£ãƒ³ãƒ«æœªé¸æŠ")] + [(g.id, g.name) for g in genre_list]

    # ğŸ”¹ ç™»éŒ²æ¸ˆã¿ã‚µã‚¤ãƒˆä¸€è¦§ã¨ä»¶æ•°
    site_list = Site.query.filter_by(user_id=user.id).all()

    # ğŸ”¹ ãƒ—ãƒ©ãƒ³ã”ã¨ã®ã‚¯ã‚©ãƒ¼ã‚¿ãƒ‡ãƒ¼ã‚¿
    quotas = UserSiteQuota.query.filter_by(user_id=user.id).all()

    # ğŸ”¹ ãƒ—ãƒ©ãƒ³ã”ã¨ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ä½¿ç”¨çŠ¶æ³ã¨å±¥æ­´ãƒ­ã‚°
    quota_by_plan = {}
    for q in quotas:
        plan = q.plan_type
        used = Site.query.filter_by(user_id=user.id, plan_type=plan).count()  # â† ğŸ”„ used_quotaã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ç®—å‡º
        total = q.total_quota or 0
        remaining = max(total - used, 0)
        logs = SiteQuotaLog.query.filter_by(user_id=user.id, plan_type=plan).order_by(SiteQuotaLog.created_at.desc()).all()

        quota_by_plan[plan] = {
            "total": total,
            "used": used,
            "remaining": remaining,
            "logs": logs
        }

    # ğŸ”¹ å…¨ä½“ã®ãƒˆãƒ¼ã‚¿ãƒ«æ•°ã¨æ®‹æ•°ã‚‚ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§çµ±ä¸€
    total_quota = sum([q.total_quota for q in quotas])
    used_quota = sum([Site.query.filter_by(user_id=user.id, plan_type=q.plan_type).count() for q in quotas])
    remaining_quota = total_quota - used_quota

    if form.validate_on_submit():
        if used_quota >= total_quota:
            flash("ã‚µã‚¤ãƒˆç™»éŒ²ä¸Šé™ã«é”ã—ã¦ã„ã¾ã™ã€‚è¿½åŠ ã™ã‚‹ã«ã¯èª²é‡‘ãŒå¿…è¦ã§ã™ã€‚", "danger")
            return redirect(url_for("main.sites", username=username))

        selected_plan = form.plan_type.data
        quota = UserSiteQuota.query.filter_by(user_id=user.id, plan_type=selected_plan).first()
        if quota:
            quota.used_quota = Site.query.filter_by(user_id=user.id, plan_type=selected_plan).count() + 1  # ğŸ”„æ›´æ–°ï¼ˆå¿µã®ãŸã‚ï¼‰
        else:
            flash("ãƒ—ãƒ©ãƒ³æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚", "danger")
            return redirect(url_for("main.sites", username=username))

        # â‘  ã¾ãšä½œæˆã—ã¦IDã‚’ç¢ºå®š
        new_site = Site(
            name       = form.name.data,
            url        = form.url.data.rstrip("/"),
            username   = form.username.data,
            app_pass   = form.app_pass.data,
            user_id    = user.id,
            plan_type  = selected_plan,
            genre_id   = form.genre_id.data if form.genre_id.data != 0 else None,  # âœ…
        )
        db.session.add(new_site)
        db.session.commit()  # â† ã“ã“ã§ new_site.id ãŒç¢ºå®š

        # â‘¡ ç™»éŒ²ç›´å¾Œã«å†…éƒ¨SEOã‚’enqueueï¼ˆéåŒæœŸãƒ¯ãƒ¼ã‚«ãƒ¼ãŒæ‹¾ã†ï¼‰
        try:
            enqueue_new_site(new_site.id)
            flash("ã‚µã‚¤ãƒˆã‚’ç™»éŒ²ã—ã¾ã—ãŸï¼ˆå†…éƒ¨SEOã®åˆæœŸå‡¦ç†ã‚’é–‹å§‹ã—ã¾ã—ãŸï¼‰", "success")
        except Exception as e:
            # enqueue ã«å¤±æ•—ã—ã¦ã‚‚ã‚µã‚¤ãƒˆç™»éŒ²è‡ªä½“ã¯æˆåŠŸã¨ã—ã¦æ‰±ã†ï¼ˆæ—¢å­˜æ©Ÿèƒ½ã‚’å£Šã•ãªã„ï¼‰
            current_app.logger.exception(f"[internal-seo] enqueue failed on site create: {e}")
            flash("ã‚µã‚¤ãƒˆã‚’ç™»éŒ²ã—ã¾ã—ãŸï¼ˆå†…éƒ¨SEOåˆæœŸå‡¦ç†ã®ç™»éŒ²ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å¾Œã‹ã‚‰ã‚„ã‚Šç›´ã›ã¾ã™ï¼‰", "warning")
        return redirect(url_for("main.sites", username=username))

    # ğŸ”¹ Stripeå±¥æ­´ï¼ˆå‚è€ƒè¡¨ç¤ºç”¨ï¼‰
    history_logs = PaymentLog.query.filter_by(user_id=user.id).order_by(PaymentLog.created_at.desc()).all()
# ğŸ” æœ€åˆã«å„ªå…ˆè¡¨ç¤ºã™ã‚‹ãƒ—ãƒ©ãƒ³ï¼ˆbusinesså„ªå…ˆï¼‰
    # ä¾‹ï¼šaffiliate ã‚’å„ªå…ˆã—ã¦åˆæœŸè¡¨ç¤ºã«ã™ã‚‹
    default_plan = "affiliate" if "affiliate" in quota_by_plan else "business"


    return render_template(
        "sites.html",
        form=form,
        sites=site_list,
        plans=quota_by_plan,
        remaining_quota=remaining_quota,  # âœ… â† å·¦ä¸Šã®è¡¨ç¤ºã«ä½¿ç”¨
        total_quota=total_quota,
        used_quota=used_quota,
        history_logs=history_logs,
        stripe_public_key=os.getenv("STRIPE_PUBLIC_KEY"),
        default_plan=default_plan  # â† ğŸ”¥è¿½åŠ ï¼
    )


@bp.post("/<username>/sites/<int:sid>/delete")
@login_required
def delete_site(username, sid: int):
    if current_user.username != username:
        abort(403)

    site = Site.query.get_or_404(sid)
    if site.user_id != current_user.id:
        abort(403)

    db.session.delete(site)
    db.session.commit()
    flash("ã‚µã‚¤ãƒˆã‚’å‰Šé™¤ã—ã¾ã—ãŸ", "success")
    return redirect(url_for("main.sites", username=username))


@bp.route("/<username>/sites/<int:sid>/edit", methods=["GET", "POST"])
@login_required
def edit_site(username, sid: int):
    if current_user.username != username:
        abort(403)

    site = Site.query.get_or_404(sid)
    if site.user_id != current_user.id:
        abort(403)

    form = SiteForm(obj=site)

    # âœ… è‡ªåˆ†ã®ã‚¸ãƒ£ãƒ³ãƒ«ã ã‘ã‚’é¸æŠè‚¢ã«å«ã‚ã‚‹
    genre_list = Genre.query.filter_by(user_id=current_user.id).order_by(Genre.name).all()
    form.genre_id.choices = [(0, "ã‚¸ãƒ£ãƒ³ãƒ«æœªé¸æŠ")] + [(g.id, g.name) for g in genre_list]

    # âœ… åˆæœŸå€¤ã¯ GET ã®ã¨ãã ã‘è¨­å®šï¼ˆPOSTæ™‚ã«ä¸Šæ›¸ãã—ãªã„ï¼ï¼‰
    if request.method == "GET":
        form.genre_id.data = site.genre_id if site.genre_id is not None else 0

    if form.validate_on_submit():
        site.name       = form.name.data
        site.url        = form.url.data.rstrip("/")
        site.username   = form.username.data
        site.app_pass   = form.app_pass.data
        site.plan_type  = form.plan_type.data
        site.genre_id   = form.genre_id.data if form.genre_id.data != 0 else None

        db.session.commit()
        flash("ã‚µã‚¤ãƒˆæƒ…å ±ã‚’æ›´æ–°ã—ã¾ã—ãŸ", "success")
        return redirect(url_for("main.log_sites", username=username))

    else:
        if request.method == "POST":
            print("âŒ ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼:", form.errors)
            print("ğŸ“Œ ã‚¸ãƒ£ãƒ³ãƒ«ID:", form.genre_id.data)

    return render_template("site_edit.html", form=form, site=site)

@bp.route('/add_genre', methods=['POST'])
@login_required
def add_genre():
    data = request.get_json()
    name = data.get('name')
    description = data.get('description', '')

    if not name:
        return jsonify(success=False, error='Name required'), 400

    new_genre = Genre(name=name, description=description, user_id=current_user.id)
    db.session.add(new_genre)
    db.session.commit()

    return jsonify(success=True, genre_id=new_genre.id, genre_name=new_genre.name)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ è¨˜äº‹ç”Ÿæˆï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥ï¼‰

@bp.route("/<username>/generate", methods=["GET", "POST"])
@login_required
def generate(username):
    if current_user.username != username:
        abort(403)

    form = GenerateForm()

    # â–¼ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ã‚µã‚¤ãƒˆã®é¸æŠè‚¢ã‚’ã‚»ãƒƒãƒˆ
    form.genre_select.choices = [(0, "â€• ä½¿ã‚ãªã„ â€•")] + [
        (p.id, p.genre)
        for p in PromptTemplate.query.filter_by(user_id=current_user.id)
    ]
    form.site_select.choices = [(0, "â€•â€• é¸æŠ â€•â€•")] + [
        (s.id, s.name)
        for s in Site.query.filter_by(user_id=current_user.id)
    ]

    # â–¼ ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰äº‹å‰é¸æŠã•ã‚ŒãŸsite_idã¨statusã‚’å–å¾—
    selected_site_id = request.args.get("site_id", type=int)
    status_filter = request.args.get("status")  # "used" / "unused" / None

    if request.method == "GET" and selected_site_id:
        form.site_select.data = selected_site_id

    # â–¼ POSTå‡¦ç†ï¼ˆè¨˜äº‹ç”Ÿæˆï¼‰
    if form.validate_on_submit():
        kws = [k.strip() for k in form.keywords.data.splitlines() if k.strip()]
        site_id = form.site_select.data or None
        enqueue_generation(
            current_user.id,
            kws,
            form.title_prompt.data,
            form.body_prompt.data,
            site_id
        )
        flash(f"{len(kws)} ä»¶ã‚’ã‚­ãƒ¥ãƒ¼ã«ç™»éŒ²ã—ã¾ã—ãŸ", "success")
        return redirect(url_for("main.log_sites", username=username))

    # â–¼ è¡¨ç¤ºã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸€è¦§ã‚’å–å¾—ï¼ˆstatusãƒ•ã‚£ãƒ«ã‚¿ã‚‚è€ƒæ…®ï¼‰
    keyword_choices = []
    selected_site = None
    site_name = None

    # â–¼ ä»¶æ•°ã‚«ã‚¦ãƒ³ãƒˆç”¨ã®å¤‰æ•°ã‚’åˆæœŸåŒ–ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯0ï¼‰
    total_count = 0
    used_count = 0
    unused_count = 0

    if form.site_select.data:
        selected_site_id = form.site_select.data
        selected_site = Site.query.get(selected_site_id)
        site_name = selected_site.name if selected_site else ""

        keyword_query = Keyword.query.filter_by(
            user_id=current_user.id,
            site_id=selected_site_id
        )

        # â–¼ ä»¶æ•°ã‚«ã‚¦ãƒ³ãƒˆï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãªã—ã§å–å¾—ï¼‰
        all_keywords = keyword_query.all()
        total_count = len(all_keywords)
        used_count = sum(1 for kw in all_keywords if kw.used)
        unused_count = total_count - used_count

        if status_filter == "used":
            keyword_query = keyword_query.filter_by(used=True)
        elif status_filter == "unused":
            keyword_query = keyword_query.filter_by(used=False)

        keyword_choices = keyword_query.order_by(Keyword.id.desc()).limit(1000).all()

    return render_template(
        "generate.html",
        form=form,
        keyword_choices=keyword_choices,
        selected_site=selected_site,
        site_name=site_name,
        status_filter=status_filter,
        total_count=total_count,      # â† å…¨ä½“ä»¶æ•°
        used_count=used_count,        # â† ç”Ÿæˆæ¸ˆã¿ä»¶æ•°
        unused_count=unused_count     # â† æœªç”Ÿæˆä»¶æ•°
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ GSCãƒ«ãƒ¼ãƒˆã‚³ãƒ¼ãƒ‰

from app.google_client import fetch_search_queries_for_site
from app.models import Keyword  # ğŸ” æ—¢å­˜ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å‚ç…§ã®ãŸã‚è¿½åŠ 
from app.article_generator import enqueue_generation  # ğŸ” å¿˜ã‚Œãšã«

#@bp.route("/generate_from_gsc/<int:site_id>", methods=["GET", "POST"])
#@login_required
#def generate_from_gsc(site_id):
    #site = Site.query.get_or_404(site_id)
    #if site.user_id != current_user.id:
       # abort(403)

    # âœ… GSCæœªæ¥ç¶šã®ã‚¬ãƒ¼ãƒ‰
    #if not site.gsc_connected:
        #flash("ã“ã®ã‚µã‚¤ãƒˆã¯ã¾ã Search Consoleã¨æ¥ç¶šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚", "danger")
        #return redirect(url_for("main.gsc_connect"))

    #try:
        #rows = fetch_search_queries(site.url, days=7, row_limit=40)
        #keywords = [row["keys"][0] for row in rows if "keys" in row]
    #except Exception as e:
        #flash(f"Search Consoleã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}", "danger")
        #return redirect(url_for("main.keywords", username=current_user.username))

    #if not keywords:
        #flash("æ¤œç´¢ã‚¯ã‚¨ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚", "warning")
        #return redirect(url_for("main.keywords", username=current_user.username))

    # âœ… æ—¢å­˜ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯
    #existing_keywords = set(
        #k.keyword for k in Keyword.query.filter_by(site_id=site.id).all()
    #)
    #new_keywords = [kw for kw in keywords if kw not in existing_keywords]

    #if not new_keywords:
        #flash("ã™ã¹ã¦ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒæ—¢ã«ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã™ã€‚", "info")
        #return redirect(url_for("main.keywords", username=current_user.username))

    # âœ… GSCç”±æ¥ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ã—ã¦DBã«è¿½åŠ 
    #for kw in new_keywords:
        #db.session.add(Keyword(
            #keyword=kw,
            #site_id=site.id,
            #user_id=current_user.id,
            #source='gsc'
        #))

    # âœ… GSCæ¥ç¶šçŠ¶æ…‹ã‚’ä¿å­˜ï¼ˆåˆå›ã®ã¿ï¼‰â€»ä¿é™ºã¨ã—ã¦æ®‹ã™
    #if not site.gsc_connected:
        #site.gsc_connected = True

    #db.session.commit()

    # âœ… è¨˜äº‹ç”Ÿæˆã‚­ãƒ¥ãƒ¼ã¸
    #enqueue_generation(new_keywords, site.id, current_user.id)

    #flash(f"{len(new_keywords)}ä»¶ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰è¨˜äº‹ç”Ÿæˆã‚’é–‹å§‹ã—ã¾ã—ãŸ", "success")
    #return redirect(url_for("main.keywords", username=current_user.username))


@bp.route("/gsc_generate", methods=["GET", "POST"])
@login_required
def gsc_generate():
    from app.google_client import fetch_search_queries_for_site
    from app.article_generator import enqueue_generation
    from app.models import Keyword, PromptTemplate

    # --- POSTï¼ˆè¨˜äº‹ç”Ÿæˆå‡¦ç†ï¼‰ ---
    if request.method == "POST":
        site_id = request.form.get("site_id", type=int)
        site = Site.query.get_or_404(site_id)

        if site.user_id != current_user.id:
            abort(403)

        # âœ… è¿½åŠ ï¼šã™ã§ã«GSCç”ŸæˆãŒå§‹ã¾ã£ã¦ã„ã‚‹å ´åˆã¯ä¸­æ­¢
        if site.gsc_generation_started:
            flash("âš ï¸ ã“ã®ã‚µã‚¤ãƒˆã§ã¯ã™ã§ã«GSCè¨˜äº‹ç”ŸæˆãŒé–‹å§‹ã•ã‚Œã¦ã„ã¾ã™ã€‚", "warning")
            return redirect(url_for("main.gsc_generate", site_id=site_id))

        # âœ… åˆå›ç”Ÿæˆãƒ•ãƒ©ã‚°ã‚’Trueã«ã™ã‚‹ï¼ˆ1å›é™ã‚Šã®èµ·å‹•ï¼‰
        site.gsc_generation_started = True
        db.session.commit()

        prompt_id = request.form.get("prompt_id", type=int)
        title_prompt = request.form.get("title_prompt", "").strip()
        body_prompt = request.form.get("body_prompt", "").strip()

        if not site.gsc_connected:
            flash("ã“ã®ã‚µã‚¤ãƒˆã¯ã¾ã GSCã¨æ¥ç¶šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚", "danger")
            return redirect(url_for("main.gsc_connect"))


        # GSCã‚¯ã‚¨ãƒªå–å¾—
        try:
            queries = fetch_search_queries_for_site(site, days=28, row_limit=1000)

            # ğŸ”§ è¿½åŠ : å–å¾—ä»¶æ•°ãƒ­ã‚°
            current_app.logger.info(f"[GSC] {len(queries)} ä»¶ã®ã‚¯ã‚¨ãƒªã‚’å–å¾— - {site.url}")

        except Exception as e:
            flash(f"GSCã‹ã‚‰ã®ã‚¯ã‚¨ãƒªå–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}", "danger")
            return redirect(url_for("main.log_sites", username=current_user.username))

        # é‡è¤‡æ’é™¤
        # âœ… æ—¢å­˜ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã†ã¡ã€status="done" ã®ã‚‚ã®ã¯å†åˆ©ç”¨ä¸å¯ã¨ã—ã¦é™¤å¤–
        existing = set(
            k.keyword
            for k in Keyword.query.filter_by(site_id=site.id, source="gsc")
            if k.status == "done"
        )
        new_keywords = [q for q in queries if q not in existing]

        # ğŸ”§ è¿½åŠ : ç©º or å…¨é‡è¤‡ã®åˆ†å²ã§åˆ¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        if not new_keywords:
            if not queries:
                flash("âš ï¸ GSCã‹ã‚‰ã‚¯ã‚¨ãƒªã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚URLå½¢å¼ãŒä¸€è‡´ã—ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚", "warning")
                current_app.logger.warning(f"[GSC] ã‚¯ã‚¨ãƒªãŒ0ä»¶ã§ã—ãŸ - {site.url}")
            else:
                flash("ã™ã¹ã¦ã®ã‚¯ã‚¨ãƒªãŒæ—¢ã«ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã™ã€‚", "info")
                current_app.logger.info(f"[GSC] å…¨ã‚¯ã‚¨ãƒªãŒæ—¢å­˜ã®ãŸã‚ç™»éŒ²ã‚¹ã‚­ãƒƒãƒ— - {site.url}")
            return redirect(url_for("main.log_sites", username=current_user.username))

        # DBã«ç™»éŒ²ï¼ˆsource='gsc'ï¼‰
        for kw in new_keywords:
            keyword = Keyword(site_id=site.id, keyword=kw, user_id=current_user.id, source="gsc")
            db.session.add(keyword)
        db.session.commit()

        # ğŸ”¸ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå–å¾—ï¼ˆä¿å­˜æ¸ˆã¿ã‚’å„ªå…ˆï¼‰
        if prompt_id:
            saved_prompt = PromptTemplate.query.filter_by(id=prompt_id, user_id=current_user.id).first()
            if saved_prompt:
                title_prompt = saved_prompt.title_pt
                body_prompt = saved_prompt.body_pt

        # ğŸ” è¨˜äº‹ç”Ÿæˆã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
        enqueue_generation(
            user_id=current_user.id,
            site_id=site.id,
            keywords=new_keywords,
            title_prompt=title_prompt,
            body_prompt=body_prompt,
        )

        flash(f"{len(new_keywords)}ä»¶ã®GSCã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰è¨˜äº‹ç”Ÿæˆã‚’é–‹å§‹ã—ã¾ã—ãŸ", "success")
        current_app.logger.info(f"[GSC] âœ… {len(new_keywords)} ä»¶ã®è¨˜äº‹ç”Ÿæˆã‚­ãƒ¥ãƒ¼ã‚’è¿½åŠ  - {site.url}")
        return redirect(url_for("main.log_sites", username=current_user.username))

    # --- GETï¼ˆãƒ•ã‚©ãƒ¼ãƒ è¡¨ç¤ºï¼‰ ---
    site_id = request.args.get("site_id", type=int)
    if not site_id:
        flash("ã‚µã‚¤ãƒˆIDãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚", "danger")
        return redirect(url_for("main.log_sites", username=current_user.username))

    site = Site.query.get_or_404(site_id)
    if site.user_id != current_user.id:
        abort(403)

    if not site.gsc_connected:
        flash("ã“ã®ã‚µã‚¤ãƒˆã¯ã¾ã GSCã¨æ¥ç¶šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚", "danger")
        return redirect(url_for("main.gsc_connect"))
    
    # âœ… è¿½åŠ : ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    status_filter = request.args.get("status")
    query = Keyword.query.filter_by(site_id=site.id, source="gsc")

    if status_filter in ["done", "unprocessed"]:
        query = query.filter(Keyword.status == status_filter)

    from app.models import Article, Keyword

# âœ… GSCç”±æ¥ã®è¨˜äº‹æ•°ï¼ˆKeyword.source="gsc" ã«ç´ã¥ã Articleï¼‰
    # âœ… GSCè¨˜äº‹æ•°ï¼ˆJOIN ON æ¡ä»¶ã‚’æ˜ç¤ºï¼‰
    gsc_done = Article.query.filter_by(site_id=site.id, source="gsc").count()

# âœ… å…¨è¨˜äº‹æ•°ï¼ˆã™ã¹ã¦ã® Articleï¼‰
    all_done = Article.query.filter_by(site_id=site.id).count()

# âœ… é€šå¸¸è¨˜äº‹æ•° = å…¨ä½“ - GSC
    manual_done = all_done - gsc_done

# âœ… åˆè¨ˆãƒ»æ®‹ã‚Šï¼ˆä¸Šé™ï¼š1000ï¼‰
    total_done = gsc_done + manual_done
    remaining = max(1000 - total_done, 0)
    
    
    # âœ… ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‰ã«å…¨GSCã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å–å¾—ï¼ˆä»¶æ•°ç”¨ï¼‰
    gsc_done_keywords = Keyword.query.filter_by(site_id=site.id, source="gsc", status="done").count()
    gsc_pending_keywords = Keyword.query.filter_by(site_id=site.id, source="gsc", status="unprocessed").count()
    gsc_total_keywords = gsc_done_keywords + gsc_pending_keywords  # ğŸ”§ åˆè¨ˆã‚’è¿½åŠ 

    # âœ… è¡¨ç¤ºãƒªã‚¹ãƒˆç”¨ã«å†ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    query = Keyword.query.filter_by(site_id=site.id, source="gsc")
    if status_filter == "done":
        query = query.filter(Keyword.status == "done")
    elif status_filter == "unprocessed":
        query = query.filter(Keyword.status != "done")
    gsc_keywords = query.order_by(Keyword.created_at.desc()).all()


    # ä¿å­˜æ¸ˆã¿ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    saved_prompts = PromptTemplate.query.filter_by(user_id=current_user.id).order_by(PromptTemplate.genre).all()

    return render_template(
        "gsc_generate.html",
        selected_site=site,
        gsc_keywords=gsc_keywords,
        saved_prompts=saved_prompts,
        title_prompt="",  # åˆæœŸå€¤
        body_prompt="",   # åˆæœŸå€¤
        request=request,   # âœ… ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã§ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹é¸æŠä¿æŒã«ä½¿ã†
        gsc_done=gsc_done,
        manual_done=manual_done,
        total_done=total_done,
        remaining=remaining,
        gsc_done_keywords=gsc_done_keywords,         # âœ… è¿½åŠ 
        gsc_pending_keywords=gsc_pending_keywords,    # âœ… è¿½åŠ 
        gsc_total_keywords=gsc_total_keywords  # ğŸ”§ è¿½åŠ 
    )


# --- æ—¢å­˜ã‚¤ãƒ³ãƒãƒ¼ãƒˆã®ä¸‹ã«è¿½åŠ ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰ ---
from flask import render_template, redirect, url_for, flash
from flask_login import login_required, current_user
from app.models import Site, db

# âœ… /gsc-connect: GSCé€£æºãƒšãƒ¼ã‚¸ã®è¡¨ç¤º
# âœ… /gsc-connect: GSCé€£æºãƒšãƒ¼ã‚¸ã®è¡¨ç¤ºï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ã®æœ‰ç„¡ã§åˆ¤å®šï¼‰
@bp.route("/gsc-connect")
@login_required
def gsc_connect():
    filter_status = request.args.get("status")  # "connected", "unconnected", "all"
    search_query = request.args.get("query", "").strip().lower()
    order = request.args.get("order")  # "recent", "most_views", "least_views"

    # âœ… ã‚¯ã‚¨ãƒªæ§‹ç¯‰ï¼ˆå…¨ä»¶ãƒ™ãƒ¼ã‚¹ã§å§‹ã‚ã‚‹ï¼‰
    sites_query = Site.query.filter_by(user_id=current_user.id)

    # âœ… ä¸¦ã³æ›¿ãˆæ¡ä»¶
    # â€» GSCã¯ã€ŒJSTã®æ˜¨æ—¥ã¾ã§ã€ã®ç›´è¿‘28æ—¥ã§ä¸¦ã¹ã‚‹ï¼ˆç›¸é–¢ã‚µãƒ–ã‚¯ã‚¨ãƒªã§é«˜é€Ÿï¼‰
    if order in ("most_views", "least_views"):
        from datetime import datetime, timezone, timedelta
        from sqlalchemy import func
        from app.models import GSCDailyTotal
        # âœ… çµ±ä¸€çª“
        _start_d, _end_d = _gsc_window_by_latest_db(28)
        _gsc_impr_28d = (
            db.session.query(func.coalesce(func.sum(GSCDailyTotal.impressions), 0))
            .filter(
                GSCDailyTotal.site_id == Site.id,
                GSCDailyTotal.date >= _start_d,
                GSCDailyTotal.date <= _end_d
            )
            .correlate(Site).scalar_subquery()
        )
        if order == "most_views":
            sites_query = sites_query.order_by(_gsc_impr_28d.desc())
        else:  # "least_views"
            sites_query = sites_query.order_by(_gsc_impr_28d.asc())
    else:
        sites_query = sites_query.order_by(Site.created_at.desc())  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼šæ–°ã—ã„é †

    sites = sites_query.all()

    # ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—
    from app.models import GSCAuthToken
    tokens = {token.site_id: token for token in GSCAuthToken.query.filter_by(user_id=current_user.id).all()}

    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ•ãƒ©ã‚°ä»˜ä¸
    for site in sites:
        site.is_token_connected = site.id in tokens

    # âœ… ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆPythonå´ã§å‡¦ç†ï¼‰
    if filter_status == "connected":
        sites = [s for s in sites if s.gsc_connected]
    elif filter_status == "unconnected":
        sites = [s for s in sites if not s.gsc_connected]

    # âœ… æ¤œç´¢ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    if search_query:
        sites = [s for s in sites if search_query in s.name.lower() or search_query in s.url.lower()]

    return render_template(
        "gsc_connect.html",
        sites=sites,
        filter_status=filter_status,
        search_query=search_query,
        order=order,
    )



@bp.route("/connect_gsc/<int:site_id>", methods=["POST"])
@login_required
def connect_gsc(site_id):
    site = Site.query.get_or_404(site_id)
    if site.user_id != current_user.id:
        flash("ã‚¢ã‚¯ã‚»ã‚¹æ¨©ãŒã‚ã‚Šã¾ã›ã‚“ã€‚", "danger")
        return redirect(url_for("main.gsc_connect"))

    site.gsc_connected = True
    db.session.commit()

    flash(f"âœ… ã‚µã‚¤ãƒˆã€Œ{site.name}ã€ã¨Googleã‚µãƒ¼ãƒã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã®æ¥ç¶šãŒå®Œäº†ã—ã¾ã—ãŸã€‚", "success")
    return redirect(url_for("main.gsc_connect"))

# app/routes.pyï¼ˆæœ«å°¾ã«è¿½åŠ ï¼‰

# âœ… å¿…è¦ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from flask import request, render_template  # â† Flaskã®æ¨™æº–é–¢æ•°
from app.models import GSCMetric, Site      # â† GSCMetricã‚’ä½¿ã£ã¦DBã‹ã‚‰é›†è¨ˆ
from flask_login import login_required, current_user
from datetime import datetime, timedelta

# âœ… GSCã‚¢ã‚¯ã‚»ã‚¹åˆ†æãƒ«ãƒ¼ãƒˆï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼åä¸è¦ã«çµ±ä¸€ï¼‰
@bp.route("/gsc/<int:site_id>")  # â† âœ… ã“ã“ã‚’ä½¿ç”¨ãƒ«ãƒ¼ãƒˆã«çµ±ä¸€
@login_required
def gsc_analysis(site_id):
    # âœ… å¯¾è±¡ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚µã‚¤ãƒˆã‹ç¢ºèª
    site = Site.query.filter_by(id=site_id, user_id=current_user.id).first_or_404()

    # âœ… æœªé€£æºã‚µã‚¤ãƒˆã¯è­¦å‘Šè¡¨ç¤º
    if not site.gsc_connected:
        return render_template("gsc_analysis.html", site=site, error="ã“ã®ã‚µã‚¤ãƒˆã¯GSCã¨æœªé€£æºã§ã™")

    # âœ… GETãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—ï¼ˆrange ã¾ãŸã¯ start/endï¼‰
    range_param = request.args.get("range", "28d")
    start_param = request.args.get("start")
    end_param = request.args.get("end")

    today = datetime.utcnow().date()

    # âœ… æ—¥ä»˜ç¯„å›²ã®æ±ºå®šãƒ­ã‚¸ãƒƒã‚¯
    if range_param == "1d":
        start_date = today - timedelta(days=1)
    elif range_param == "7d":
        start_date = today - timedelta(days=7)
    elif range_param == "28d":
        start_date = today - timedelta(days=28)
    elif range_param == "3m":
        start_date = today - timedelta(days=90)
    elif range_param == "6m":
        start_date = today - timedelta(days=180)
    elif range_param == "12m":
        start_date = today - timedelta(days=365)
    elif range_param == "16m":
        start_date = today - timedelta(days=480)
    elif range_param == "custom" and start_param and end_param:
        try:
            start_date = datetime.strptime(start_param, "%Y-%m-%d").date()
            today = datetime.strptime(end_param, "%Y-%m-%d").date()
        except ValueError:
            return render_template(
                "gsc_analysis.html",
                site=site,
                error="æ—¥ä»˜å½¢å¼ãŒä¸æ­£ã§ã™"
            )
    else:
        # âœ… ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ28æ—¥
        start_date = today - timedelta(days=28)

    # âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰è©²å½“æœŸé–“ã®GSCãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—
    metrics = GSCMetric.query.filter(
        GSCMetric.site_id == site_id,
        GSCMetric.date >= start_date,
        GSCMetric.date <= today
    ).order_by(GSCMetric.date.asc()).all()

    # âœ… ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¸ãƒ‡ãƒ¼ã‚¿é€ä¿¡
    return render_template(
        "gsc_analysis.html",
        site=site,
        metrics=metrics,
        start_date=start_date,
        end_date=today,
        selected_range=range_param
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ç”Ÿæˆãƒ­ã‚°
@bp.route("/<username>/log/site/<int:site_id>")
@login_required
def log(username, site_id):
    if current_user.username != username:
        abort(403)

    from collections import defaultdict
    from .article_generator import _generate_slots_per_site

    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ & ã‚½ãƒ¼ãƒˆã‚­ãƒ¼å–å¾—
    status = request.args.get("status")
    sort_key = request.args.get("sort", "scheduled_at")
    sort_order = request.args.get("order", "desc")

    # âœ… GSCçµã‚Šè¾¼ã¿ç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—
    source = request.args.get("source", "all")

    # æœªã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è¨˜äº‹ã® slot ã‚’è‡ªå‹•å‰²å½“
    unscheduled = Article.query.filter(
        Article.user_id == current_user.id,
        Article.scheduled_at.is_(None),
    ).all()

    if unscheduled:
        site_map = defaultdict(list)
        for art in unscheduled:
            if art.site_id:
                site_map[art.site_id].append(art)

        for sid, articles in site_map.items():
            slots = iter(_generate_slots_per_site(current_app, sid, len(articles)))
            for art in articles:
                art.scheduled_at = next(slots)
        db.session.commit()

    # è¨˜äº‹å–å¾—ã‚¯ã‚¨ãƒª
    q = Article.query.filter_by(user_id=current_user.id, site_id=site_id)
    if status:
        q = q.filter_by(status=status)

    if source == "gsc":
        q = q.filter_by(source="gsc")  # âœ… GSCè¨˜äº‹ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿

    # å¿…ãš site æƒ…å ±ã‚‚ preloadï¼ˆclicks/impressionsç”¨ï¼‰
    q = q.options(selectinload(Article.site))

    # åˆæœŸä¸¦ã³é †ï¼šæŠ•ç¨¿äºˆå®šæ—¥æ™‚å„ªå…ˆ
    q = q.order_by(
        nulls_last(asc(Article.scheduled_at)),
        Article.created_at.desc(),
    )

    articles = q.all()

    # --- å½“è©²ã‚µã‚¤ãƒˆã®ç›´è¿‘28æ—¥åˆè¨ˆï¼ˆJSTï¼‰ã‚’å–å¾—ï¼ˆè¨˜äº‹è¡Œã®è¡¨ç¤ºï¼†ä¸¦ã¹æ›¿ãˆç”¨ï¼‰ ---
    # âœ… çµ±ä¸€çª“ï¼ˆJSTã®æ˜¨æ—¥ âˆ§ DBæœ€æ–°æ—¥ï¼‰
    start_d, end_d = _gsc_window_by_latest_db(28)

    gsc_row = (
        db.session.query(
            func.coalesce(func.sum(GSCDailyTotal.clicks), 0),
            func.coalesce(func.sum(GSCDailyTotal.impressions), 0),
        )
        .filter(
            GSCDailyTotal.site_id == site_id,
            GSCDailyTotal.date >= start_d,
            GSCDailyTotal.date <= end_d,
        )
        .first()
    )
    site_gsc = {
        "clicks": int(gsc_row[0] or 0),
        "impressions": int(gsc_row[1] or 0),
    }

    # ğŸ”½ ä¸¦ã³æ›¿ãˆï¼ˆPythonå´ï¼‰: ã‚¯ãƒªãƒƒã‚¯/è¡¨ç¤ºå›æ•°ã¯ã‚µã‚¤ãƒˆåˆè¨ˆã§ã‚½ãƒ¼ãƒˆ
    if sort_key == "clicks":
        keyval = site_gsc["clicks"]
        articles.sort(key=lambda _a: keyval, reverse=(sort_order == "desc"))
    elif sort_key == "impr":
        keyval = site_gsc["impressions"]
        articles.sort(key=lambda _a: keyval, reverse=(sort_order == "desc"))

    site = Site.query.get_or_404(site_id)

    return render_template(
        "log.html",
        articles=articles,
        site=site,
        status=status,
        sort_key=sort_key,
        sort_order=sort_order,
        selected_source=source,  # âœ… ãƒ•ã‚£ãƒ«ã‚¿UIã®çŠ¶æ…‹ä¿æŒç”¨
        jst=JST,
        site_gsc=site_gsc,  # âœ… è¿½åŠ : ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¸æ¸¡ã™
    )



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ãƒ­ã‚°ï¼šã‚µã‚¤ãƒˆé¸æŠãƒšãƒ¼ã‚¸ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥ï¼‰
@bp.route("/<username>/log/sites")
@login_required
def log_sites(username):
    if current_user.username != username:
        abort(403)

    from sqlalchemy import case
    from app.models import Genre, GSCDailyTotal
    from datetime import datetime, timedelta, timezone
    from sqlalchemy import func, asc, desc
    from sqlalchemy.orm import selectinload


    # GETãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    status_filter = request.args.get("plan_type", "all")
    search_query = request.args.get("query", "").strip().lower()
    sort_key = request.args.get("sort", "created")
    sort_order = request.args.get("order", "asc")
    genre_id = request.args.get("genre_id", "0")
    try:
        genre_id = int(genre_id)
    except ValueError:
        genre_id = 0

    # ---------- GSCåˆè¨ˆï¼ˆç›´è¿‘28æ—¥ãƒ»JSTï¼‰ ----------
    JST = timezone(timedelta(hours=9))
    today_jst = datetime.utcnow().replace(tzinfo=timezone.utc).astimezone(JST).date()
    # âœ… GSC UI ã¨åŒã˜ã€Œæ˜¨æ—¥ã¾ã§ã®28æ—¥ã€
    end_d   = today_jst - timedelta(days=1)
    start_d = end_d - timedelta(days=27)

    gsc_sub = (
        db.session.query(
            GSCDailyTotal.site_id.label("site_id"),
            func.coalesce(func.sum(GSCDailyTotal.clicks), 0).label("clicks"),
            func.coalesce(func.sum(GSCDailyTotal.impressions), 0).label("impressions"),
        )
        .filter(GSCDailyTotal.date >= start_d, GSCDailyTotal.date <= end_d)
        .group_by(GSCDailyTotal.site_id)
    ).subquery()

    # ---------- ã‚µãƒ–ã‚¯ã‚¨ãƒªï¼ˆè¨˜äº‹æ•°ãªã©ã®é›†è¨ˆï¼‹GSCåˆè¨ˆã‚’JOINï¼‰ ----------
    subquery = (
        db.session.query(
            Site.id.label("id"),
            Site.name.label("name"),
            Site.url.label("url"),
            Site.plan_type.label("plan_type"),
            Site.gsc_connected.label("gsc_connected"),
            Site.created_at.label("created_at"),
            func.count(Article.id).label("total"),
            func.sum(case((Article.status == "done", 1), else_=0)).label("done"),
            func.sum(case((Article.status == "posted", 1), else_=0)).label("posted"),
            func.sum(case((Article.status == "error", 1), else_=0)).label("error"),
            func.coalesce(func.max(gsc_sub.c.clicks), 0).label("clicks"),
            func.coalesce(func.max(gsc_sub.c.impressions), 0).label("impressions"),
        )
        .select_from(Site)  # â† å·¦å´ï¼ˆFROMï¼‰ã‚’æ˜ç¤ºã—ã¦æš—é»™JOINã®æ›–æ˜§ã•ã‚’è§£æ¶ˆ
        .outerjoin(Article, Site.id == Article.site_id)
        .outerjoin(gsc_sub, gsc_sub.c.site_id == Site.id)
        .filter(Site.user_id == current_user.id)
        .group_by(Site.id)
    ).subquery()

    # ---------- ãƒ¡ã‚¤ãƒ³ã‚¯ã‚¨ãƒªï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼†ä¸¦ã³æ›¿ãˆï¼‰ ----------
    query = db.session.query(subquery)

    if status_filter in ["affiliate", "business"]:
        query = query.filter(subquery.c.plan_type == status_filter)

    if genre_id > 0:
        # ã‚µãƒ–ã‚¯ã‚¨ãƒªã‚’å·¦å´ã«å›ºå®šã—ã¦ã‹ã‚‰ Site ã‚’JOINï¼ˆONå¥ã¯æ—¢ã«æ˜ç¤ºï¼‰
        query = (
            query.select_from(subquery).join(Site, Site.id == subquery.c.id).filter(Site.genre_id == genre_id)
        )

    if search_query:
        query = query.filter(
            func.lower(subquery.c.name).like(f"%{search_query}%") |
            func.lower(subquery.c.url).like(f"%{search_query}%")
        )

    # ä¸¦ã³é †ã‚«ãƒ©ãƒ è¨­å®š
    sort_columns = {
        "created": subquery.c.created_at,
        "total": subquery.c.total,
        "done": subquery.c.done,
        "posted": subquery.c.posted,
        "clicks": subquery.c.clicks,
        "impressions": subquery.c.impressions
    }
    order_column = sort_columns.get(sort_key, subquery.c.created_at)

    if sort_order == "desc":
        query = query.order_by(order_column.desc())
    else:
        query = query.order_by(order_column.asc())

    result = query.all()

    # ã‚¸ãƒ£ãƒ³ãƒ«ä¸€è¦§
    genre_list = Genre.query.filter_by(user_id=current_user.id).order_by(Genre.name).all()
    genre_choices = [(0, "ã™ã¹ã¦ã®ã‚¸ãƒ£ãƒ³ãƒ«")] + [(g.id, g.name) for g in genre_list]

    return render_template(
        "log_sites.html",
        sites=result,
        selected_status=status_filter,
        selected_genre_id=genre_id,
        genre_choices=genre_choices,
        search_query=search_query,
        sort_key=sort_key,
        sort_order=sort_order
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
@bp.route("/preview/<int:article_id>")
@login_required
def preview(article_id: int):
    art = Article.query.get_or_404(article_id)
    if art.user_id != current_user.id:
        abort(403)
    styled = _decorate_html(art.body or "")
    return render_template("preview.html", article=art, styled_body=styled)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ WordPress å³æ™‚æŠ•ç¨¿
@bp.post("/article/<int:id>/post")
@login_required
def post_article(id):
    art = Article.query.get_or_404(id)
    if art.user_id != current_user.id:
        abort(403)
    if not art.site:
        flash("æŠ•ç¨¿å…ˆã‚µã‚¤ãƒˆãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“", "danger")
        return redirect(url_for(".log", site_id=art.site_id))

    try:
        url = post_to_wp(art.site, art)
        art.posted_at = datetime.utcnow()
        art.status = "posted"
        db.session.commit()
        flash(f"WordPress ã¸æŠ•ç¨¿ã—ã¾ã—ãŸ: {url}", "success")
    except Exception as e:
        current_app.logger.exception("å³æ™‚æŠ•ç¨¿å¤±æ•—: %s", e)
        db.session.rollback()
        flash(f"æŠ•ç¨¿å¤±æ•—: {e}", "danger")

    return redirect(url_for(".log", username=current_user.username, site_id=art.site_id))


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ è¨˜äº‹ç·¨é›†ãƒ»å‰Šé™¤ãƒ»å†è©¦è¡Œ
@bp.route("/article/<int:id>/edit", methods=["GET", "POST"])
@login_required
def edit_article(id):
    art = Article.query.get_or_404(id)
    if art.user_id != current_user.id:
        abort(403)
    form = ArticleForm(obj=art)
    if form.validate_on_submit():
        art.title = form.title.data
        art.body  = form.body.data
        db.session.commit()
        flash("è¨˜äº‹ã‚’æ›´æ–°ã—ã¾ã—ãŸ", "success")
        return redirect(url_for(".log", username=current_user.username, site_id=art.site_id))
    return render_template("edit_article.html", form=form, article=art)

@bp.post("/article/<int:id>/delete")
@login_required
def delete_article(id):
    art = Article.query.get_or_404(id)
    if art.user_id != current_user.id:
        abort(403)
    db.session.delete(art)
    db.session.commit()
    flash("è¨˜äº‹ã‚’å‰Šé™¤ã—ã¾ã—ãŸ", "success")
    return redirect(url_for(".log", username=current_user.username, site_id=art.site_id))

# app/routes.py

@bp.route("/<username>/articles/<int:id>/retry", methods=["POST"])
@login_required
def retry_article(username, id):
    art = Article.query.get_or_404(id)
    if art.user_id != current_user.id or username != current_user.username:
        abort(403)

    if not art.title_prompt or not art.body_prompt:
        flash("ã“ã®è¨˜äº‹ã¯å†ç”Ÿæˆã§ãã¾ã›ã‚“ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœªä¿å­˜ï¼‰", "error")
        return redirect(url_for("main.view_articles", username=username))

    art.status = "pending"
    art.progress = 0
    art.updated_at = datetime.utcnow()
    db.session.commit()

    # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å†ç”Ÿæˆ
    from app.article_generator import _generate
    app = current_app._get_current_object()
    threading.Thread(
        target=_generate,
        args=(app, art.id, art.title_prompt, art.body_prompt),
        daemon=True
    ).start()

    flash("è¨˜äº‹ã®å†ç”Ÿæˆã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„ã€‚", "success")
    return redirect(url_for("main.view_articles", username=username))



@bp.post("/articles/bulk-delete")
@login_required
def bulk_delete_articles():
    ids = request.form.getlist("selected_ids")
    if not ids:
        flash("å‰Šé™¤ã™ã‚‹è¨˜äº‹ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“", "warning")
        return redirect(request.referrer or url_for(".dashboard"))

    for aid in ids:
        article = Article.query.get(int(aid))
        if article and article.user_id == current_user.id:
            db.session.delete(article)

    db.session.commit()
    flash(f"{len(ids)}ä»¶ã®è¨˜äº‹ã‚’å‰Šé™¤ã—ã¾ã—ãŸ", "success")
    return redirect(request.referrer or url_for(".dashboard"))



@bp.route("/debug-post/<int:aid>")
@login_required
def debug_post(aid):
    art = Article.query.get_or_404(aid)
    if art.user_id != current_user.id:
        abort(403)
    try:
        url = post_to_wp(art.site, art)
        return f"SUCCESS: {url}"
    except Exception as e:
        return f"ERROR: {e}", 500
    
import requests
from app.models import GSCAuthToken, db
import datetime

# Google OAuth2 è¨­å®š
GOOGLE_CLIENT_ID = os.environ.get("GOOGLE_CLIENT_ID")
GOOGLE_CLIENT_SECRET = os.environ.get("GOOGLE_CLIENT_SECRET")
GOOGLE_REDIRECT_URI = os.environ.get("GOOGLE_REDIRECT_URI")
GOOGLE_SCOPE = "https://www.googleapis.com/auth/webmasters.readonly"
GOOGLE_AUTH_URL = "https://accounts.google.com/o/oauth2/v2/auth"
GOOGLE_TOKEN_URL = "https://oauth2.googleapis.com/token"


@bp.route("/authorize_gsc/<int:site_id>")
@login_required
def authorize_gsc(site_id):
    session["gsc_site_id"] = site_id  # å¾Œã§callbackã§å‚ç…§ã™ã‚‹ãŸã‚ä¿å­˜
    auth_url = (
        f"{GOOGLE_AUTH_URL}?"
        f"response_type=code&client_id={GOOGLE_CLIENT_ID}"
        f"&redirect_uri={GOOGLE_REDIRECT_URI}"
        f"&scope={GOOGLE_SCOPE}&access_type=offline&prompt=consent"
    )
    return redirect(auth_url)


@bp.route("/oauth2callback")
@login_required
def oauth2callback():
    from app.models import Site

    code = request.args.get("code")
    if not code:
        flash("Googleèªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸã€‚", "danger")
        return redirect(url_for("main.gsc_connect"))

    site_id = session.get("gsc_site_id")
    site = Site.query.get_or_404(site_id)

    # ãƒˆãƒ¼ã‚¯ãƒ³äº¤æ›ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    data = {
        "code": code,
        "client_id": GOOGLE_CLIENT_ID,
        "client_secret": GOOGLE_CLIENT_SECRET,
        "redirect_uri": GOOGLE_REDIRECT_URI,
        "grant_type": "authorization_code",
    }
    response = requests.post(GOOGLE_TOKEN_URL, data=data)
    if response.status_code != 200:
        flash("ãƒˆãƒ¼ã‚¯ãƒ³ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚", "danger")
        return redirect(url_for("main.gsc_connect"))

    tokens = response.json()
    access_token = tokens["access_token"]
    refresh_token = tokens.get("refresh_token")
    expires_in = tokens.get("expires_in", 3600)
    expiry = datetime.datetime.utcnow() + datetime.timedelta(seconds=expires_in)

    # ä¿å­˜ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆã¯æ›´æ–°ï¼‰
    existing = GSCAuthToken.query.filter_by(site_id=site.id, user_id=current_user.id).first()
    if existing:
        existing.access_token = access_token
        existing.refresh_token = refresh_token
        existing.token_expiry = expiry
    else:
        new_token = GSCAuthToken(
            site_id=site.id,
            user_id=current_user.id,
            access_token=access_token,
            refresh_token=refresh_token,
            token_expiry=expiry,
        )
        db.session.add(new_token)

    site.gsc_connected = True
    db.session.commit()

    flash(f"ã‚µã‚¤ãƒˆã€Œ{site.name}ã€ã¨Google Search Consoleã®æ¥ç¶šã«æˆåŠŸã—ã¾ã—ãŸã€‚", "success")
    return redirect(url_for("main.gsc_connect"))

from app.forms import GenreForm

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ã‚¸ãƒ£ãƒ³ãƒ«ç®¡ç†ãƒšãƒ¼ã‚¸
@bp.route("/<username>/genres", methods=["GET", "POST"])
@login_required
def manage_genres(username):
    if current_user.username != username:
        abort(403)

    form = GenreForm()
    if form.validate_on_submit():
        # ğŸ”¹ æ—¢å­˜ã‚¸ãƒ£ãƒ³ãƒ«åã¨é‡è¤‡ã—ãªã„ã‚ˆã†ã«ãƒã‚§ãƒƒã‚¯ï¼ˆåŒä¸€ãƒ¦ãƒ¼ã‚¶ãƒ¼å†…ï¼‰
        existing = Genre.query.filter_by(user_id=current_user.id, name=form.name.data.strip()).first()
        if existing:
            flash("åŒã˜åå‰ã®ã‚¸ãƒ£ãƒ³ãƒ«ãŒæ—¢ã«å­˜åœ¨ã—ã¾ã™ã€‚", "warning")
        else:
            genre = Genre(
                name=form.name.data.strip(),
                description=form.description.data.strip(),
                user_id=current_user.id
            )
            db.session.add(genre)
            db.session.commit()
            flash("ã‚¸ãƒ£ãƒ³ãƒ«ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚", "success")
        return redirect(url_for("main.manage_genres", username=username))

    genres = Genre.query.filter_by(user_id=current_user.id).order_by(Genre.name).all()
    return render_template("genres.html", form=form, genres=genres)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ã‚¸ãƒ£ãƒ³ãƒ«ç·¨é›†
@bp.route("/<username>/genres/edit/<int:genre_id>", methods=["GET", "POST"])
@login_required
def edit_genre(username, genre_id):
    if current_user.username != username:
        abort(403)

    genre = Genre.query.filter_by(id=genre_id, user_id=current_user.id).first_or_404()
    form = GenreForm(obj=genre)

    if form.validate_on_submit():
        genre.name = form.name.data.strip()
        genre.description = form.description.data.strip()
        db.session.commit()
        flash("ã‚¸ãƒ£ãƒ³ãƒ«ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚", "success")
        return redirect(url_for("main.manage_genres", username=username))

    return render_template("genres.html", form=form, genres=[], edit_genre=genre)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ã‚¸ãƒ£ãƒ³ãƒ«å‰Šé™¤
@bp.route("/<username>/genres/delete/<int:genre_id>", methods=["POST"])
@login_required
def delete_genre(username, genre_id):
    if current_user.username != username:
        abort(403)

    genre = Genre.query.filter_by(id=genre_id, user_id=current_user.id).first_or_404()
    db.session.delete(genre)
    db.session.commit()
    flash("ã‚¸ãƒ£ãƒ³ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚", "info")
    return redirect(url_for("main.manage_genres", username=username))


# -----------------------------------------------------------------
#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å¤–éƒ¨SEOé–¢é€£ãƒ«ãƒ¼ãƒˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# -----------------------------------------------------------------

@bp.route("/external/sites")
@login_required
def external_seo_sites():
    from app.models import (
        Site, ExternalSEOJob, ExternalArticleSchedule,
        ExternalBlogAccount, BlogType, ExternalSEOJobLog, Article
    )
    from app import db
    from sqlalchemy.orm import selectinload
    from sqlalchemy import func, or_
    from datetime import datetime, timedelta, timezone

    sites = (
        Site.query
        .filter_by(user_id=current_user.id)
        .options(
            selectinload(Site.external_jobs),
            selectinload(Site.external_accounts),
        )
        .all()
    )

    job_map, key_set = {}, set()
    for s in sites:
        for job in s.external_jobs:
            if job.status == "archived":
                continue
            key = (s.id, job.blog_type)
            key_set.add(key)
            job_map[(s.id, job.blog_type.value.lower())] = job

    posted_counts = (
        db.session.query(
            ExternalBlogAccount.site_id,
            ExternalBlogAccount.blog_type,
            func.count(ExternalArticleSchedule.id),
        )
        .join(
            ExternalArticleSchedule,
            ExternalArticleSchedule.blog_account_id == ExternalBlogAccount.id,
        )
        .filter(
            ExternalArticleSchedule.status == "posted",
            ExternalBlogAccount.site_id.in_([sid for sid, _ in key_set]) if key_set else True,
            ExternalBlogAccount.blog_type.in_([bt for _, bt in key_set]) if key_set else True,
        )
        .group_by(ExternalBlogAccount.site_id, ExternalBlogAccount.blog_type)
        .all()
    )
    for site_id, blog_type, cnt in posted_counts:
        key = (site_id, blog_type.value.lower())
        if key in job_map:
            job_map[key].posted_cnt = cnt
    for job in job_map.values():
        if not hasattr(job, "posted_cnt"):
            job.posted_cnt = 0

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹é›†è¨ˆï¼ˆã‚¢ã‚«ã‚¦ãƒ³ãƒˆå˜ä½ï¼‰
    all_ld_account_ids = []
    for s in sites:
        for acc in (s.external_accounts or []):
            if acc.blog_type == BlogType.LIVEDOOR:
                all_ld_account_ids.append(acc.id)

    per_acc_total, per_acc_posted = {}, {}
    if all_ld_account_ids:
        for aid, cnt in (
            db.session.query(
                ExternalArticleSchedule.blog_account_id,
                func.count(ExternalArticleSchedule.id),
            )
            .filter(ExternalArticleSchedule.blog_account_id.in_(all_ld_account_ids))
            .group_by(ExternalArticleSchedule.blog_account_id)
            .all()
        ):
            per_acc_total[aid] = cnt

        for aid, cnt in (
            db.session.query(
                ExternalArticleSchedule.blog_account_id,
                func.count(ExternalArticleSchedule.id),
            )
            .filter(
                ExternalArticleSchedule.blog_account_id.in_(all_ld_account_ids),
                ExternalArticleSchedule.status == "posted",
            )
            .group_by(ExternalArticleSchedule.blog_account_id)
            .all()
        ):
            per_acc_posted[aid] = cnt

    for s in sites:
        livedoor_accounts = []
        for acc in (s.external_accounts or []):
            if acc.blog_type != BlogType.LIVEDOOR:
                continue

            setattr(acc, "captcha_done", bool(getattr(acc, "is_captcha_completed", False)))
            setattr(acc, "email_verified", bool(getattr(acc, "is_email_verified", False)))

            livedoor_blog_id = getattr(acc, "livedoor_blog_id", None)
            setattr(acc, "blog_created", bool(livedoor_blog_id))
            setattr(acc, "api_key", getattr(acc, "atompub_key_enc", None))

            title = (
                getattr(acc, "nickname", None)
                or getattr(acc, "username", None)
                or livedoor_blog_id
                or f"account#{acc.id}"
            )
            setattr(acc, "blog_title", title)

            public_url = getattr(acc, "public_url", None)
            if not public_url and livedoor_blog_id:
                public_url = f"https://{livedoor_blog_id}.livedoor.blog/"
            setattr(acc, "public_url", public_url)

            total  = per_acc_total.get(acc.id, 0)
            posted = per_acc_posted.get(acc.id, 0)
            generated = max(total - posted, 0)
            setattr(acc, "stat_total", total)
            setattr(acc, "stat_posted", posted)
            setattr(acc, "stat_generated", generated)
            setattr(acc, "has_activity", total > 0)

            livedoor_accounts.append(acc)

        # â–¼ livedoor_blog_id ãŒåŒã˜ã‚‚ã®ã¯ 1 ä»¶ã«çµ±åˆï¼ˆNULLã¯çµ±åˆã—ãªã„ï¼‰
        dedup_map = {}
        for acc in livedoor_accounts:
            key = getattr(acc, "livedoor_blog_id", None)
            if key is None:
                # blog_id æœªç¢ºå®šã¯ãã®ã¾ã¾åˆ¥ã‚«ãƒ¼ãƒ‰ã¨ã—ã¦æ‰±ã†
                dedup_map[f"__id__:{acc.id}"] = acc
                continue

            prev = dedup_map.get(key)
            if not prev:
                dedup_map[key] = acc
                continue

            # ã©ã¡ã‚‰ã‚’æ®‹ã™ã‹ï¼šAPIã‚­ãƒ¼ > CAPTCHAæ¸ˆã¿ > idæ–°ã—ã„
            def score(a):
                return (
                    2 if getattr(a, "api_key", None) else
                    1 if getattr(a, "captcha_done", False) else
                    0,
                    getattr(a, "id", 0)
                )

            if score(acc) > score(prev):
                dedup_map[key] = acc

        dedup_list = list(dedup_map.values())
        s.livedoor_accounts = dedup_list
        s.ld_count = len(dedup_list)  # â† ã“ã®å€¤ã‚’ãƒ†ãƒ³ãƒ—ãƒ¬ã® (n) ã«ä½¿ã†

    # â–¼ å„ã‚µã‚¤ãƒˆã®ã€Œé€šå¸¸è¨˜äº‹ï¼ˆå¤–éƒ¨SEOä»¥å¤–ã§æŠ•ç¨¿æ¸ˆã¿ï¼‰ã€ä»¶æ•°ã‚’ãƒ†ãƒ³ãƒ—ãƒ¬ã«æ¸¡ã™
    site_ids = [s.id for s in sites]
    if site_ids:
        normal_counts = dict(
            db.session.query(Article.site_id, func.count(Article.id))
            .filter(Article.site_id.in_(site_ids))
            .filter(or_(Article.source.is_(None), Article.source != "external"))
            .filter(Article.status.in_(["posted", "published"]))  # â† done ã‚’é™¤å¤–ï¼ˆWPæŠ•ç¨¿æ¸ˆã¿ã®ã¿ï¼‰
            .group_by(Article.site_id)
            .all()
        )
    else:
        normal_counts = {}
    for s in sites:
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå´ã§ can_start_extseo åˆ¤å®šç”¨ã«å‚ç…§
        s.normal_post_count = normal_counts.get(s.id, 0)

    # === GSC ç›´è¿‘28æ—¥åˆè¨ˆï¼ˆJSTã§ã€Œæ˜¨æ—¥ã¾ã§ã€ï¼‰â†’ ã‚µã‚¤ãƒˆä¸€è¦§ã¨å®Œå…¨åŒä¸€ãƒ­ã‚¸ãƒƒã‚¯ ===
    from app.models import GSCDailyTotal  # â† ã‚µã‚¤ãƒˆä¸€è¦§ã¨åŒã˜ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨

    clicks28 = {}
    impr28   = {}
    if site_ids:
        start_d, end_d = _gsc_window_by_latest_db(28)

        rows = (
            db.session.query(
                GSCDailyTotal.site_id,
                func.coalesce(func.sum(GSCDailyTotal.clicks), 0).label("clicks"),
                func.coalesce(func.sum(GSCDailyTotal.impressions), 0).label("impressions"),
            )
            .filter(GSCDailyTotal.site_id.in_(site_ids))
            .filter(GSCDailyTotal.date >= start_d, GSCDailyTotal.date <= end_d)
            .group_by(GSCDailyTotal.site_id)
            .all()
        )
        clicks28 = {sid: c for sid, c, _ in rows}
        impr28   = {sid: i for sid, _, i in rows}

    for s in sites:
        s.clicks_28d      = clicks28.get(s.id, 0)
        s.impressions_28d = impr28.get(s.id, 0)

    return render_template(
        "external_sites.html",
        sites=sites,
        job_map=job_map,
        ExternalSEOJobLog=ExternalSEOJobLog,
    )




@bp.post("/external/start")
@login_required
def start_external_seo() -> "Response":
    """
    HTMX ã‹ã‚‰é€ã‚‰ã‚Œã¦ãã‚‹

        site_id=<æ•°å­—>&blog=<æ–‡å­—åˆ—>

    ã‚’å—ã‘å–ã‚Šã€GPTãƒ™ãƒ¼ã‚¹ã®AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆã‚’å³æ™‚å®Ÿè¡Œã™ã‚‹ã€‚
    - blog=note â†’ run_note_signup()
    - blog=hatena â†’ run_hatena_signup()
    - blog=livedoor â†’ run_livedoor_signup()
    """
    from flask import request, abort, jsonify, render_template
    from app.models import Site
    from app.enums import BlogType  # BlogType Enum
    from app.services.blog_signup import (
        note_signup,
        hatena_signup,
        livedoor_signup,
    )

    site_id = request.form.get("site_id", type=int)
    blog = (request.form.get("blog") or "").lower()

    if not site_id or not blog:
        return "site_id ã¨ blog ã¯å¿…é ˆã§ã™", 400

    # BlogType Enumå¤‰æ›ï¼ˆå­˜åœ¨ã—ãªã„blogãªã‚‰400ï¼‰
    try:
        blog_type = BlogType(blog)
    except ValueError:
        return "ä¸æ­£ãªãƒ–ãƒ­ã‚°ã‚¿ã‚¤ãƒ—", 400

    # ã‚µã‚¤ãƒˆå–å¾—ã¨æ‰€æœ‰æ¨©ãƒã‚§ãƒƒã‚¯ï¼ˆç®¡ç†è€…ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
    site = Site.query.get_or_404(site_id)
    if (not current_user.is_admin) and (site.user_id != current_user.id):
        abort(403)

    # --- ğŸ¯ GPTã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®Ÿè¡Œ ---
    try:
        if blog_type == BlogType.NOTE:
            note_signup.signup(site)
        elif blog_type == BlogType.HATENA:
            hatena_signup.signup(site)
        elif blog_type == BlogType.LIVEDOOR:
            livedoor_signup.signup(site)
        else:
            return f"æœªå¯¾å¿œã®ãƒ–ãƒ­ã‚°: {blog}", 400
    except Exception as e:
        return f"AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¤±æ•—: {str(e)}", 500

    # HTMXå¯¾å¿œ
    if request.headers.get("HX-Request"):
        return render_template(
            "_job_progress.html",
            site_id=site_id,
            blog=blog_type.value,
            job=None
        )
    return jsonify(status="success")



# -----------------------------------------------------------------
# å¤–éƒ¨SEO: é€²æ—ãƒ‘ãƒãƒ« HTMX ç”¨
# -----------------------------------------------------------------
@bp.route("/external/jobs/<int:site_id>")
@login_required
def external_seo_job_status(site_id):
    from app.models import ExternalSEOJob

    job = (ExternalSEOJob.query
           .filter_by(site_id=site_id)
           .order_by(ExternalSEOJob.id.desc())
           .first())

    return render_template("_job_progress.html",
                           job=job,
                           site_id=site_id)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å¤–éƒ¨SEO: æŠ•ç¨¿ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ä¸€è¦§è¡¨ç¤º
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@bp.route("/external/schedules/<int:site_id>")
@login_required
def external_schedules(site_id):
    from app.models import ExternalArticleSchedule, Keyword, ExternalBlogAccount

    # blog_account_id ã‚’ site_id ã§çµã‚‹
    schedules = (
        db.session.query(ExternalArticleSchedule, Keyword, ExternalBlogAccount)
        .join(Keyword, ExternalArticleSchedule.keyword_id == Keyword.id)
        .join(ExternalBlogAccount, ExternalArticleSchedule.blog_account_id == ExternalBlogAccount.id)
        .filter(ExternalBlogAccount.site_id == site_id)
        .order_by(ExternalArticleSchedule.scheduled_date.asc())
        .all()
    )
    return render_template("external_schedules.html",
                           schedules=schedules,
                           site_id=site_id)

from flask import send_file, make_response
from .services.blog_signup.crypto_utils import decrypt
from app.models import ExternalBlogAccount, BlogType
import asyncio, json, time


# -----------------------------------------------------------
# ãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘: è‡ªåˆ†ã®å¤–éƒ¨ãƒ–ãƒ­ã‚°ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä¸€è¦§ï¼ˆæ¤œç´¢ãƒ»çµè¾¼ãƒ»ã‚½ãƒ¼ãƒˆå¯¾å¿œï¼‰
# -----------------------------------------------------------

@bp.route("/external/accounts")
@login_required
def external_accounts():
    from app.models import ExternalBlogAccount, Site, ExternalArticleSchedule, BlogType
    from app.services.blog_signup.crypto_utils import decrypt
    from sqlalchemy import or_, func, case
    from sqlalchemy.orm import aliased

    blog_type = request.args.get("blog_type")
    sort      = request.args.get("sort")
    search    = request.args.get("q", "").strip()
    site_id   = request.args.get("site_id", type=int)

    # ãƒ™ãƒ¼ã‚¹: ãƒ­ã‚°ã‚¤ãƒ³ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚µã‚¤ãƒˆã«å±ã™ã‚‹ï¼ˆsite_id ãŒ NULL ã§ã‚‚å¯ï¼‰
    base = (
        db.session.query(ExternalBlogAccount.id)
        .outerjoin(Site, ExternalBlogAccount.site_id == Site.id)
        .filter(
            (ExternalBlogAccount.site_id == None) |  # noqa: E711
            (Site.user_id == current_user.id)
        )
    )
    if site_id:
        base = base.filter(ExternalBlogAccount.site_id == site_id)
    if blog_type:
        # Enum ã®å¯èƒ½æ€§ã«é…æ…®ï¼ˆæ–‡å­—åˆ—ã§ã‚‚ Enum ã§ã‚‚æ¯”è¼ƒã§ãã‚‹ã‚ˆã†ã«ï¼‰
        try:
            bt = BlogType(blog_type)  # æ–‡å­—åˆ—â†’Enum
            base = base.filter(ExternalBlogAccount.blog_type == bt)
        except Exception:
            base = base.filter(ExternalBlogAccount.blog_type == blog_type)

    if search:
        base = base.filter(or_(
            ExternalBlogAccount.email.ilike(f"%{search}%"),
            ExternalBlogAccount.nickname.ilike(f"%{search}%"),
            ExternalBlogAccount.username.ilike(f"%{search}%"),
        ))

    # é›†è¨ˆã«ä½¿ã†åˆ¥åï¼ˆâ€» JOIN ã¯ schedule ã®ã¿ã€‚Keyword/Article ã«ã¯ JOIN ã—ãªã„ï¼‰
    S = aliased(ExternalArticleSchedule)

    # å„ã‚¢ã‚«ã‚¦ãƒ³ãƒˆè¡Œã”ã¨ã®é›†è¨ˆï¼ˆ1ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ=1è¡Œï¼‰
    # - total_cnt    : COUNT(DISTINCT S.id)
    # - posted_cnt   : SUM(CASE WHEN S.status='posted' THEN 1 ELSE 0 END)
    # - generated_cnt: SUM(CASE WHEN S.article_id IS NOT NULL THEN 1 ELSE 0 END)
    per_acc_rows = (
        db.session.query(
            ExternalBlogAccount,
            func.count(func.distinct(S.id)).label("total_cnt"),
            func.sum(case((S.status == "posted", 1), else_=0)).label("posted_cnt"),
            func.sum(case((S.article_id != None, 1), else_=0)).label("generated_cnt")  # noqa: E711
        )
        .select_from(ExternalBlogAccount)
        .outerjoin(S, S.blog_account_id == ExternalBlogAccount.id)
        .outerjoin(Site, ExternalBlogAccount.site_id == Site.id)
        .filter(base.whereclause)  # ãƒ™ãƒ¼ã‚¹ã®ãƒ•ã‚£ãƒ«ã‚¿ã‚’é©ç”¨
        .group_by(ExternalBlogAccount.id)
        .all()
    )

    # ï¼ˆblog_type, blog_idï¼‰ã§ãƒ¦ãƒ‹ãƒ¼ã‚¯åŒ–ã—ã€ä»£è¡¨1ä»¶ã«é›†è¨ˆã‚’åˆç®—
    def score(acc):
        # ä»£è¡¨é¸å®šå„ªå…ˆåº¦: APIã‚­ãƒ¼ > CAPTCHAæ¸ˆã¿ > id
        return (
            2 if getattr(acc, "atompub_key_enc", None) else
            1 if getattr(acc, "is_captcha_completed", False) else
            0,
            getattr(acc, "id", 0)
        )

    groups = {}  # key -> {"repr": acc, "total":int, "posted":int, "generated":int, "raw":[acc,...]}
    for acc, total_cnt, posted_cnt, generated_cnt in per_acc_rows:
        key_blog_id = acc.livedoor_blog_id or f"__id__:{acc.id}"
        key = (acc.blog_type, key_blog_id)
        g = groups.get(key)
        total_i     = int(total_cnt or 0)
        posted_i    = int(posted_cnt or 0)
        generated_i = int(generated_cnt or 0)

        if not g:
            groups[key] = {
                "repr": acc,
                "total": total_i,
                "posted": posted_i,
                "generated": generated_i,
                "raw": [acc],
            }
        else:
            # ä»£è¡¨ã‚’å·®ã—æ›¿ãˆã‚‹å ´åˆãŒã‚ã‚‹
            if score(acc) > score(g["repr"]):
                g["repr"] = acc
            # é›†è¨ˆã¯åˆç®—
            g["total"]     += total_i
            g["posted"]    += posted_i
            g["generated"] += generated_i
            g["raw"].append(acc)

    # è¡¨ç¤ºç”¨ãƒªã‚¹ãƒˆï¼ˆä»£è¡¨ acc ã«åˆç®—æ¸ˆã¿ã®æ•°å€¤ã‚’æŒãŸã›ã‚‹ï¼‰
    accts = []
    for _, g in groups.items():
        a = g["repr"]
        a.total_cnt     = g["total"]
        a.posted_cnt    = g["posted"]
        a.generated_cnt = g["generated"]
        a._raw_count    = len(g["raw"])  # ä»»æ„ï¼šçµ±åˆä»¶æ•°ï¼ˆè¡¨ç¤ºã—ãŸã‘ã‚Œã°ãƒ†ãƒ³ãƒ—ãƒ¬ã§å‚ç…§ï¼‰
        accts.append(a)

    # ä¸¦ã³æ›¿ãˆï¼ˆãƒ¦ãƒ‹ãƒ¼ã‚¯åŒ–å¾Œã®å€¤ã§ï¼‰
    def sort_key(a):
        if sort == "posted_asc":
            return (a.posted_cnt or 0, a.id)
        if sort == "posted_desc":
            return (-(a.posted_cnt or 0), a.id)
        if sort == "generated_asc":
            return (a.generated_cnt or 0, a.id)
        if sort == "generated_desc":
            return (-(a.generated_cnt or 0), a.id)
        if sort == "total_asc":
            return (a.total_cnt or 0, a.id)
        # default: total_desc
        return (-(a.total_cnt or 0), a.id)

    accts.sort(key=sort_key)

    all_sites = Site.query.filter_by(user_id=current_user.id).all()

    return render_template(
        "external_accounts.html",
        accts=accts,                 # â† ãƒ¦ãƒ‹ãƒ¼ã‚¯åŒ–å¾Œã®ä»£è¡¨ãŸã¡
        all_sites=all_sites,
        decrypt=decrypt,
        site_id=site_id,
        selected_blog_type=blog_type,
        selected_sort=sort,
        search_query=search
    )




@bp.route("/external/account/<int:acct_id>/articles")
@login_required
def external_account_articles(acct_id):
    from app.models import ExternalBlogAccount, ExternalArticleSchedule, Keyword, Article

    acct = ExternalBlogAccount.query.get_or_404(acct_id)
    site = acct.site
    if site.user_id != current_user.id and not current_user.is_admin:
        abort(403)

    rows = (
        db.session.query(ExternalArticleSchedule, Keyword, Article)
        .join(Keyword, ExternalArticleSchedule.keyword_id == Keyword.id)
        .outerjoin(Article, Article.id == ExternalArticleSchedule.article_id)
        .filter(ExternalArticleSchedule.blog_account_id == acct_id)
        # â–¼ ä¿®æ­£ï¼šå¤ã„é †ï¼ˆASCï¼‰ï¼‹ ã‚¿ã‚¤ãƒ–ãƒ¬ãƒ¼ã‚¯ã« schedule.id
        .order_by(ExternalArticleSchedule.scheduled_date.asc(),
                  ExternalArticleSchedule.id.asc())
        .all()
    )

    return render_template(
        "external_articles.html",
        acct=acct, site=site, rows=rows
    )


@bp.route("/external/article/<int:article_id>/preview")
@login_required
def external_article_preview(article_id):
    from app.models import Article

    art = Article.query.get_or_404(article_id)

    if art.user_id != current_user.id and not current_user.is_admin:
        abort(403)

    return render_template("external_article_preview.html", article=art)



# å¤–éƒ¨SEOè¨˜äº‹ ç·¨é›†
@bp.route("/external/article/<int:article_id>/edit", methods=["GET", "POST"])
@login_required
def external_article_edit(article_id):
    from app.models import Article
    art = Article.query.get_or_404(article_id)

    if art.user_id != current_user.id and not current_user.is_admin:
        abort(403)

    if request.method == "POST":
        art.title = request.form.get("title", art.title)
        art.body = request.form.get("body", art.body)
        db.session.commit()
        flash("è¨˜äº‹ã‚’æ›´æ–°ã—ã¾ã—ãŸ", "success")
        # ç¢ºå®Ÿã«æˆ»ã‚Œã‚‹ã‚ˆã†ã«
        return redirect(request.referrer or url_for("main.external_schedules", site_id=art.site_id))

    return render_template("external_article_edit.html", article=art)

# å¤–éƒ¨SEOè¨˜äº‹ å‰Šé™¤
@bp.route("/external/article/<int:article_id>/delete", methods=["POST"])
@login_required
def external_article_delete(article_id):
    from app.models import Article, ExternalArticleSchedule, Keyword

    art = Article.query.get_or_404(article_id)
    if art.user_id != current_user.id and not current_user.is_admin:
        abort(403)

    # Article ã‹ã‚‰ Keyword.id ã‚’å¼•ã
    kw = Keyword.query.filter_by(site_id=art.site_id, keyword=art.keyword).first()

    if kw:
        schedules = ExternalArticleSchedule.query.filter_by(keyword_id=kw.id).all()
        for sched in schedules:
            db.session.delete(sched)

    db.session.delete(art)
    db.session.commit()
    flash("è¨˜äº‹ã‚’å‰Šé™¤ã—ã¾ã—ãŸ", "success")
    # å…ƒç”»é¢ã«æˆ»ã™ï¼ˆacct_id ãŒå–ã‚Œãªã„ã®ã§ referrer å„ªå…ˆï¼‰
    return redirect(request.referrer or url_for("main.external_schedules", site_id=art.site_id))


# å¤–éƒ¨SEOè¨˜äº‹ å³æ™‚æŠ•ç¨¿
@bp.route("/external/schedule/<int:schedule_id>/post_now", methods=["POST"])
@login_required
def external_schedule_post_now(schedule_id):
    from datetime import datetime
    from flask import current_app, request, redirect, url_for, flash, abort
    from flask_login import current_user
    from app import db
    from app.models import ExternalArticleSchedule
    from app.tasks import _run_external_post_job  # â† ã“ã“ã‚’ä¿®æ­£

    sched = ExternalArticleSchedule.query.get_or_404(schedule_id)
    acct = sched.blog_account
    site = acct.site

    # æ‰€æœ‰æ¨©ãƒã‚§ãƒƒã‚¯
    if site.user_id != current_user.id and not current_user.is_admin:
        abort(403)

    # ç›´ã¡ã«å®Ÿè¡Œå¯¾è±¡ã¸ï¼ˆUTC naiveï¼‰
    sched.scheduled_date = datetime.utcnow()
    sched.status = "pending"
    db.session.commit()

    try:
        # pending ã‚’å‡¦ç†
        _run_external_post_job(current_app._get_current_object(), schedule_id=schedule_id)
        flash("å³æ™‚æŠ•ç¨¿ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãã—ã¦ãƒšãƒ¼ã‚¸ã‚’æ›´æ–°ã—ã¦ãã ã•ã„ã€‚", "success")
    except Exception as e:
        current_app.logger.exception("[external] post_now failed")
        flash(f"å³æ™‚æŠ•ç¨¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}", "danger")

    return redirect(request.referrer or url_for("main.external_account_articles", acct_id=acct.id))

# --- ä¸€æ‹¬å‰Šé™¤: å¤–éƒ¨ãƒ–ãƒ­ã‚°ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ + äºˆç´„ +ï¼ˆå®‰å…¨æ¡ä»¶ä¸‹ã®ï¼‰ç”Ÿæˆè¨˜äº‹ ---
@bp.post("/external/account/<int:acct_id>/delete")
@login_required
def external_account_delete(acct_id):
    from app.models import (
        ExternalBlogAccount, ExternalArticleSchedule, Keyword, Article, Site
    )
    from sqlalchemy import exists, and_, select
    from app import db

    acct = ExternalBlogAccount.query.get_or_404(acct_id)
    site: Site = acct.site

    # æ¨©é™
    if not current_user.is_admin and site.user_id != current_user.id:
        return {"ok": False, "error": "æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“"}, 403

    # ã¾ãšã€ã“ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®å…¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å–å¾—ï¼ˆKeywordã‚‚ä½¿ã†ãŸã‚IDã‚’ä¿æŒï¼‰
    schedules = (
        db.session.query(ExternalArticleSchedule)
        .filter(ExternalArticleSchedule.blog_account_id == acct.id)
        .all()
    )
    keyword_ids = [s.keyword_id for s in schedules if getattr(s, "keyword_id", None)]
    # IDâ†’ãƒ†ã‚­ã‚¹ãƒˆã‚’å¾—ã‚‹ï¼ˆArticleã¯ keyword(ãƒ†ã‚­ã‚¹ãƒˆ) åŸºæº–ã§ç´ä»˜ã‘ã‚‰ã‚Œã¦ã„ã‚‹ãŸã‚ï¼‰
    kw_texts = []
    if keyword_ids:
        kw_texts = [
            k.keyword for k in db.session.query(Keyword).filter(Keyword.id.in_(keyword_ids)).all()
        ]

    # ã“ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä»¥å¤–ã§ã‚‚åŒã˜ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰IDãŒä½¿ã‚ã‚Œã¦ã„ã‚‹ã‹ï¼ˆæ®‹ã™æ¡ä»¶ï¼‰
    # â†’ Articleã¯ã€ŒåŒã˜ keyword ãƒ†ã‚­ã‚¹ãƒˆã€ã‚’å…±æœ‰ã—å¾—ã‚‹ã®ã§ã€
    #   â€œä»–ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®äºˆç´„ãŒåŒä¸€KeywordIDã‚’å‚ç…§ã—ã¦ã„ãªã„â€è¨˜äº‹ã®ã¿å‰Šé™¤å¯¾è±¡ã¨ã™ã‚‹
    if kw_texts:
        # schedules ãƒ†ãƒ¼ãƒ–ãƒ«ã§ â€œåŒä¸€ keyword_id ã‹ã¤ åˆ¥ã‚¢ã‚«ã‚¦ãƒ³ãƒˆâ€ ãŒå­˜åœ¨ã—ãªã„ã“ã¨ã‚’æ¡ä»¶ã« Article ã‚’å‰Šé™¤
        # Article ã¯ site_id ã¨ source='external' ã§é™å®š
        subq_other = (
            db.session.query(ExternalArticleSchedule.id)
            .filter(
                ExternalArticleSchedule.keyword_id.in_(keyword_ids),
                ExternalArticleSchedule.blog_account_id != acct.id
            )
            .exists()
        )
        # å‰Šé™¤å¯¾è±¡ Article ã®é¸åˆ¥
        articles_q = (
            db.session.query(Article)
            .filter(
                Article.site_id == site.id,
                Article.source == "external",
                Article.keyword.in_(kw_texts),
                ~subq_other   # ä»–ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®äºˆç´„ãŒç„¡ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã¿
            )
        )
        deleted_articles = articles_q.delete(synchronize_session=False)
    else:
        deleted_articles = 0

    # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å‰Šé™¤
    db.session.query(ExternalArticleSchedule)\
        .filter(ExternalArticleSchedule.blog_account_id == acct.id)\
        .delete(synchronize_session=False)

    # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå‰Šé™¤
    db.session.delete(acct)
    db.session.commit()

    return {"ok": True, "deleted_articles": int(deleted_articles)}


# -----------------------------------------------------------------
# Livedoor æ‰‹å‹•ä¿å­˜: APIã‚­ãƒ¼/ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# -----------------------------------------------------------------
@bp.post("/external/livedoor/credentials/save")
@login_required
def livedoor_credentials_save():
    """
    å…¥åŠ›: site_id, account_id, blog_id, endpoint, api_key
    æ©Ÿèƒ½: æ¤œè¨¼ãƒ»æ­£è¦åŒ–ã—ã¦ä¿å­˜ï¼ˆDBå„ªå…ˆ / æš«å®šJSONãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
    æˆ»ã‚Š: { ok: true, masked_key: "â€¢â€¢â€¢â€¢abcd", status: "unknown" } or { ok:false, error:"..." }
    """
    from flask import request, jsonify, abort
    from app import db
    from app.models import Site, ExternalBlogAccount, BlogType
    import re, urllib.parse
    # æš«å®šãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆDBæœªå¯¾å¿œç’°å¢ƒï¼‰: JSONä¿å­˜é–¢æ•°
    try:
        from app.services.blog_signup.livedoor_signup import save_livedoor_credentials as _json_save
    except Exception:
        _json_save = None

    def _mask_tail(s: str, n: int = 4) -> str:
        if not s:
            return ""
        tail = s[-n:] if len(s) >= n else s
        return "â€¢â€¢â€¢â€¢" + tail

    def _normalize_endpoint(raw: str) -> str:
        v = (raw or "").strip()
        if not v:
            return v
        # ã‚¹ã‚­ãƒ¼ãƒ ä»˜ä¸
        if not re.match(r"^https?://", v, re.I):
            v = "https://" + v
        # ä½™è¨ˆãªç©ºç™½ã‚„é€£ç¶šã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã®æ•´ç†ï¼ˆãƒ—ãƒ­ãƒˆã‚³ãƒ«éƒ¨ã¯é™¤ãï¼‰
        parts = urllib.parse.urlsplit(v)
        path = re.sub(r"/{2,}", "/", parts.path or "/")
        # /atompub ãŒå«ã¾ã‚Œã¦ã„ãªã‘ã‚Œã°ä»˜ä¸ï¼ˆæœ«å°¾ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã¯1ã¤ã«ï¼‰
        if not re.search(r"/atompub/?$", path, re.I):
            path = path.rstrip("/") + "/atompub"
        path = path.rstrip("/")  # æœ€çµ‚çš„ã«æœ«å°¾ã‚¹ãƒ©ãªã—ã«çµ±ä¸€
        v2 = urllib.parse.urlunsplit((parts.scheme, parts.netloc, path, parts.query, parts.fragment))
        return v2

    def _validate_blog_id(bid: str) -> bool:
        return bool(re.match(r"^[a-z0-9_]{3,20}$", (bid or "").strip()))

    # --- å…¥åŠ›å–å¾—ï¼ˆJSON or formï¼‰ ---
    getv = (request.get_json(silent=True) or request.form)
    site_id    = getv.get("site_id", type=int)
    account_id = getv.get("account_id", type=int)
    blog_id    = (getv.get("blog_id") or "").strip()
    endpoint   = (getv.get("endpoint") or "").strip()
    api_key    = (getv.get("api_key") or "").strip()

    if not site_id or not account_id:
        return jsonify(ok=False, error="site_id ã¨ account_id ã¯å¿…é ˆã§ã™"), 400
    if not blog_id or not endpoint or not api_key:
        return jsonify(ok=False, error="blog_id / endpoint / api_key ã¯å¿…é ˆã§ã™"), 400
    if not _validate_blog_id(blog_id):
        return jsonify(ok=False, error="blog_id ã®å½¢å¼ãŒä¸æ­£ã§ã™ï¼ˆåŠè§’è‹±æ•°+_ 3ã€œ20 æ–‡å­—ï¼‰"), 400

    # æ‰€æœ‰æ¨©
    site = Site.query.get_or_404(site_id)
    if (not current_user.is_admin) and (site.user_id != current_user.id):
        abort(403)
    acct = ExternalBlogAccount.query.get_or_404(account_id)
    if acct.site_id != site.id and (not current_user.is_admin):
        return jsonify(ok=False, error="ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãŒã‚µã‚¤ãƒˆã«å±ã—ã¦ã„ã¾ã›ã‚“"), 400
    # Livedoor ä»¥å¤–ã¯æ‹’å¦
    if getattr(acct, "blog_type", None) != BlogType.LIVEDOOR:
        return jsonify(ok=False, error="ã“ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã¯ Livedoor ã§ã¯ã‚ã‚Šã¾ã›ã‚“"), 400

    # æ­£è¦åŒ–
    endpoint_norm = _normalize_endpoint(endpoint)
    if not re.match(r"^https://[^/]+/.*", endpoint_norm, re.I):
        return jsonify(ok=False, error="endpoint URL ãŒä¸æ­£ã§ã™"), 400

    # --- ä¿å­˜ï¼ˆDBå„ªå…ˆ / ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯JSONï¼‰ ---
    saved = False
    try:
        # ã§ãã‚‹ã ã‘åºƒããƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«å¯¾å¿œï¼ˆç’°å¢ƒå·®ç•°ã‚’å¸åï¼‰
        if hasattr(acct, "livedoor_blog_id"):
            acct.livedoor_blog_id = blog_id
        if hasattr(acct, "atompub_endpoint"):
            acct.atompub_endpoint = endpoint_norm
        if hasattr(acct, "atompub_key_enc"):
            # æš—å·åŒ–ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æƒ³å®š
            acct.atompub_key_enc = api_key
        elif hasattr(acct, "api_key"):
            # å¹³æ–‡ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒã‚ã‚‹ç’°å¢ƒå‘ã‘
            acct.api_key = api_key
        # æœªãƒ†ã‚¹ãƒˆçŠ¶æ…‹ã«æˆ»ã™ï¼ˆBoolean/Nullable ä¸¡å¯¾å¿œï¼‰
        if hasattr(acct, "api_post_enabled"):
            try:
                acct.api_post_enabled = None
            except Exception:
                pass
        db.session.commit()
        saved = True
    except Exception:
        db.session.rollback()
        saved = False

    # DBãŒä½¿ãˆãªã„ï¼ˆã¾ãŸã¯å¤±æ•—ï¼‰ç’°å¢ƒã§ã¯æš«å®šJSONã«ä¿å­˜
    if not saved:
        if _json_save is None:
            return jsonify(ok=False, error="ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆDB/JSONã¨ã‚‚ã«ä¸å¯ï¼‰"), 500
        try:
            _json_save(
                site_id=site_id,
                account_id=account_id,
                livedoor_blog_id=blog_id,
                endpoint=endpoint_norm,
                api_key=api_key,
            )
        except Exception as e:
            return jsonify(ok=False, error=f"ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"), 500

    return jsonify(ok=True, masked_key=_mask_tail(api_key, 4), status="unknown")


# -----------------------------------------------------------------
# Livedoor æ¥ç¶šãƒ†ã‚¹ãƒˆï¼ˆè»½é‡ AtomPub GETï¼‰
# -----------------------------------------------------------------
@bp.post("/external/livedoor/credentials/test")
@login_required
def livedoor_credentials_test():
    """
    å…¥åŠ›: site_id, account_id
    æ©Ÿèƒ½: ä¿å­˜æ¸ˆã¿ blog_id / endpoint / api_key ã§è»½é‡æ¥ç¶šç¢ºèª
    æˆ»ã‚Š: { ok:true } ã‚‚ã—ãã¯ { ok:false, detail:"..." }
    å‰¯ä½œç”¨: ExternalBlogAccount.api_post_enabled ã‚’ True/False ã«æ›´æ–°
    """
    from flask import request, jsonify, abort
    from app import db
    from app.models import Site, ExternalBlogAccount, BlogType
    import requests

    # livedoor_atompub å´ã« probe é–¢æ•°ãŒã‚ã‚Œã°åˆ©ç”¨ã€ç„¡ã‘ã‚Œã°ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    try:
        from app.services.livedoor_atompub import probe_auth as _probe_auth
    except Exception:
        _probe_auth = None

    getv = (request.get_json(silent=True) or request.form)
    site_id    = getv.get("site_id", type=int)
    account_id = getv.get("account_id", type=int)
    if not site_id or not account_id:
        return jsonify(ok=False, detail="site_id ã¨ account_id ã¯å¿…é ˆã§ã™"), 400

    site = Site.query.get_or_404(site_id)
    if (not current_user.is_admin) and (site.user_id != current_user.id):
        abort(403)
    acct = ExternalBlogAccount.query.get_or_404(account_id)
    if acct.site_id != site.id and (not current_user.is_admin):
        return jsonify(ok=False, detail="ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãŒã‚µã‚¤ãƒˆã«å±ã—ã¦ã„ã¾ã›ã‚“"), 400
    if getattr(acct, "blog_type", None) != BlogType.LIVEDOOR:
        return jsonify(ok=False, detail="ã“ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã¯ Livedoor ã§ã¯ã‚ã‚Šã¾ã›ã‚“"), 400

    blog_id  = getattr(acct, "livedoor_blog_id", None)
    endpoint = getattr(acct, "atompub_endpoint", None)
    # ã‚­ãƒ¼ã¯ç’°å¢ƒã«ã‚ˆã‚Šãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åãŒç•°ãªã‚Šã†ã‚‹
    api_key  = getattr(acct, "atompub_key_enc", None) or getattr(acct, "api_key", None)
    if not (blog_id and endpoint and api_key):
        return jsonify(ok=False, detail="è¨­å®šãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆblog_id / endpoint / api_keyï¼‰"), 400

    ok = False
    detail = ""
    try:
        if callable(_probe_auth):
            # æ—¢å­˜ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’æœ€å„ªå…ˆ
            # æœŸå¾…: æˆ»ã‚Šå€¤ True/Falseã€ä¾‹å¤–ã§ã‚¨ãƒ©ãƒ¼è©³ç´°
            ok = bool(_probe_auth(endpoint=endpoint, api_key=api_key, blog_id=blog_id))
            detail = "" if ok else "èªè¨¼ã‚¨ãƒ©ãƒ¼"
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æœ€å°ã® GET ã‚’æŠ•ã’ã€200/401/403 ã§åˆ¤å®šï¼ˆè¶…è»½é‡ï¼‰
            # èªè¨¼ãƒ˜ãƒƒãƒ€æ–¹å¼ãŒç’°å¢ƒä¾å­˜ã®ãŸã‚ã€ã“ã“ã§ã¯ç–é€š/èªè¨¼å¤±æ•—ã®å¤§æ ã®ã¿ã‚’åˆ¤å®š
            try:
                resp = requests.get(endpoint, timeout=6)
                if resp.status_code // 100 == 2:
                    ok = True
                elif resp.status_code in (401, 403):
                    ok = False
                    detail = "èªè¨¼ã‚¨ãƒ©ãƒ¼"
                else:
                    ok = False
                    detail = f"HTTP {resp.status_code}"
            except requests.Timeout:
                ok = False
                detail = "ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ"
    except Exception as e:
        ok = False
        detail = f"æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}"

    # ãƒ•ãƒ©ã‚°æ›´æ–°ï¼ˆNullable/Boolean ã‚’è¨±å®¹ï¼‰
    try:
        if hasattr(acct, "api_post_enabled"):
            acct.api_post_enabled = True if ok else False
        db.session.commit()
    except Exception:
        db.session.rollback()

    if ok:
        return jsonify(ok=True)
    return jsonify(ok=False, detail=(detail or "æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ")), 200


# -----------------------------------------------------------
# ç®¡ç†è€…å‘ã‘: å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¤–éƒ¨ãƒ–ãƒ­ã‚°ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä¸€è¦§
# -----------------------------------------------------------
@admin_bp.route("/admin/blog_accounts")
@login_required
def admin_blog_accounts():
    if not current_user.is_admin:
        abort(403)

    from app.models import ExternalBlogAccount
    from app.services.blog_signup.crypto_utils import decrypt

    accts = (ExternalBlogAccount
             .query.order_by(ExternalBlogAccount.created_at.desc())
             .all())

    # â˜… ãƒ‘ã‚¹ã‚’ "admin/xxx.html" ã«å¤‰æ›´
    return render_template(
        "admin/admin_blog_accounts.html",
        accts    = accts,
        decrypt  = decrypt,
    )


# ---------------------------------------------------------
# ğŸ” ç®¡ç†è€…å°‚ç”¨ï¼šãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯ã§å¯¾è±¡ãƒ–ãƒ­ã‚°ã¸ãƒ­ã‚°ã‚¤ãƒ³ã™ã‚‹ä¸­é–“ãƒšãƒ¼ã‚¸
# ---------------------------------------------------------
# app/routes.py ãªã©
from flask import Blueprint, request, abort, render_template_string
from flask_login import login_required, current_user
from app import db


# ---------------------------------------------------------
# ğŸ” ç®¡ç†è€…å°‚ç”¨ï¼šãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯è‡ªå‹•ãƒ­ã‚°ã‚¤ãƒ³
# ---------------------------------------------------------
@admin_bp.route("/admin/blog_login", methods=["POST"])
@login_required
def admin_blog_login():
    """
    ç®¡ç†è€…ãŒã€Œãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯ãƒ­ã‚°ã‚¤ãƒ³ã€ã‚’æŠ¼ã—ãŸæ™‚ã«å‘¼ã³å‡ºã•ã‚Œã‚‹ã€‚
    - å¯¾å¿œã‚µãƒ¼ãƒ“ã‚¹ (note / hatena â€¦) ã¯è‡ªå‹• POST
    - æœªå¯¾å¿œã‚µãƒ¼ãƒ“ã‚¹ã¯è³‡æ ¼æƒ…å ±ã‚’è¡¨ç¤º
    """
    if not current_user.is_admin:
        abort(403)

    from app.models import ExternalBlogAccount
    from app.services.blog_signup.crypto_utils import decrypt

    acct_id = request.form.get("account_id", type=int)
    if not acct_id:
        abort(400, "account_id missing")

    acct: ExternalBlogAccount | None = ExternalBlogAccount.query.get(acct_id)
    if not acct:
        abort(404, "account not found")

    email    = decrypt(acct.email)
    password = decrypt(acct.password)
    username = acct.username

    login_map = {
        "note": {
            "url": "https://note.com/login",
            "user_field": "email",
            "pass_field": "password",
        },
        "hatena": {
            "url": "https://www.hatena.ne.jp/login",
            "user_field": "name",
            "pass_field": "password",
        },
        # ã“ã“ã«ä»–ãƒ–ãƒ­ã‚°ã‚’è¿½åŠ 
    }

    cfg = login_map.get(acct.blog_type.value)

    # --- å¯¾å¿œãƒ–ãƒ­ã‚°ï¼šè‡ªå‹• POST ãƒ•ã‚©ãƒ¼ãƒ  ----
    if cfg:
        return f"""
        <!doctype html><html lang="ja"><head><meta charset="utf-8">
        <title>auto-login</title></head><body>
          <p style="font-family:sans-serif;margin-top:2rem">
            {acct.blog_type.value} ã«ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆä¸­â€¦
          </p>
          <form id="f" action="{cfg['url']}" method="post">
            <input type="hidden" name="{cfg['user_field']}" value="{email}">
            <input type="hidden" name="{cfg['pass_field']}" value="{password}">
          </form>
          <script>setTimeout(()=>document.getElementById('f').submit(), 300);</script>
        </body></html>
        """

    # --- æœªå¯¾å¿œãƒ–ãƒ­ã‚°ï¼šè³‡æ ¼æƒ…å ±è¡¨ç¤º ----
    return render_template_string("""
      <!doctype html><html lang="ja"><head><meta charset="utf-8">
      <title>è³‡æ ¼æƒ…å ±</title></head><body style="font-family:sans-serif">
        <h2>æ‰‹å‹•ãƒ­ã‚°ã‚¤ãƒ³ãŒå¿…è¦ã§ã™</h2>
        <ul>
          <li><b>ã‚µãƒ¼ãƒ“ã‚¹</b>: {{ blog }}</li>
          <li><b>ãƒ¦ãƒ¼ã‚¶ãƒ¼å</b>: {{ uname }}</li>
          <li><b>ãƒ¡ãƒ¼ãƒ«</b>: {{ mail }}</li>
          <li><b>ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰</b>: {{ pwd }}</li>
        </ul>
      </body></html>
    """, blog=acct.blog_type.value, uname=username, mail=email, pwd=password)



# -----------------------------------------------------------
# ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯ãƒ­ã‚°ã‚¤ãƒ³ 
# -----------------------------------------------------------
@bp.route("/external/login/<int:acct_id>")
@login_required
def blog_one_click_login(acct_id):
    acct = ExternalBlogAccount.query.get_or_404(acct_id)
    if not (current_user.is_admin or acct.site.user_id == current_user.id):
        abort(403)

    from app.services.blog_signup.crypto_utils import decrypt

    if acct.blog_type == BlogType.NOTE:
        from app.services.blog_signup.note_login import get_note_cookies
        cookies = asyncio.run(get_note_cookies(decrypt(acct.email), decrypt(acct.password)))
        resp = make_response(redirect("https://note.com"))
        for c in cookies:
            resp.set_cookie(
                key=c["name"], value=c["value"],
                domain=".note.com", path="/", secure=True, httponly=True,
                samesite="Lax", expires=int(time.time()) + 60*60
            )
        return resp

    elif acct.blog_type == BlogType.LIVEDOOR:
        # â˜… è¿½åŠ ï¼šLivedoorå¯¾å¿œ
        from app.services.blog_signup.livedoor_login import get_livedoor_cookies
        cookies = asyncio.run(get_livedoor_cookies(decrypt(acct.email), decrypt(acct.password)))
        # ç®¡ç†ç”»é¢å´ã«å…¥ã‚Œã‚‹
        resp = make_response(redirect("https://livedoor.blogcms.jp/member/"))
        for c in cookies:
            resp.set_cookie(
                key=c["name"], value=c["value"],
                domain=c.get("domain", ".livedoor.com"),
                path="/", secure=True, httponly=True,
                samesite="Lax", expires=int(time.time()) + 60*60
            )
        return resp

    else:
        abort(400, "Login not supported yet")



# ====== ãƒ«ãƒ¼ãƒˆå…ˆé ­ã® import ä»˜è¿‘ã«è¿½è¨˜/ç½®æ› ======
from flask import session as flask_session  # æ—¢ã«ã‚ã‚Œã°OK
from app.services.blog_signup.livedoor_signup import (
    generate_safe_id, generate_safe_password,
    prepare_captcha as ld_prepare_captcha,   # æ–°APIå
    submit_captcha as ld_submit_captcha,     # æ–°APIå
    suggest_livedoor_blog_id,
    poll_latest_link_gw,                     # ãƒ¡ãƒ¼ãƒ«èªè¨¼ãƒªãƒ³ã‚¯å–å¾—
    generate_livedoor_id_candidates,         # â˜… è¿½åŠ ï¼šå®Ÿéš›ã«åˆ©ç”¨ã—ã¦ã„ã‚‹ãŸã‚
)
from app.services.mail_utils.mail_gw import create_inbox
from app.services.blog_signup.livedoor_atompub_recover import recover_atompub_key
from app.services.pw_controller import pwctl  # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®æ˜ç¤ºã‚¯ãƒ­ãƒ¼ã‚ºç”¨
# æ—¢å­˜ import ç¾¤ã®è¿‘ãã«è¿½è¨˜
from flask import current_app  # submit_captcha ã§ä½¿ã£ã¦ã„ã‚‹ãŸã‚
from app.services.pw_session_store import (
    save as pw_save,
    get_cred as pw_get,
    clear as pw_clear,
)
# â€» pw_set ã¯å­˜åœ¨ã—ãªã„ãŸã‚ import ã—ãªã„ï¼ˆImportErrorå¯¾ç­–ï¼‰

# ====== /prepare_captcha ======
@bp.route("/prepare_captcha", methods=["POST"])
@login_required
def prepare_captcha():
    from app.models import Site, ExternalBlogAccount
    from app import db
    from flask import jsonify, request, url_for
    from uuid import uuid4
    from pathlib import Path
    import time as _time
    import logging
    logger = logging.getLogger(__name__)

    # ---------- âœ… è¿½åŠ : DBã‚³ãƒŸãƒƒãƒˆã‚’å …ç‰¢åŒ– ----------
    def safe_commit(session, retries: int = 1) -> bool:
        """
        OperationalError(åˆ‡æ–­ãªã©)æ™‚ã« rollbackâ†’æœ€å¤§1å›ã ã‘å†å®Ÿè¡Œã€‚
        å¤±æ•—ã—ãŸã‚‰ Falseã€‚ãã®ä»–ã®ä¾‹å¤–ã¯ä¸Šä½ã¸æŠ•ã’ãªã„ï¼ˆå‘¼ã³å‡ºã—å´ã§æ¡ã‚Šã¤ã¶ã™æ–¹é‡ï¼‰ã€‚
        """
        try:
            session.commit()
            return True
        except OperationalError as e:
            try:
                current_app.logger.warning("safe_commit: OperationalError on commit, retrying once: %s", e)
                session.rollback()
                session.commit()
                return True
            except OperationalError as e2:
                current_app.logger.exception("safe_commit: retry failed: %s", e2)
                session.rollback()
                return False
        except Exception:
            # ã“ã“ã§ã¯å …ãå¤±æ•—ã«å€’ã™ï¼ˆå‘¼ã³å‡ºã—å´ã§æ¡ã‚Šã¤ã¶ã™è¨­è¨ˆï¼‰
            current_app.logger.exception("safe_commit: non-OperationalError on commit")
            session.rollback()
            return False

    site_id    = request.form.get("site_id", type=int)
    blog       = request.form.get("blog")  # "livedoor"
    account_id = request.form.get("account_id", type=int)

    if not site_id or not blog:
        return jsonify({"captcha_url": None, "error": "site_id ã¾ãŸã¯ blog ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“",
                        "site_id": site_id, "account_id": account_id})

    site = Site.query.get(site_id)
    if not site or (not current_user.is_admin and site.user_id != current_user.id):
        return jsonify({"captcha_url": None, "error": "æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“",
                        "site_id": site_id, "account_id": account_id})

    # æ‰€æœ‰ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæ¤œè¨¼ï¼ˆä»»æ„ï¼‰
    acct = ExternalBlogAccount.query.get(account_id) if account_id else None
    if acct:
        if acct.site_id != site_id:
            return jsonify({"captcha_url": None, "error": "account_id ãŒ site_id ã«å±ã—ã¦ã„ã¾ã›ã‚“",
                            "site_id": site_id, "account_id": account_id})
        if (not current_user.is_admin) and (acct.site.user_id != current_user.id):
            return jsonify({"captcha_url": None, "error": "æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“",
                            "site_id": site_id, "account_id": account_id})

    # ä»®ç™»éŒ²ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ¡ãƒ¼ãƒ« & å€™è£œ blog_idï¼‰
    email, token = create_inbox()  # æ—¢å­˜
    if not (email and token):
        return jsonify({"ok": False, "error": "mailbox_init_failed"}), 500

    desired_blog_id = request.form.get("blog_id") or request.form.get("sub") or None
    # è‹±å­—é–‹å§‹ãƒ»3â€“20ãƒ»è‹±æ•°ï¼‹_ æº–æ‹ ã®å€™è£œãƒ­ã‚¸ãƒƒã‚¯ã‚’æ¡ç”¨
    livedoor_id  = generate_livedoor_id_candidates(site)[0]
    password     = generate_safe_password()

    try:
        base_text = site.name or site.url or ""
        desired_blog_id = suggest_livedoor_blog_id(base_text, db.session)
    except Exception:
        desired_blog_id = None

    # â–¶ æ–°API: Playwright ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œã£ã¦ CAPTCHA ç”»åƒã‚’ä¿å­˜
    try:
        session_id, img_abs_path = ld_prepare_captcha(email, livedoor_id, password)
    except Exception:
        logger.exception("[prepare_captcha] CAPTCHAç”Ÿæˆã§ä¾‹å¤–ãŒç™ºç”Ÿ")
        return jsonify({"captcha_url": None, "error": "CAPTCHAã®æº–å‚™ã«å¤±æ•—ã—ã¾ã—ãŸ",
                        "site_id": site_id, "account_id": account_id})
    
    # â˜… è¿½åŠ ï¼šè³‡æ ¼æƒ…å ±ã‚’ sid å˜ä½ã§ä¿å­˜ï¼ˆãƒ•ã‚©ãƒ¼ãƒ ã‚„ Flask ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¾å­˜ã—ãªã„ï¼‰
    pw_save(session_id,
            email=email,
            password=password,
            livedoor_id=livedoor_id,
            token=token,
            site_id=site_id,
            account_id=account_id,
            desired_blog_id=desired_blog_id)
    
    # è¿½åŠ ä¿å­˜ã¯ä¸è¦ã€‚/submit_captcha ã¯ pw_session_store.pw_get(session_id) ã‚’å‚ç…§ã™ã‚‹å‰æ

    # ç”»åƒURLåŒ–
    img_name = Path(img_abs_path).name
    ts = int(_time.time())
    captcha_url = url_for("static", filename=f"captchas/{img_name}", _external=True) + f"?v={ts}"

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿æŒï¼ˆæ¬¡ã® /submit_captcha ç”¨ï¼‰
    flask_session.update({
        "captcha_email": email,
        "captcha_nickname": livedoor_id,
        "captcha_password": password,
        "captcha_token": token,
        "captcha_site_id": site_id,
        "captcha_blog": blog,
        "captcha_image_filename": img_name,
        "captcha_session_id": session_id,
        "captcha_account_id": account_id,
        "captcha_desired_blog_id": desired_blog_id,
    })

    # ä»»æ„ï¼šDBãƒ­ã‚°
    if acct:
        acct.captcha_session_id = session_id
        acct.captcha_image_path = f"captchas/{img_name}"
        # âœ… DBæ›¸ãè¾¼ã¿ã¯â€œä»»æ„â€ã€‚å¤±æ•—ã—ã¦ã‚‚UIã¯ session_id ã§å›å¾©ã§ãã‚‹ãŸã‚æˆåŠŸè¿”å´ã‚’å„ªå…ˆ
        if not safe_commit(db.session, retries=1):
            current_app.logger.warning(
                "[prepare_captcha] DBæ›´æ–°(å¤–éƒ¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã¸ã®captcha_session_idè¨­å®š)ã«å¤±æ•—ã—ã¾ã—ãŸãŒç¶šè¡Œã—ã¾ã™ "
                "(site_id=%s account_id=%s session_id=%s)", site_id, account_id, session_id
            )

    return jsonify({
        "ok": True,
        "captcha_url": captcha_url,
        "site_id": site_id,
        "account_id": account_id,
        # â† â˜… ã“ã‚Œã‚’å¿…ãšè¿”ã™ï¼ˆãƒ•ãƒ­ãƒ³ãƒˆãŒ submit æ™‚ã«åŒå°ï¼‰
        "session_id": session_id,
        # token è‡ªä½“ã¯è¿”ã•ãªã„æ–¹ãŒå®‰å…¨ã€‚ä¿å­˜ã§ããŸã‹ã®ãƒ•ãƒ©ã‚°ã ã‘è¿”ã™
        "token_saved": True
    })


# ====== /submit_captcha ======
@bp.route("/submit_captcha", methods=["POST"])
@login_required
def submit_captcha():
    from app.services.blog_signup.crypto_utils import encrypt
    from app.models import Site, ExternalBlogAccount
    from app.enums import BlogType
    from app.utils.captcha_dataset_utils import save_captcha_label_pair
    from app import db
    from flask import jsonify, session, request, current_app
    import logging, contextlib, asyncio
    import time

    logger = logging.getLogger(__name__)
    # ãƒãƒ³ãƒ‰ã‚ªãƒ•ä¸­ã¯å¾Œç‰‡ä»˜ã‘ã‚’æŠ‘æ­¢ã™ã‚‹ãƒ•ãƒ©ã‚°
    keep_pw_session = False
    # finally ã§å‚ç…§ã™ã‚‹ã®ã§å…ˆã«ç”¨æ„ã—ã¦ãŠãï¼ˆæœªå®šç¾©å‚ç…§å¯¾ç­–ï¼‰
    token = None
    captcha_text = request.form.get("captcha_text")
    if not captcha_text:
        return jsonify({"status": "error", "message": "CAPTCHAæ–‡å­—åˆ—ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“"}), 400

    # å­¦ç¿’ç”¨ä¿å­˜
    img_name = session.get("captcha_image_filename")
    if captcha_text and img_name:
        with contextlib.suppress(Exception):
            save_captcha_label_pair(img_name, captcha_text)

    # â˜… ã¾ãšãƒ•ã‚©ãƒ¼ãƒ å„ªå…ˆã§å—ã‘ã‚‹ï¼ˆãƒ–ãƒ©ã‚¦ã‚¶ã® Flask ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒç©ºã§ã‚‚å¾©æ—§ã§ãã‚‹ï¼‰
    site_id    = request.form.get("site_id", type=int) or session.get("captcha_site_id")
    account_id = request.form.get("account_id", type=int) or session.get("captcha_account_id")
    session_id = request.form.get("session_id") or session.get("captcha_session_id")

    # â˜… ã‚µãƒ¼ãƒãƒ¼å´ã‚¹ãƒˆã‚¢ã‹ã‚‰è³‡æ ¼æƒ…å ±ã‚’å¾©å…ƒï¼ˆãƒ•ã‚©ãƒ¼ãƒ /Flaskã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒç©ºã§ã‚‚OKï¼‰
    cred = pw_get(session_id) if session_id else None

    email = (
        request.form.get("email")
        or session.get("captcha_email")
        or (cred and cred.get("email"))
    )
    password = (
        request.form.get("password")
        or session.get("captcha_password")
        or (cred and cred.get("password"))
    )
    livedoor_id = (
        request.form.get("livedoor_id")
        or session.get("captcha_nickname")
        or (cred and cred.get("livedoor_id"))
    )

    # URLã‚µãƒ–ãƒ‰ãƒ¡ã‚¤ãƒ³=ãƒ¦ãƒ¼ã‚¶ãƒ¼IDï¼ˆå¸Œæœ›å€¤ï¼‰ã€‚ç„¡ã‘ã‚Œã° livedoor_id ã‚’ä½¿ã†
    desired_blog_id = (
        request.form.get("desired_blog_id")
        or request.form.get("blog_id")
        or request.form.get("sub")
        or session.get("captcha_desired_blog_id")
        or (cred and cred.get("desired_blog_id"))
        or livedoor_id
    )


    if not all([site_id, session_id, account_id]):
        return jsonify({"status": "error", "message": "ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™"}), 400

    site = Site.query.get(site_id)
    acct = ExternalBlogAccount.query.get(account_id)
    if not site or not acct or acct.site_id != site_id:
        return jsonify({"status": "error", "message": "å¯¾è±¡ãŒä¸æ­£ã§ã™"}), 400
    if (not current_user.is_admin) and (site.user_id != current_user.id):
        return jsonify({"status": "error", "message": "æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“"}), 403

    ok = False
    try:
        # â–¶ æ–°API: åŒä¸€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ CAPTCHA é€ä¿¡ â†’ /register/done ã‚’å¾…æ©Ÿ
        ok = ld_submit_captcha(session_id, captcha_text)
    except Exception:
        logger.exception("[submit_captcha] CAPTCHAé€ä¿¡ã§ä¾‹å¤–")
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯å¾Œã§å¿…ãšç ´æ£„
        return jsonify({"status": "error", "message": "CAPTCHAé€ä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸ"}), 500

    if not ok:
        # å¤±æ•—æ™‚ã¯ä¸­é–“ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆã‚ã‚Œã°ï¼‰
        try:
            if acct and not getattr(acct, "atompub_key_enc", None):
                db.session.delete(acct)
                db.session.commit()
        except Exception:
            db.session.rollback()
        finally:
            with contextlib.suppress(Exception):
                pwctl.close_session(session_id)
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚­ãƒ¼æƒé™¤ï¼ˆcaptcha_status ã¯æ®‹ã™ï¼‰
            for k in list(session.keys()):
                if k.startswith("captcha_") and k != "captcha_status":
                    session.pop(k)
        return jsonify({
            "status": "recreate_required",
            "message": "CAPTCHAçªç ´ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚",
            "site_id": site_id,
        }), 200

    # --- ã“ã“ã‹ã‚‰ æ—¢å­˜ã®ã€Œãƒ¡ãƒ¼ãƒ«èªè¨¼â†’AtomPubã‚­ãƒ¼å›åã€ã‚’ç¶™ç¶š ---
    try:
        # ãƒ¡ãƒ¼ãƒ«ç¢ºèªãƒªãƒ³ã‚¯å–å¾—ï¼ˆæœ€å¤§ 5 å› / 30 ç§’ï¼‰
        # â˜… å¤‰æ•°åã®é£Ÿã„é•ã„ãƒã‚°ä¿®æ­£ï¼štoken ã‚’ä¸€å…ƒåŒ–ã—ã¦æ‰±ã†
        token = (
            request.form.get("token")
            or session.get("captcha_token")
            or (cred and cred.get("token"))
        )
        if not token:
            with contextlib.suppress(Exception):
                pwctl.close_session(session_id)
            return jsonify({
                "status": "recreate_required",
                "message": "ç¢ºèªãƒ¡ãƒ¼ãƒ«ã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³å¾©å…ƒã«å¤±æ•—ï¼‰",
                "site_id": site_id,
            }), 200
        activation_url = None  # â† ã“ã‚Œã‚’è¿½åŠ 
        for _ in range(5):
            with contextlib.suppress(Exception):
                activation_url = asyncio.run(poll_latest_link_gw(token))
            if activation_url:
                break
            time.sleep(6)

        if not activation_url:
            with contextlib.suppress(Exception):
                pwctl.close_session(session_id)
            return jsonify({
                "status": "recreate_required",
                "message": "ç¢ºèªãƒ¡ãƒ¼ãƒ«ãƒªãƒ³ã‚¯ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ",
                "site_id": site_id,
            }), 200

        # Playwright ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ãã®ã¾ã¾èªè¨¼URLã¸é·ç§»ã—ã¦ final å…¥åŠ›ã‚’æ‹¾ã†
        # ï¼ˆrecover_atompub_key ã¯ãƒšãƒ¼ã‚¸ã‚’å—ã‘å–ã£ã¦ blog_id / api_key ã‚’æŠ½å‡ºã™ã‚‹å®Ÿè£…ï¼‰
        # reviveã¯åŸºæœ¬ä¸è¦ã ãŒã€è½ã¡ã¦ã„ãŸã‚‰è‡ªå‹•å¾©å¸°
        page = pwctl.run(pwctl.get_page(session_id)) or pwctl.run(pwctl.revive(session_id))
        if not page:
            raise RuntimeError("Playwright ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒæ¶ˆå¤±ã—ã¾ã—ãŸ")

        # èªè¨¼URLã¸é·ç§»ï¼ˆã“ã‚Œã‚‚ pwctl ã®ãƒ«ãƒ¼ãƒ—ä¸Šã§ï¼‰
        pwctl.run(page.goto(activation_url, wait_until="load"))

        # â˜… ã“ã“ã‚’ asyncio.run(...) ã§ã¯ãªã pwctl.run(...) ã«ã™ã‚‹ã®ãŒãƒã‚¤ãƒ³ãƒˆ
        # â˜… ç½®æ›ï¼šrecover ã§ä½¿ã† livedoor ã® user_id ã¯ã€åŸºæœ¬ livedoor_id ã‚’ä½¿ã†
        user_id = (
            request.form.get("livedoor_id")
            or request.form.get("user_id")
            or request.form.get("userid")
            or request.form.get("username")
            or request.form.get("account_id")
            or livedoor_id
        )
        if not user_id:
            current_app.logger.error("[submit_captcha] livedoor user_id is missing (sid=%s)", session_id)
            return jsonify({"ok": False, "error": "missing_user_id"}), 400

        
        # --- ã“ã“ã§ãƒ•ã‚©ãƒ¼ãƒ å€¤ã‚’é›†ã‚ã‚‹ï¼ˆåç§°ã®æºã‚Œã‚’å¸åï¼‰ ---
        nickname = (
            request.form.get("nickname")
            or request.form.get("display_name")
            or request.form.get("name")
        )

        # ã“ã“ã‹ã‚‰ã¯ â€œæ—¢å­˜å€¤ã‚’å„ªå…ˆã—ã€æœªè¨­å®šã®ã¨ãã ã‘ãƒ•ã‚©ãƒ¼ãƒ ã‹ã‚‰è£œå®Œâ€
        email = (
            email
            or request.form.get("email")
            or request.form.get("livedoor_email")
            or request.form.get("mail")
        )

        password = (
            password
            or request.form.get("password")
            or request.form.get("livedoor_password")
            or request.form.get("pass")
        )

        # desired_blog_id ã¯é–¢æ•°å‰åŠã§ cred/ã‚»ãƒƒã‚·ãƒ§ãƒ³/ãƒ•ã‚©ãƒ¼ãƒ ã‹ã‚‰ä¸€åº¦ç¢ºå®šæ¸ˆã¿ã€‚
        # å¾Œæ®µã§å†è¨ˆç®—ãƒ»ä¸Šæ›¸ãã—ãªã„ï¼ˆãã®ã¾ã¾ desired_blog_id ã‚’ä½¿ã†ï¼‰ã€‚


        # æœ€ä½é™ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå¿…è¦ã«å¿œã˜ã¦ 400 ã‚’è¿”ã™ï¼‰
        if not email or not password:
            current_app.logger.error(
                "[submit_captcha] email/password missing (sid=%s, has_email=%s, has_pw=%s)",
                session_id, bool(email), bool(password)
            )
            return jsonify({"ok": False, "error": "missing_email_or_password"}), 400

        if not nickname:
            nickname = email.split("@")[0]  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

        # âœ… è‡ªå‹•ä½œæˆã¯ã‚„ã‚ã¦ **æ‰‹å‹•ãƒãƒ³ãƒ‰ã‚ªãƒ•** ã«åˆ‡æ›¿
        # åŒä¸€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®æ–°ã‚¿ãƒ–ã§ /member/blog/create ã‚’é–‹ãã ã‘ï¼ˆé€ä¿¡ã¯ã—ãªã„ï¼‰
        result = open_create_tab_for_handoff(
            session_id,
            site,
            prefill_title=True,   # ç”Ÿæˆæ¸ˆã¿ã‚¿ã‚¤ãƒˆãƒ«ã‚’å…¥åŠ›æ¬„ã«ãƒ—ãƒªãƒ•ã‚£ãƒ«
        )
        if not result or not result.get("ok"):
            with contextlib.suppress(Exception):
                pwctl.close_session(session_id)
            return jsonify({
                "status": "handoff_error",
                "message": result.get("error", "handoff_failed"),
                "site_id": site_id,
                "account_id": account_id
            }), 200

        # ãƒ•ãƒ­ãƒ³ãƒˆã¯ã“ã®URLã‚’æ–°è¦ã‚¿ãƒ–ã§é–‹ãï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€Œãƒ–ãƒ­ã‚°ã‚’ä½œæˆã™ã‚‹ã€ã‚’æ‰‹å‹•ã‚¯ãƒªãƒƒã‚¯ï¼‰
        handoff = {
            "url": result.get("url"),
            "prefilled_title": result.get("prefilled_title"),
            "has_blog_id_box": result.get("has_blog_id_box"),
            # â˜… è¿½åŠ ï¼šå¾Œç¶šã® /handoff_finalize ã§ç¢ºå®Ÿã«åŒä¸€PWã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’æ´ã‚ã‚‹ã‚ˆã†ã«ã™ã‚‹
            "session_id": session_id,
        }
        # ã“ã“ã‹ã‚‰ã¯äººæ‰‹ä½œæ¥­ã«ãƒãƒˆãƒ³ã‚’æ¸¡ã™ã®ã§ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯ç¶­æŒã™ã‚‹
        keep_pw_session = True
        current_app.logger.info(
            "[handoff] ready sid=%s url=%s has_id_box=%s title=%s",
            session_id,
            handoff.get("url"),
            handoff.get("has_blog_id_box"),
            handoff.get("prefilled_title"),
        )
        session["captcha_status"] = {
            "captcha_sent": True,
            "email_verified": True,
            "account_created": False,
            "api_key_received": False,
            "step": "handoff_ready",
            "site_id": site_id,
            "account_id": account_id,
            # â˜… è¿½åŠ ï¼šã‚»ãƒƒã‚·ãƒ§ãƒ³å´ã«ã‚‚ handoff.session_id ã‚’ä¿å­˜ï¼ˆä¿é™ºï¼‰
            "handoff": handoff,
        }
        return jsonify({
            "status": "handoff_ready",
            "site_id": site_id,
            "account_id": account_id,
            "handoff": handoff,
            "next_cta": "open_create_ui"
        }), 200
        

    finally:
        # ãƒãƒ³ãƒ‰ã‚ªãƒ•ä¸­ã¯ä½•ã‚‚ç‰‡ä»˜ã‘ãªã„ï¼ˆåŒä¸€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§äººæ‰‹æ“ä½œã‚’ç¶šè¡Œã™ã‚‹ãŸã‚ï¼‰
        if keep_pw_session:
            current_app.logger.info("[cleanup] handoff in progress -> keep session alive (sid=%s)", session_id)
        else:
            current_app.logger.info("[cleanup] closing pw session & clearing temp keys (sid=%s)", session_id)
            with contextlib.suppress(Exception):
                pwctl.close_session(session_id)
            with contextlib.suppress(Exception):
                pw_clear(session_id)
            # ãƒ¡ãƒ¼ãƒ«ãƒˆãƒ¼ã‚¯ãƒ³ã¯ãƒãƒ³ãƒ‰ã‚ªãƒ•ã§ãªã„é€šå¸¸çµŒè·¯ã®ã¿è§£æ”¾
            # ã‚»ãƒãƒ•ã‚©è§£æ”¾ã¯ /external-seo/end ã«å§”ã­ã‚‹ï¼ˆã“ã“ã§ã¯ãƒ¡ãƒ¼ãƒ«ãƒˆãƒ¼ã‚¯ãƒ³ã¯è§£æ”¾å¯¾è±¡ã§ã¯ãªã„ï¼‰
            # ã‚‚ã—ã“ã“ã§è§£æ”¾ã—ãŸã„å ´åˆã¯ extseo_token ã‚’å–ã‚Šå‡ºã—ã¦ release ã™ã‚‹
            # with contextlib.suppress(Exception):
            #     ext_tok = session.get("extseo_token")
            #     if ext_tok:
            #         release(ext_tok)
            # é€²æ—ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ(captcha_status)ã¯æ®‹ã—ã¤ã¤ã€ä¸€æ™‚ã‚­ãƒ¼(captcha_*)ã‚’æƒé™¤
            for key in list(session.keys()):
                if key.startswith("captcha_") and key != "captcha_status":
                    session.pop(key)

# ====== /handoff_finalize ======
@bp.route("/handoff_finalize", methods=["POST"])
@login_required
def handoff_finalize():
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒ /member/blog/create ã§æ‰‹å‹•ä½œæˆã‚’çµ‚ãˆãŸã‚ã¨ã«å‘¼ã¶ã€‚
    æ—¢å­˜ã® Playwright ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‹ã‚‰ blog_id / api_key ã‚’å›åã—ã¦ DB ã«ä¿å­˜ã™ã‚‹ã€‚
    """
    from flask import jsonify, session, request, current_app
    from app.models import Site, ExternalBlogAccount
    from app.enums import BlogType
    from app import db
    import contextlib
    # â˜… è¿½åŠ ï¼šã“ã“ã§ã®ã¿ä½¿ã†ãŸã‚ãƒ­ãƒ¼ã‚«ãƒ« importï¼ˆæ˜ç¤ºã—ã¦ãŠãï¼‰
    from app.services.blog_signup.livedoor_atompub_recover import recover_atompub_key

    site_id = request.form.get("site_id", type=int) or (session.get("captcha_status") or {}).get("site_id")
    account_id = request.form.get("account_id", type=int) or (session.get("captcha_status") or {}).get("account_id")
    session_id = session.get("captcha_session_id") or (session.get("captcha_status") or {}).get("handoff", {}).get("session_id")
    # handoff_ready ã®æ™‚ç‚¹ã§ã¯ session["captcha_session_id"] ã‚’ä¿æŒã—ã¦ã„ã‚‹å‰æ
    if not session_id:
        # å¿µã®ãŸã‚ DB å´ã‹ã‚‰æ‹¾ã†ï¼ˆã‚ã‚Œã°ï¼‰
        acct = ExternalBlogAccount.query.get(account_id) if account_id else None
        if acct and getattr(acct, "captcha_session_id", None):
            session_id = acct.captcha_session_id

    if not all([site_id, account_id, session_id]):
        return jsonify({"status": "error", "message": "handoff ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™"}), 400

    site = Site.query.get(site_id)
    acct = ExternalBlogAccount.query.get(account_id)
    if not site or not acct or acct.site_id != site_id:
        return jsonify({"status": "error", "message": "å¯¾è±¡ãŒä¸æ­£ã§ã™"}), 400
    if (not current_user.is_admin) and (site.user_id != current_user.id):
        return jsonify({"status": "error", "message": "æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“"}), 403

    # ã“ã“ã‹ã‚‰å›å
    cred = pw_get(session_id) or {}
    email = cred.get("email") or session.get("captcha_email")
    password = cred.get("password") or session.get("captcha_password")
    livedoor_id = cred.get("livedoor_id") or session.get("captcha_nickname")
    desired_blog_id = cred.get("desired_blog_id") or session.get("captcha_desired_blog_id") or livedoor_id
    email_token = cred.get("token") or session.get("captcha_token")

    if not (email and password and livedoor_id):
        return jsonify({"status": "error", "message": "è³‡æ ¼æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™"}), 400

    # æ—¢å­˜ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰ãƒšãƒ¼ã‚¸ã‚’å–å¾—ï¼ˆè½ã¡ã¦ãŸã‚‰ reviveï¼‰
    page = pwctl.run(pwctl.get_page(session_id)) or pwctl.run(pwctl.revive(session_id))
    if not page:
        return jsonify({"status": "error", "message": "Playwright ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}), 500

    # ã“ã“ã§ blog_id / api_key ã‚’å›å
    result = pwctl.run(recover_atompub_key(
        page,
        livedoor_id=livedoor_id,
        nickname=(email.split("@")[0] if email else livedoor_id),
        email=email,
        password=password,
        site=site,
        desired_blog_id=desired_blog_id,
    ))

    if not result or not result.get("success"):
        return jsonify({
            "status": "handoff_error",
            "message": result.get("error", "APIã‚­ãƒ¼ã®å›åã«å¤±æ•—ã—ã¾ã—ãŸ"),
            "site_id": site_id,
            "account_id": account_id,
        }), 200

    new_blog_id  = (result.get("blog_id") or "").strip() or None
    new_api_key  = (result.get("api_key") or "").strip() or None
    new_endpoint = (result.get("endpoint") or "").strip() or None

    # é‡è¤‡ blog_id ãŒã‚ã‚Œã°æ—¢å­˜ã‚’å„ªå…ˆ
    dup = None
    if new_blog_id:
        dup = (ExternalBlogAccount.query
               .filter(
                   ExternalBlogAccount.site_id == site_id,
                   ExternalBlogAccount.blog_type == (acct.blog_type or BlogType.LIVEDOOR),
                   ExternalBlogAccount.livedoor_blog_id == new_blog_id,
                   ExternalBlogAccount.id != account_id
               )
               .first())
    target = dup or acct

    if hasattr(target, "is_captcha_completed"):
        target.is_captcha_completed = True
    if new_blog_id and hasattr(target, "livedoor_blog_id"):
        target.livedoor_blog_id = new_blog_id
    if new_blog_id and hasattr(target, "username"):
        if not target.username or target.username.startswith("u-"):
            target.username = new_blog_id
    if new_endpoint and hasattr(target, "atompub_endpoint"):
        with contextlib.suppress(Exception):
            target.atompub_endpoint = new_endpoint
    if new_api_key and hasattr(target, "atompub_key_enc"):
        from app.services.blog_signup.crypto_utils import encrypt
        with contextlib.suppress(Exception):
            target.atompub_key_enc = encrypt(new_api_key)
        if hasattr(target, "api_post_enabled"):
            target.api_post_enabled = True

    db.session.commit()

    got_api = bool(new_api_key or getattr(target, "atompub_key_enc", None))
    resolved_account_id = target.id
    session["captcha_status"] = {
        "captcha_sent": True,
        "email_verified": True,
        "account_created": True,
        "api_key_received": got_api,
        "step": "APIå–å¾—å®Œäº†",
        "site_id": site_id,
        "account_id": resolved_account_id,
    }

    # handoff å®Œäº†ã—ãŸã®ã§å¾Œç‰‡ä»˜ã‘
    with contextlib.suppress(Exception):
        pwctl.close_session(session_id)
    with contextlib.suppress(Exception):
        pw_clear(session_id)
    # åŒä¸Šï¼šã‚»ãƒãƒ•ã‚©ã¯ /external-seo/end ã§è§£æ”¾ã€‚ã“ã“ã§ã¯ä½•ã‚‚ã—ãªã„
    # with contextlib.suppress(Exception):
    #     ext_tok = session.get("extseo_token")
    #     if ext_tok:
    #         release(ext_tok)
    for key in list(session.keys()):
        if key.startswith("captcha_") and key != "captcha_status":
            session.pop(key)

    return jsonify({
        "status": "captcha_success",
        "step": session["captcha_status"]["step"],
        "site_id": site_id,
        "account_id": resolved_account_id,
        "api_key_received": got_api,
        "next_cta": "ready_to_post" if got_api else "captcha_done"
    }), 200


@bp.route("/ld/open_create_ui", methods=["POST"])
@login_required
def open_create_ui():
    """ä»»æ„ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§â€œåˆ¥ã‚¿ãƒ–ã§ä½œæˆç”»é¢â€ã‚’é–‹ããŸã„å ´åˆã®è»½é‡APIï¼ˆUIãƒœã‚¿ãƒ³ç”¨ï¼‰"""
    from flask import request, jsonify, session as flask_session
    from app.models import Site
    session_id = request.form.get("session_id") or flask_session.get("captcha_session_id")
    site_id    = request.form.get("site_id")    or flask_session.get("captcha_site_id")
    if not session_id or not site_id:
        return jsonify({"ok": False, "error": "missing_params"}), 400
    site = Site.query.get(int(site_id))
    if not site:
        return jsonify({"ok": False, "error": "site_not_found"}), 404
    result = open_create_tab_for_handoff(session_id, site, prefill_title=True)
    if not result or not result.get("ok"):
        return jsonify({"ok": False, "error": result.get("error", "handoff_failed")}), 500
    return jsonify({"ok": True, **result}), 200

@bp.route("/captcha_status", methods=["GET"])
@login_required
def get_captcha_status():
    from flask import session, jsonify, request
    # DBãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨
    from app.models import ExternalBlogAccount

    status = session.get("captcha_status")

    # ä»»æ„ï¼š?account_id=... ãŒæ¥ãŸã‚‰æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
    q_acc = request.args.get("account_id", type=int)

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒã‚ã‚‹å ´åˆã®åŸºæœ¬å¿œç­”
    if status:
        if q_acc and status.get("account_id") and status["account_id"] != q_acc:
            # åˆ¥ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’è¦‹ã«æ¥ãŸå ´åˆã¯æœªé–‹å§‹æ‰±ã„
            return jsonify({"status": "not_started", "step": "æœªé–‹å§‹"}), 200
        return jsonify(status), 200

    # â˜… ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒåˆ‡ã‚Œã¦ã‚‚ã€DBãŒAPIå–å¾—æ¸ˆãªã‚‰ã€ŒAPIå–å¾—å®Œäº†ã€ã‚’è¿”ã™ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    if q_acc:
        acct = ExternalBlogAccount.query.get(q_acc)
        if acct and getattr(acct, "atompub_key_enc", None):
            return jsonify({
                "captcha_sent": True,
                "email_verified": True,          # ã“ã“ã¯æ¨å®šï¼ˆAPIå–å¾—æ¸ˆã¿å‰æï¼‰
                "account_created": True,         # åŒä¸Š
                "api_key_received": True,
                "step": "APIå–å¾—å®Œäº†",
                "site_id": getattr(acct, "site_id", None),
                "account_id": q_acc
            }), 200

    # ä½•ã‚‚æƒ…å ±ãŒãªã„
    return jsonify({"status": "not_started", "step": "æœªé–‹å§‹"}), 200

@bp.get("/generate")
@login_required
def external_seo_generate_get():
    from datetime import datetime, timezone
    from app import db
    from app.models import Site, ExternalBlogAccount, BlogType
    from app.tasks import enqueue_generate_and_schedule
    from sqlalchemy import and_

    site_id = request.args.get("site_id", type=int)
    account_id = request.args.get("account_id", type=int)
    blog_type_param = request.args.get("blog_type", default="livedoor").strip().lower() if request.args.get("blog_type") else "livedoor"

    if not site_id:
        flash("site_id ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚", "danger")
        return redirect(url_for("main.external_seo_sites"))

    site = Site.query.get_or_404(site_id)
    if (not current_user.is_admin) and (site.user_id != current_user.id):
        abort(403)

    try:
        target_blog_type = getattr(BlogType, blog_type_param.upper())
    except Exception:
        target_blog_type = BlogType.LIVEDOOR

    # å¯¾è±¡ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®é¸å®š
    if account_id:
        acct = ExternalBlogAccount.query.get_or_404(account_id)
        if acct.site_id != site_id:
            flash("ä¸æ­£ãªã‚¢ã‚¯ã‚»ã‚¹ã§ã™ï¼ˆã‚µã‚¤ãƒˆä¸ä¸€è‡´ï¼‰", "danger")
            return redirect(url_for("main.external_seo_sites"))
        if acct.blog_type != target_blog_type:
            flash("ä¸æ­£ãªã‚¢ã‚¯ã‚»ã‚¹ã§ã™ï¼ˆãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ä¸ä¸€è‡´ï¼‰", "danger")
            return redirect(url_for("main.external_seo_sites"))
        if not acct.atompub_key_enc:
            flash("ã“ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã¯APIã‚­ãƒ¼æœªå–å¾—ã®ãŸã‚è¨˜äº‹ç”Ÿæˆã§ãã¾ã›ã‚“ã€‚", "danger")
            return redirect(url_for("main.external_seo_sites"))
        accounts_to_run = [acct]
    else:
        # ã¾ã¨ã‚å®Ÿè¡Œï¼šæœªãƒ­ãƒƒã‚¯ & API å–å¾—æ¸ˆã¿ã®ã¿å€™è£œã«ã™ã‚‹
        accounts_to_run = (
            ExternalBlogAccount.query
            .filter(
                and_(
                    ExternalBlogAccount.site_id == site_id,
                    ExternalBlogAccount.blog_type == target_blog_type,
                    ExternalBlogAccount.atompub_key_enc.isnot(None),
                    ExternalBlogAccount.generation_locked.is_(False),
                )
            )
            .all()
        )
        if not accounts_to_run:
            flash("å®Ÿè¡Œå¯èƒ½ãªã‚¢ã‚«ã‚¦ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆAPIæœªå–å¾— ã¾ãŸã¯ æ—¢ã«ãƒ­ãƒƒã‚¯æ¸ˆã¿ï¼‰ã€‚", "warning")
            return redirect(url_for("main.external_seo_sites"))

    ok, ng, skipped_locked = 0, 0, 0
    failed = []

    for acct in accounts_to_run:
        try:
            # ---- ã“ã“ãŒæ’ä¹…ãƒ­ãƒƒã‚¯ã®è‚ ----
            # è¡Œãƒ­ãƒƒã‚¯ã‚’å–ã‚Šã€äºŒé‡å®Ÿè¡Œã‚’é˜²ã
            row = (
                ExternalBlogAccount.query
                .with_for_update()           # SELECT ... FOR UPDATE
                .filter_by(id=acct.id)
                .first()
            )
            if not row:
                skipped_locked += 1
                continue

            # æ—¢ã«ãƒ­ãƒƒã‚¯æ¸ˆã¿ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—
            if row.generation_locked:
                skipped_locked += 1
                continue

            # ã“ã“ã§æ’ä¹…ãƒ­ãƒƒã‚¯ã‚’ç«‹ã¦ã¦ç¢ºå®š
            row.generation_locked = True
            row.generation_locked_at = datetime.now(timezone.utc)
            db.session.add(row)
            db.session.commit()             # å…ˆã«ç¢ºå®š â†’ ä»¥å¾Œã¯äºŒé‡å®Ÿè¡Œä¸å¯

            # ãƒ­ãƒƒã‚¯ç¢ºå®šå¾Œã«ã‚­ãƒ¥ãƒ¼æŠ•å…¥
            enqueue_generate_and_schedule(
                user_id=current_user.id,
                site_id=site_id,
                blog_account_id=row.id,
                count=100,
                per_day=10,
                start_day_jst=None,   # ç¿Œæ—¥é–‹å§‹ï¼ˆé–¢æ•°å†…ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§å‡¦ç†ï¼‰
            )
            ok += 1

        except Exception as e:
            db.session.rollback()
            ng += 1
            failed.append((acct.id, str(e)))

    # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
    if ok and not ng:
        msg = f"{ok}ä»¶ã®ãƒ–ãƒ­ã‚°ã§è¨˜äº‹ç”Ÿæˆã‚’é–‹å§‹"
        if skipped_locked:
            msg += f" ï¼ ãƒ­ãƒƒã‚¯æ¸ˆã¿ã‚¹ã‚­ãƒƒãƒ— {skipped_locked}ä»¶"
        flash(msg, "success")
    elif ok and ng:
        flash(f"{ok}ä»¶é–‹å§‹ / {ng}ä»¶å¤±æ•—ï¼ˆãƒ­ãƒƒã‚¯æ¸ˆã¿ã‚¹ã‚­ãƒƒãƒ— {skipped_locked}ä»¶ï¼‰", "warning")
    else:
        # 1ä»¶ã‚‚é–‹å§‹ã§ããªã‹ã£ãŸ
        if skipped_locked:
            flash("ã™ã¹ã¦ã®å¯¾è±¡ãŒãƒ­ãƒƒã‚¯æ¸ˆã¿ã®ãŸã‚å®Ÿè¡Œã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚", "warning")
        else:
            flash("è¨˜äº‹ç”Ÿæˆã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚", "danger")

    if failed:
        for aid, msg in failed[:3]:
            flash(f"account_id={aid}: {msg}", "danger")
        if len(failed) > 3:
            flash(f"â€¦ä»– {len(failed)-3}ä»¶", "danger")

    return redirect(url_for("main.external_seo_sites"))


from flask import render_template, redirect, url_for, request, session, flash
from app.services.mail_utils.mail_tm import poll_latest_link_tm_async as poll_latest_link_gw
from app.services.blog_signup.livedoor_signup import extract_verification_url

@bp.route('/confirm_email_manual/<task_id>')
def confirm_email_manual(task_id):
    """
    CAPTCHAå¾Œã€èªè¨¼ãƒªãƒ³ã‚¯ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æ‰‹å‹•ã§è¡¨ç¤ºã™ã‚‹ç”»é¢ã€‚
    """
    # ãƒ¡ãƒ¼ãƒ«å—ä¿¡ï¼ˆæœ€å¤§30å›ãƒãƒ¼ãƒªãƒ³ã‚°ï¼‰ â† æ—¢å­˜é–¢æ•°ã‚’å†åˆ©ç”¨
    email_body = poll_latest_link_gw(task_id=task_id, max_attempts=30, interval=5)

    if email_body:
        # èªè¨¼URLã‚’æŠ½å‡º
        verification_url = extract_verification_url(email_body)
        if verification_url:
            return render_template("confirm_email.html", verification_url=verification_url)
        else:
            flash("èªè¨¼ãƒªãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ", "danger")
            return redirect(url_for('dashboard'))
    else:
        flash("èªè¨¼ãƒ¡ãƒ¼ãƒ«ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ", "danger")
        return redirect(url_for('dashboard'))

from flask import request, session, redirect, url_for, flash
from app.services.blog_signup.livedoor_signup import fetch_livedoor_credentials


@bp.route('/finish_signup/<task_id>', methods=['POST'])
def finish_signup(task_id):
    """
    ãƒ¡ãƒ¼ãƒ«èªè¨¼ãŒå®Œäº†ã—ãŸå¾Œã«å‘¼ã°ã‚Œã‚‹å‡¦ç†ã€‚
    AtomPub API Keyã‚’å–å¾—ã—ã€DBä¿å­˜ or è¡¨ç¤ºã«é€²ã‚€ã€‚
    """
    try:
        # ã™ã§ã«å­˜åœ¨ã™ã‚‹ task_id ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚„ä¿å­˜æƒ…å ±ã‹ã‚‰å†é–‹
        result = fetch_livedoor_credentials(task_id)

        if result and result.get("blog_id") and result.get("api_key"):
            # å¿…è¦ã«å¿œã˜ã¦DBä¿å­˜ or ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜ï¼ˆã“ã“ã§ã¯è¡¨ç¤ºç”¨ï¼‰
            flash("ğŸ‰ AtomPub APIæƒ…å ±ã‚’æ­£å¸¸ã«å–å¾—ã—ã¾ã—ãŸ", "success")
            flash(f"ãƒ–ãƒ­ã‚°ID: {result['blog_id']}", "info")
            flash(f"API Key: {result['api_key']}", "info")
            return redirect(url_for('dashboard'))  # ã¾ãŸã¯ account_details, etc.
        else:
            flash("APIæƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ", "danger")
            return redirect(url_for('dashboard'))

    except Exception as e:
        flash(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", "danger")
        return redirect(url_for('dashboard'))

from flask import render_template, abort
from app.services.blog_signup.livedoor_signup import fetch_livedoor_credentials

@bp.route("/external/livedoor/confirm/<task_id>")
def confirm_livedoor_email(task_id):
    creds = fetch_livedoor_credentials(task_id)
    if not creds:
        abort(404, description="èªè¨¼æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    return render_template("confirm_email.html", blog_id=creds["blog_id"], api_key=creds["api_key"])

# ===============================
# å¤–éƒ¨SEOè¨˜äº‹ç”Ÿæˆãƒ«ãƒ¼ãƒˆï¼ˆæ–°è¦è¿½åŠ ï¼‰
# ===============================

from flask import Blueprint, request, redirect, url_for, flash
from flask_login import login_required, current_user
from app.models import ExternalBlogAccount
#from app.tasks import _run_external_post_job

# æ—¢å­˜ã®
# @bp.route("/external-seo/generate/<int:site_id>/<int:blog_id>", methods=["POST"])
# def external_seo_generate(...):
# ã‚’ä¸¸ã”ã¨ç½®ãæ›ãˆ

@bp.route("/external-seo/generate/<int:site_id>/<int:blog_id>", methods=["POST"])
@login_required
def external_seo_generate(site_id, blog_id):
    """
    æ—¢å­˜ã® /external-seo/generate/<site_id>/<blog_id> ã‚’æ¸©å­˜ã—ãŸã¾ã¾ã€
    ç”Ÿæˆï¼†ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã®æ–°ãƒ­ã‚¸ãƒƒã‚¯ã«å·®ã—æ›¿ãˆã€‚
    - 100æœ¬ç”Ÿæˆ
    - 1æ—¥10æœ¬
    - ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«é–‹å§‹ã¯ã€Œç”Ÿæˆé–‹å§‹ã®ç¿Œæ—¥ã€
    """
    from flask import redirect, url_for, flash
    from app.models import ExternalBlogAccount, Site, BlogType
    from app.external_seo_generator import generate_and_schedule_external_articles

    # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå–å¾—
    acct = ExternalBlogAccount.query.get_or_404(blog_id)

    # site_idæ•´åˆæ€§
    if acct.site_id != site_id:
        flash("ä¸æ­£ãªã‚¢ã‚¯ã‚»ã‚¹ã§ã™ï¼ˆã‚µã‚¤ãƒˆä¸ä¸€è‡´ï¼‰ã€‚", "danger")
        return redirect(url_for("main.external_seo_sites"))

    # æ‰€æœ‰æ¨©ãƒã‚§ãƒƒã‚¯ï¼ˆç®¡ç†è€…ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
    site = Site.query.get_or_404(site_id)
    if (not current_user.is_admin) and (site.user_id != current_user.id):
        abort(403)

    # APIã‚­ãƒ¼å¿…é ˆ
    if not getattr(acct, "atompub_key_enc", None):
        flash("APIã‚­ãƒ¼ãŒæœªå–å¾—ã®ãŸã‚è¨˜äº‹ç”Ÿæˆã§ãã¾ã›ã‚“ã€‚", "danger")
        return redirect(url_for("main.external_seo_sites"))

    try:
        # â€» start_day_jst ã‚’çœç•¥ â†’ ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿å´ã§ã€Œç¿Œæ—¥é–‹å§‹ã€ã«è‡ªå‹•åŒ–
        created = generate_and_schedule_external_articles(
            user_id=current_user.id,
            site_id=site_id,
            blog_account_id=acct.id,
            count=100,
            per_day=10,
            start_day_jst=None,
        )
        flash(f"å¤–éƒ¨SEOè¨˜äº‹ã®ç”Ÿæˆã‚’é–‹å§‹ã—ã¾ã—ãŸï¼ˆ{created}ä»¶ã€1æ—¥10æœ¬ãƒ»ç¿Œæ—¥ã‹ã‚‰æŠ•ç¨¿ï¼‰ã€‚", "success")
    except Exception as e:
        current_app.logger.exception("[external-seo] generate (legacy route) failed")
        flash(f"è¨˜äº‹ç”Ÿæˆé–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}", "danger")

    return redirect(url_for("main.external_seo_sites"))


# ===============================
# å¤–éƒ¨SEO: 100æœ¬ç”Ÿæˆï¼‹1æ—¥10æœ¬ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ï¼ˆæ–°è¦ï¼‰
# ===============================
from flask import request, jsonify, current_app
from flask_login import login_required, current_user
from datetime import datetime, timedelta, timezone
from app.models import ExternalBlogAccount, BlogType, Article
from app.external_seo_generator import generate_and_schedule_external_articles
from sqlalchemy import or_


JST = timezone(timedelta(hours=9))

@bp.route("/external-seo/generate_and_schedule", methods=["POST"])
@login_required
def external_seo_generate_and_schedule():
    """
    å¤–éƒ¨SEOè¨˜äº‹ã‚’ã¾ã¨ã‚ã¦ç”Ÿæˆã—ã€1æ—¥10æœ¬ï¼ˆJST 10:00ã€œ21:59ã®â€œåˆ‡ã‚Šã®è‰¯ããªã„åˆ†â€ï¼‰ã§ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã€‚
    JSON/FORM:
      site_id: int (å¿…é ˆ)
      blog_account_id: int (ä»»æ„ã€‚æœªæŒ‡å®šãªã‚‰ site_id ã«ç´ã¥ãæœ€æ–° Livedoor ã‚’è‡ªå‹•é¸æŠ)
      count: ç”Ÿæˆæœ¬æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ100ï¼‰
      per_day: 1æ—¥ã‚ãŸã‚Šæœ¬æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ10ï¼‰
      start_date_jst: "YYYY-MM-DD"ï¼ˆJSTã®é–‹å§‹æ—¥ã€‚çœç•¥æ™‚ã¯å½“æ—¥ï¼‰
    """
    # å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    site_id = request.form.get("site_id", type=int) or (request.json or {}).get("site_id")
    count = request.form.get("count", type=int) or (request.json or {}).get("count", 100)
    per_day = request.form.get("per_day", type=int) or (request.json or {}).get("per_day", 10)
    start_date_s = request.form.get("start_date_jst") or (request.json or {}).get("start_date_jst")

    if not site_id:
        return jsonify({"ok": False, "error": "site_id is required"}), 400
    
    # â–¼ é€šå¸¸è¨˜äº‹ï¼ˆå¤–éƒ¨SEOä»¥å¤–ã§æŠ•ç¨¿æ¸ˆã¿ï¼‰ãŒ 50 æœ¬æœªæº€ãªã‚‰å®Ÿè¡Œã‚’ãƒ–ãƒ­ãƒƒã‚¯
    normal_count = (
        Article.query
        .filter(Article.site_id == site_id)
        .filter(or_(Article.source.is_(None), Article.source != "external"))
        .filter(Article.status.in_(["posted", "published"]))  # â† done ã‚’å«ã‚ãªã„
        .count()
    )
    if normal_count < 100:
        return jsonify({
            "ok": False,
            "error": "å¤–éƒ¨SEOé–‹å§‹ã®æ¡ä»¶ã‚’æº€ãŸã—ã¦ã¾ã›ã‚“",
            "count": normal_count
        }), 400

    if start_date_s:
        try:
            y, m, d = map(int, start_date_s.split("-"))
            start_day_jst = datetime(y, m, d, tzinfo=JST)
        except Exception:
            return jsonify({"ok": False, "error": "start_date_jst must be YYYY-MM-DD"}), 400
    else:
        start_day_jst = datetime.now(JST).replace(hour=0, minute=0, second=0, microsecond=0)

    # å¯¾è±¡ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ
    blog_account_id = request.form.get("blog_account_id") or (request.json or {}).get("blog_account_id")
    if blog_account_id:
        acct = ExternalBlogAccount.query.get(int(blog_account_id))
    else:
        acct = (ExternalBlogAccount.query
                .filter_by(site_id=site_id, blog_type=BlogType.LIVEDOOR)
                .order_by(ExternalBlogAccount.id.desc())
                .first())
    if not acct:
        return jsonify({"ok": False, "error": "Livedoorã‚¢ã‚«ã‚¦ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}), 400

    # æ‰€æœ‰æ¨©ãƒã‚§ãƒƒã‚¯ï¼ˆç®¡ç†è€…ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
    if (not current_user.is_admin) and (acct.site.user_id != current_user.id):
        return jsonify({"ok": False, "error": "æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“"}), 403

    # å®Ÿè¡Œ
    try:
        created = generate_and_schedule_external_articles(
            user_id=current_user.id,
            site_id=site_id,
            blog_account_id=acct.id,
            count=int(count),
            per_day=int(per_day),
            start_day_jst=start_day_jst,
        )
        return jsonify({"ok": True, "created": created})
    except Exception as e:
        current_app.logger.exception("[external-seo] generate_and_schedule failed")
        return jsonify({"ok": False, "error": str(e)}), 500

from sqlalchemy.exc import IntegrityError
import secrets, time  # â˜… è¿½åŠ 
import re as _re
from urllib.parse import urlparse
try:
    from unidecode import unidecode  # ã‚ã‚Œã°æ—¥æœ¬èªâ†’ãƒ­ãƒ¼ãƒå­—åŒ–
except Exception:
    def unidecode(x): return x


@bp.route("/external-seo/new-account", methods=["POST"])
@bp.route("/external-seo/new-account/", methods=["POST"])
@login_required
def external_seo_new_account():
    """
    Livedoorã®ä»®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’1ä»¶ä½œæˆï¼ˆå¿…é ˆã‚«ãƒ©ãƒ ã¯å­˜åœ¨ç¢ºèªã—ã¦ã‹ã‚‰ã‚»ãƒƒãƒˆï¼‰ã€‚
    ä¾‹å¤–æ™‚ã‚‚å¿…ãšJSONã§è¿”ã™ã€‚
    """
    from flask import request, jsonify
    from app.models import Site, ExternalBlogAccount, BlogType, Article
    from app import db
    from sqlalchemy import or_
    import logging
    from datetime import datetime

    logger = logging.getLogger(__name__)

    # ---- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ -------------------------------------------------
    def _stub_email(site_id: int) -> str:
        """email UNIQUEå¯¾ç­–ï¼šè¡çªã—ãªã„ãƒ€ãƒŸãƒ¼ã‚’æ¯å›ç”Ÿæˆ"""
        # ä¾‹: pending-12-1723358300123-a3f1@stub.local
        return f"pending-{site_id}-{int(time.time()*1000)}-{secrets.token_hex(2)}@stub.local"

    def _stub_name(prefix: str, site_id: int) -> str:
        """username ç”¨ã®ãƒ€ãƒŸãƒ¼ï¼ˆå®‰å…¨ã«ãƒ¦ãƒ‹ãƒ¼ã‚¯å¯„ã‚Šã«ï¼‰"""
        # ä¾‹: u-12-1723358300123-a
        return f"{prefix}-{site_id}-{int(time.time()*1000)}-{secrets.token_hex(1)}"

    def _slugify_from_site(site: "Site") -> str:
        """
        ã‚µã‚¤ãƒˆå/URLã‹ã‚‰ display ç”¨ã®çŸ­ã„ã‚¹ãƒ©ãƒƒã‚°ã‚’ç”Ÿæˆï¼ˆa-z0-9-ã€å…ˆé ­ã¯è‹±å­—ã€æœ€å¤§20æ–‡å­—ï¼‰
        å¤–éƒ¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ã‚«ãƒ¼ãƒ‰è¡¨ç¤ºã«ä½¿ã†ã€‚DBã®ä¸€æ„åˆ¶ç´„ã«ã¯é–¢ä¸ã—ãªã„ã€‚
        """
        base = (site.name or "")[:60]
        if not base and getattr(site, "url", None):
            try:
                host = urlparse(site.url).hostname or ""
                base = host.split(".")[0] if host else ""
            except Exception:
                base = ""

        if not base:
            base = f"site-{site.id}"

        s = unidecode(str(base)).lower()
        s = s.replace("&", " and ")
        s = _re.sub(r"[^a-z0-9]+", "-", s)
        s = _re.sub(r"-{2,}", "-", s).strip("-")
        if not s:
            s = f"site-{site.id}"
        if s[0].isdigit():
            s = "blog-" + s
        s = s[:20]
        if len(s) < 3:
            s = (s + "-blog")[:20]
        return s
    # --------------------------------------------------------------------

    try:
        site_id = request.form.get("site_id", type=int)
        if not site_id:
            return jsonify({"ok": False, "error": "site_id ãŒã‚ã‚Šã¾ã›ã‚“"}), 200

        site = Site.query.get(site_id)
        if not site:
            return jsonify({"ok": False, "error": "Site ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}), 200
        if (not current_user.is_admin) and (site.user_id != current_user.id):
            return jsonify({"ok": False, "error": "æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“"}), 200
        
        # â–¼ é€šå¸¸è¨˜äº‹ï¼ˆå¤–éƒ¨SEOä»¥å¤–ã§ WPã«æŠ•ç¨¿æ¸ˆã¿ï¼‰ãŒ 100 æœ¬æœªæº€ãªã‚‰ãƒ–ãƒ­ãƒƒã‚¯
        normal_count = (
            Article.query
            .filter(Article.site_id == site_id)
            .filter(or_(Article.source.is_(None), Article.source != "external"))
            .filter(Article.status.in_(["posted", "published"]))  # â† done ã‚’å«ã‚ãªã„
            .count()
        )
        if normal_count < 100:
            return jsonify({
                "ok": False,
                "error": "å¤–éƒ¨SEOé–‹å§‹ã®æ¡ä»¶ã‚’æº€ãŸã—ã¦ã¾ã›ã‚“",
                "count": normal_count
            }), 400

        # è¡¨ç¤ºç”¨ã‚¹ãƒ©ãƒƒã‚°ï¼ˆã‚«ãƒ¼ãƒ‰ã®ã‚¿ã‚¤ãƒˆãƒ«ã«ä½¿ã†ï¼‰
        display_slug = _slugify_from_site(site)

        # UNIQUEè¡çªã«å‚™ãˆã¦æ•°å›ã ã‘ãƒªãƒˆãƒ©ã‚¤
        attempts = 0
        while True:
            try:
                # ã¾ãšæœ€å°é™ã®å¿…é ˆã ã‘ã§ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ï¼ˆå­˜åœ¨ã—ãªã„åˆ—ã¯è§¦ã‚‰ãªã„ï¼‰
                acc = ExternalBlogAccount(
                    site_id=site.id,
                    blog_type=BlogType.LIVEDOOR,
                )

                # --- ã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿å®‰å…¨ã«ã‚»ãƒƒãƒˆ ---
                # UNIQUE ã®å¯èƒ½æ€§ãŒã‚ã‚‹ email ã¯å¿…ãšãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒ€ãƒŸãƒ¼ã«ã™ã‚‹
                if hasattr(acc, "email"):
                    acc.email = _stub_email(site.id)

                # username ã¯ãƒ€ãƒŸãƒ¼ã€nickname ã¯è¡¨ç¤ºã«è¿‘ã„å€¤ï¼ˆã‚µã‚¤ãƒˆç”±æ¥ã‚¹ãƒ©ãƒƒã‚°ï¼‰ã‚’å…¥ã‚Œã¦ãŠã
                if hasattr(acc, "username"):
                    acc.username = _stub_name("u", site.id)
                if hasattr(acc, "password"):
                    acc.password = ""  # ä»®
                if hasattr(acc, "nickname"):
                    acc.nickname = display_slug  # â† ã“ã“ã‚’ã‚µã‚¤ãƒˆç”±æ¥ã«

                # çŠ¶æ…‹ç³»ï¼ˆå­˜åœ¨ã™ã‚Œã°ï¼‰
                if hasattr(acc, "status"):                acc.status = "active"
                if hasattr(acc, "message"):               acc.message = None
                if hasattr(acc, "cookie_path"):           acc.cookie_path = None
                if hasattr(acc, "livedoor_blog_id"):      acc.livedoor_blog_id = None
                if hasattr(acc, "atompub_key_enc"):       acc.atompub_key_enc = None
                if hasattr(acc, "api_post_enabled"):      acc.api_post_enabled = False
                if hasattr(acc, "is_captcha_completed"):  acc.is_captcha_completed = False
                # is_email_verified ã¯å­˜åœ¨ã—ãªã„ç’°å¢ƒãŒã‚ã‚‹ãŸã‚è§¦ã‚‰ãªã„
                if hasattr(acc, "posted_cnt"):            acc.posted_cnt = 0
                if hasattr(acc, "next_batch_started"):    acc.next_batch_started = None
                if hasattr(acc, "created_at"):            acc.created_at = datetime.utcnow()

                db.session.add(acc)
                db.session.commit()
                break  # â† æˆåŠŸ

            except IntegrityError:
                # emailï¼ˆã‚„ä»–ã®ä¸€æ„åˆ¶ç´„ï¼‰è¡çªæ™‚ã¯å†æ¡ç•ªã—ã¦ãƒªãƒˆãƒ©ã‚¤
                db.session.rollback()
                attempts += 1
                if attempts >= 5:
                    logger.exception("[external_seo_new_account] integrity error (retries exceeded)")
                    return jsonify({"ok": False, "error": "DBã®ä¸€æ„åˆ¶ç´„ã§ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ™‚é–“ã‚’ãŠã„ã¦å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚"}), 200
                # ãƒ«ãƒ¼ãƒ—å…ˆé ­ã§æ–°ã—ã„ãƒ€ãƒŸãƒ¼ã‚’æ¡ç•ªã—ã¦å†ä½œæˆ

        account_payload = {
            "id": acc.id,
            # è¡¨ç¤ºåã¯ã‚µã‚¤ãƒˆåãƒ™ãƒ¼ã‚¹ã®ã‚¹ãƒ©ãƒƒã‚°ã‚’ä½¿ç”¨ï¼ˆã‚«ãƒ¼ãƒ‰ã®ã‚¿ã‚¤ãƒˆãƒ«ãŒäººé–“ã«ã‚ã‹ã‚Šã‚„ã™ããªã‚‹ï¼‰
            "blog_title": display_slug,
            "public_url": None,
            "api_key": None,
            "stat_total": 0,
            "stat_posted": 0,
        }
        return jsonify({"ok": True, "site_id": site.id, "account": account_payload}), 200

    except Exception as e:
        db.session.rollback()
        logger.exception("[external_seo_new_account] error")
        return jsonify({"ok": False, "error": f"ã‚µãƒ¼ãƒã‚¨ãƒ©ãƒ¼: {str(e)}"}), 200
    

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å¤–éƒ¨SEOã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹APIï¼ˆçµ±åˆç‰ˆï¼šã“ã‚Œ1æœ¬ã ã‘æ®‹ã™ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from app.utils.semaphore import current_active, try_acquire, release, LIMIT

@bp.get("/external-seo/status")
@login_required
def external_seo_status():
    """
    ãƒ•ãƒ­ãƒ³ãƒˆã®ãƒãƒ¼ãƒªãƒ³ã‚°ç”¨APIã‚’ä¸€æœ¬åŒ–ï¼š
      - ä¸¦åˆ—å®Ÿè¡Œã®ä½¿ç”¨çŠ¶æ³ï¼ˆactive/limit/availableï¼‰
      - extseo_token ã«ç´ã¥ãé€²æ—ãƒ»captcha_url ç­‰ã®çŠ¶æ…‹
    ã‚’åŒæ™‚ã«è¿”ã™ã€‚ãƒ•ãƒ­ãƒ³ãƒˆã¯å¿…è¦ãªã‚­ãƒ¼ã ã‘è¦‹ã‚Œã°OKï¼ˆä¸‹ä½äº’æ›ï¼‰ã€‚
    """
    from flask import jsonify, session

    # 1) ä¸¦åˆ—å®Ÿè¡Œã®å®¹é‡æƒ…å ±
    active = current_active()
    cap = {
        "active": active,
        "limit": LIMIT,
        "available": max(LIMIT - active, 0),
    }

    # 2) ãƒˆãƒ¼ã‚¯ãƒ³ã«ç´ã¥ãé€²æ—ï¼ˆã‚ã‚Œã°è¿”ã™ï¼‰
    tok = session.get("extseo_token")
    st = {}
    # EXTSEO_STATUS ã¯ãƒ•ã‚¡ã‚¤ãƒ«å…ˆé ­ãªã©ã§ dict åˆæœŸåŒ–æ¸ˆã¿æƒ³å®š
    try:
        st = EXTSEO_STATUS.get(tok) or {}
    except Exception:
        st = {}

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ã ã‘ç©ã‚“ã§ã„ã‚‹UIç”¨ã®è»½ã„é€²æ—ãŒã‚ã‚Œã°ãƒãƒ¼ã‚¸ï¼ˆä»»æ„ï¼‰
    try:
        sess_st = session.get("captcha_status") or {}
        if sess_st:
            st = {**st, **sess_st}
    except Exception:
        pass

    # ã¾ã¨ã‚ã¦è¿”ã™ï¼ˆä¸‹ä½äº’æ›ï¼šå¾“æ¥ã®ã‚­ãƒ¼ã‚‚ãã®ã¾ã¾ st ã«å«ã‚ã‚‹ï¼‰
    resp = {"ok": True, **cap, **st}
    if not tok:
        resp["token_missing"] = True
    return jsonify(resp)



@bp.route("/external-seo/start", methods=["POST"])
@login_required
def external_seo_start():
    token = try_acquire()
    if not token:
        flash("å¤–éƒ¨SEOã®åŒæ™‚å®Ÿè¡Œã¯æœ€å¤§3ä»¶ã¾ã§ã§ã™ã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚", "error")
        return jsonify({
            "ok": False,
            "reason": "busy",
            "message": "å¤–éƒ¨SEOå®Ÿè¡ŒãŒæ··é›‘ä¸­ã§ã™"
        }), 429

    # â˜… ã‚»ãƒãƒ•ã‚©ç”¨ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜ï¼ˆcaptcha_tokenã¨ã¯åˆ†é›¢ï¼‰
    session["extseo_token"] = token
    return jsonify({"ok": True, "token": token})

# ==== è¿½åŠ : å¤–éƒ¨SEO ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—ï¼ˆã‚µãƒ¼ãƒãŒå¾“æ¥è¦å‰‡ã§å€¤ã‚’ç”Ÿæˆã—ã€ãƒ˜ãƒ«ãƒ‘ãƒ¼ã«æ¸¡ã™ï¼‰====
@bp.post("/external-seo/bootstrap")
@login_required
def external_seo_bootstrap():
    from flask import request, jsonify, session
    from flask_login import current_user
    from app import db
    from app.models import Site
    from app.services.mail_utils.mail_gw import create_inbox
    # ç”Ÿæˆè¦å‰‡ã¯å¾“æ¥ã®ã¾ã¾æµç”¨
    from app.services.blog_signup.livedoor_signup import (
        generate_safe_id, generate_safe_password, suggest_livedoor_blog_id,
        _craft_blog_title as ld_craft_blog_title  # ç§æœ‰é–¢æ•°ã ãŒ import å¯ã€‚è¦å‰‡å®Œå…¨ä¸€è‡´ã®ãŸã‚ä½¿ç”¨
    )

    # /external-seo/start ã§é…ã‚‰ã‚ŒãŸ extseo_token ã‚’å¿…é ˆã¨ã™ã‚‹
    tok = session.get("extseo_token")
    if not tok:
        return jsonify({"ok": False, "error": "missing extseo_token; call /external-seo/start first"}), 400

    # å…¥åŠ›ï¼ˆJSON or form ä¸¡å¯¾å¿œï¼‰
    if request.is_json:
        site_id = request.json.get("site_id")
        account_id = request.json.get("account_id")
    else:
        site_id = request.form.get("site_id")
        account_id = request.form.get("account_id")

    try:
        site_id = int(site_id) if site_id is not None else None
    except Exception:
        site_id = None
    try:
        account_id = int(account_id) if account_id is not None else None
    except Exception:
        account_id = None

    if not site_id:
        return jsonify({"ok": False, "error": "missing site_id"}), 400

    site = Site.query.get(site_id)
    if not site or (not current_user.is_admin and site.user_id != current_user.id):
        return jsonify({"ok": False, "error": "permission denied"}), 403

    # â–¼ å¾“æ¥ã¨åŒã˜è¦å‰‡ã§ç”Ÿæˆï¼ˆï¼VPSæ™‚ä»£ã¨å®Œå…¨ä¸€è‡´ï¼‰
    email, inbox_token = create_inbox()                 # æ—¢å­˜GWã®ã¾ã¾
    # è‹±å­—é–‹å§‹ãƒ»3â€“20ãƒ»è‹±æ•°ï¼‹_ æº–æ‹ ã®å€™è£œãƒ­ã‚¸ãƒƒã‚¯ã‚’æ¡ç”¨
    livedoor_id = generate_livedoor_id_candidates(site)[0]
    password    = generate_safe_password()
    try:
        blog_title = ld_craft_blog_title(site)          # ã‚¿ã‚¤ãƒˆãƒ«è¦å‰‡ã‚’å®Œå…¨è¸è¥²
    except Exception:
        blog_title = "ãƒ–ãƒ­ã‚°"
    try:
        desired_blog_id = suggest_livedoor_blog_id(site.name or site.url or "", db.session)
    except Exception:
        desired_blog_id = None

    # UI ãƒãƒ¼ãƒªãƒ³ã‚°ç”¨ã®è»½ã„åˆæœŸçŠ¶æ…‹
    st = dict(session.get("captcha_status") or {})
    st.update({
        "step": "bootstrap_ok",
        "progress": max(5, int(st.get("progress") or 0)),
        "site_id": site_id,
        "account_id": account_id,
    })
    session["captcha_status"] = st

    # çµ¶å¯¾URLï¼ˆBlueprint åã«ä¾å­˜ã›ãšã€ç¢ºå®Ÿã«è§£æ±ºï¼‰
    root = request.url_root.rstrip("/")
    callback_url = f"{root}/external-seo/callback"
    upload_url   = f"{root}/external-seo/prepare_captcha"
    # STEP 3 ã§å®Ÿè£…äºˆå®šã€‚å…ˆã« URL ã‚’è¿”ã—ã¦ãŠãã€ãƒ˜ãƒ«ãƒ‘ãƒ¼ã¯å­˜åœ¨ã™ã‚Œã°ä½¿ã†
    verify_poll_url = f"{root}/external-seo/fetch_verify_url?token={inbox_token}"

    return jsonify({
        "ok": True,
        "token": tok,
        "site_id": site_id,
        "account_id": account_id,
        # å¾“æ¥è¦å‰‡ã§ç”Ÿæˆã—ãŸå€¤ï¼ˆï¼ãƒ˜ãƒ«ãƒ‘ãƒ¼ã¯â€œå—ã‘å–ã£ãŸã¾ã¾â€ä½¿ã†ï¼‰
        "email": email,
        "inbox_token": inbox_token,
        "livedoor_id": livedoor_id,
        "password": password,
        "blog_title": blog_title,
        "desired_blog_id": desired_blog_id,
        # ãƒ˜ãƒ«ãƒ‘ãƒ¼ãŒå©ãã‚µãƒ¼ãƒå´ã®å…¥å£
        "callback_url": callback_url,
        "upload_url": upload_url,
        # ãƒ¡ãƒ¼ãƒ«èªè¨¼URLã®å–å¾—ï¼ˆSTEP 3ã§ã‚µãƒ¼ãƒå®Ÿè£…ã€‚ç„¡ã‘ã‚Œã°ãƒ˜ãƒ«ãƒ‘ãƒ¼ã¯è‡ªå‰fallbackï¼‰
        "verify_poll_url": verify_poll_url,
    })

# ==== è¿½åŠ : å¤–éƒ¨SEO ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒãƒ¼ãƒªãƒ³ã‚° ====
@bp.get("/external-seo/captcha_status")
@login_required
def external_seo_captcha_status():
    """
    UIãŒå®šæœŸãƒãƒ¼ãƒªãƒ³ã‚°ã—ã¦é€²æ—ã‚„CAPTCHAç”»åƒURLã€å®Œäº†ãƒ•ãƒ©ã‚°ã‚’å–å¾—ã™ã‚‹ã€‚
    ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒè¦‹ãˆãªã„ç’°å¢ƒã§ã¯ç©ºã«è¿‘ã„ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«ãªã‚‹ãŒã€ãã‚Œã§OKã€‚
    """
    from flask import session, jsonify

    st = dict(session.get("captcha_status") or {})

    # æ—¢å®šå€¤ï¼ˆUIå´ã§ã®æ‰±ã„ã‚’å®‰å®šã•ã›ã‚‹ï¼‰
    st.setdefault("step", "idle")
    try:
        st["progress"] = max(0, min(100, int(st.get("progress") or 0)))
    except Exception:
        st["progress"] = 0

    # ã‚ˆãä½¿ã†ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯å¿…ãšéµã‚’ç”¨æ„ã—ã¦ãŠãï¼ˆundefinedå›é¿ï¼‰
    st.setdefault("captcha_url", None)
    st.setdefault("captcha_sent", False)
    st.setdefault("email_verified", False)
    st.setdefault("account_created", False)
    st.setdefault("api_key_received", False)
    st.setdefault("site_id", None)
    st.setdefault("account_id", None)

    # extseo_token ãŒç”Ÿãã¦ã„ã‚‹ã‹ï¼ˆä¸¦åˆ—ã‚¬ãƒ¼ãƒ‰ã®å¯è¦–åŒ–ï¼‰
    st["extseo_active"] = bool(session.get("extseo_token"))

    return jsonify({"ok": True, **st})


# ==== è¿½åŠ : å¤–éƒ¨SEO ãƒ¡ãƒ¼ãƒ«èªè¨¼URLã®ãƒãƒ¼ãƒªãƒ³ã‚° ====
@bp.get("/external-seo/fetch_verify_url")
def external_seo_fetch_verify_url():
    """
    ãƒ˜ãƒ«ãƒ‘ãƒ¼ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼PCï¼‰ã‹ã‚‰ãƒãƒ¼ãƒªãƒ³ã‚°ã•ã‚Œã‚‹ã€‚
    ã‚µãƒ¼ãƒå´ï¼ˆVPSæ™‚ä»£ã¨åŒã˜ãƒ¡ãƒ¼ãƒ«å—ä¿¡ãƒ­ã‚¸ãƒƒã‚¯ï¼‰ã§æœ€æ–°ã®èªè¨¼ãƒ¡ãƒ¼ãƒ«æœ¬æ–‡ã‚’å–å¾—ã—ã€
    Livedoorã® verify ãƒªãƒ³ã‚¯ã‚’æŠ½å‡ºã—ã¦è¿”ã™ã€‚è¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã° ok:falseã€‚
    ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯ä¸€å®šé–“éš”ã§å†ãƒãƒ¼ãƒªãƒ³ã‚°ã™ã‚‹æƒ³å®šã€‚
    ä¾‹: GET /external-seo/fetch_verify_url?token=<inbox_token>&timeout=120&interval=5
    """
    from flask import request, jsonify, current_app
    # æ—¢å­˜ï¼šlivedoor_signup ã‹ã‚‰å¾“æ¥ã®æŠ½å‡ºãƒ­ã‚¸ãƒƒã‚¯ã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼ˆå®Œå…¨è¸è¥²ï¼‰
    from app.services.blog_signup.livedoor_signup import (
        extract_verification_url,          # æœ¬æ–‡ã‹ã‚‰ verify URL æŠœãå‡ºã—
        poll_latest_link_gw,               # = mail_tm ã® poll ã‚’å†è¼¸å‡ºï¼ˆVPSæ™‚ä»£ã®å®Ÿè£…ï¼‰
    )

    token = (request.args.get("token") or "").strip()
    if not token:
        return jsonify({"ok": False, "error": "missing token"}), 400

    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ 120ç§’/5ç§’é–“éš”ï¼ˆVPSæ™‚ä»£ã®ä½“æ„Ÿã«åˆã‚ã›ã‚‹ï¼‰
    try:
        timeout_sec = int(request.args.get("timeout", 120))
    except Exception:
        timeout_sec = 120
    try:
        interval_sec = int(request.args.get("interval", 5))
    except Exception:
        interval_sec = 5

    # poll_latest_link_gw ã¯ â€œãƒ¡ãƒ¼ãƒ«æœ¬æ–‡ãƒ†ã‚­ã‚¹ãƒˆâ€ ã‚’è¿”ã™æƒ³å®šï¼ˆå¾“æ¥äº’æ›ï¼‰
    # task_id=token ã‚’ã‚­ãƒ¼ã«ã€timeout/interval ã«å¿œã˜ã¦ãƒªãƒˆãƒ©ã‚¤
    try:
        email_body = poll_latest_link_gw(
            task_id=token,
            max_attempts=max(1, int(timeout_sec // max(1, interval_sec))),
            interval=max(1, interval_sec),
        )
    except Exception as e:
        current_app.logger.exception("[EXTSEO-VERIFY] poll error: %s", e)
        return jsonify({"ok": False, "error": "poll_error"}), 500

    if not email_body:
        # ã¾ã å±Šã‹ãªã„ã ã‘ã€‚ãƒãƒ¼ãƒªãƒ³ã‚°ç¶™ç¶šã•ã›ã‚‹
        return jsonify({"ok": False, "reason": "no_mail"})

    # æœ¬æ–‡ã‹ã‚‰ Livedoor ã® verify URL ã‚’æŠ½å‡ºï¼ˆè¦å‰‡ã¯ livedoor_signup.extract_verification_url ã«å®Œå…¨æº–æ‹ ï¼‰
    url = extract_verification_url(email_body)
    if not url:
        return jsonify({"ok": False, "reason": "no_link"})

    # è¦‹ã¤ã‹ã£ãŸ â†’ è¿”ã™ï¼ˆãƒ˜ãƒ«ãƒ‘ãƒ¼ãŒâ€œãƒ¦ãƒ¼ã‚¶ãƒ¼IPã§â€ã“ã®URLã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦èªè¨¼ã‚’å®Œäº†ã•ã›ã‚‹ï¼‰
    return jsonify({"ok": True, "verification_url": url})


@bp.route("/external-seo/end", methods=["POST"])
@login_required
def external_seo_end():
    # â˜… JSON bodyã‹ã‚‰ã§ã¯ãªãã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜ã—ãŸextseo_tokenã‚’è§£æ”¾ã™ã‚‹
    token = session.pop("extseo_token", None)
    if not token:
        return jsonify({"ok": False, "error": "no active external-seo token"}), 400
    release(token)
    return jsonify({"ok": True})

# -----------------------------------------------------------------
# å¤–éƒ¨SEO: ãƒ­ãƒ¼ã‚«ãƒ«ãƒ˜ãƒ«ãƒ‘ãƒ¼ â†’ ã‚µãƒ¼ãƒãƒ¼ é€²æ—/å®Œäº†ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
# -----------------------------------------------------------------
@bp.post("/external-seo/callback")
def external_seo_callback():
    """
    ãƒ­ãƒ¼ã‚«ãƒ«ãƒ˜ãƒ«ãƒ‘ãƒ¼ã‹ã‚‰ã®é€²æ—/å®Œäº†é€šçŸ¥ã€‚
    """
    from flask import request, jsonify, session, current_app
    from app import db
    from app.models import ExternalBlogAccount
    from app.services.blog_signup.crypto_utils import encrypt

    data = request.get_json(silent=True) or {}
    tok  = (data.get("token") or "").strip()
    if not tok:
        return jsonify({"ok": False, "error": "missing token"}), 400

    # å¯èƒ½ãªã‚‰ãƒ–ãƒ©ã‚¦ã‚¶ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ãƒˆãƒ¼ã‚¯ãƒ³ã¨çªãåˆã‚ã›ï¼ˆã‚ºãƒ¬ã¦ã‚‚è‡´å‘½ã§ã¯ãªã„ï¼‰
    try:
        if session.get("extseo_token") and session["extseo_token"] != tok:
            current_app.logger.warning("[EXTSEO-CB] token mismatch (session present but different)")
    except Exception:
        pass

    # å‹ã‚’æ•´ãˆã‚‹ï¼ˆstr "46" ã¨ int 46 ã®ä¸ä¸€è‡´ã§èª¤è­¦å‘ŠãŒå‡ºãªã„ã‚ˆã†ã«ï¼‰
    def _to_int(v):
        try:
            return int(v)
        except Exception:
            return v

    site_id    = _to_int(data.get("site_id"))
    account_id = _to_int(data.get("account_id"))

    step      = (data.get("step") or data.get("status") or "").strip()
    progress  = data.get("progress")
    helper_host = data.get("helper_host")
    helper_ip_public = data.get("helper_ip_public")
    blog_id   = (data.get("blog_id") or "").strip() or None
    endpoint  = (data.get("endpoint") or "").strip() or None
    api_key   = (data.get("api_key") or "").strip() or None

    # é€²æ—ãƒ­ã‚°
    try:
        current_app.logger.info(
            "[EXTSEO-CB] tok ok, site=%s acc=%s step=%s prog=%s helper_host=%s helper_ip=%s",
            site_id, account_id, step, progress, helper_host, helper_ip_public
        )
    except Exception:
        pass

    # âœ… ã¾ãšãƒˆãƒ¼ã‚¯ãƒ³ã‚¹ãƒˆã‚¢ã‚’æ›´æ–°ï¼ˆUIã¯ /external-seo/status ã§èª­ã‚€ï¼‰
    _extseo_update(tok,
                   step=step or None,
                   progress=progress if isinstance(progress, (int, float)) else None,
                   site_id=site_id,
                   account_id=account_id,
                   blog_id=blog_id,
                   endpoint=endpoint,
                   api_key_received=True if api_key else None)

    # account_id ãŒç„¡ã‘ã‚Œã°é€²æ—ã ã‘å—ã‘ä»˜ã‘ã¦çµ‚äº†
    if not account_id:
        return jsonify({"ok": True, "noted": True})

    # --- DB åæ˜ ï¼ˆAPIã‚­ãƒ¼ãƒ»blog_idãªã©ãŒæ¥ãŸå ´åˆï¼‰ ---
    acct = ExternalBlogAccount.query.get(account_id)
    if not acct:
        return jsonify({"ok": False, "error": "account not found"}), 404

    # site_id ã®æ•´åˆãƒã‚§ãƒƒã‚¯ï¼ˆå‹åˆã‚ã›æ¸ˆã¿ï¼‰
    try:
        if site_id is not None and getattr(acct, "site_id", None) is not None and int(acct.site_id) != int(site_id):
            current_app.logger.warning("[EXTSEO-CB] site/account mismatch: site_id=%s acc.site_id=%s",
                                       site_id, acct.site_id)
    except Exception:
        pass

    touched = False

    if blog_id and hasattr(acct, "livedoor_blog_id"):
        try:
            acct.livedoor_blog_id = blog_id
            if hasattr(acct, "username") and (not acct.username or str(acct.username).startswith("u-")):
                acct.username = blog_id
            touched = True
        except Exception:
            db.session.rollback()
            return jsonify({"ok": False, "error": "failed to save blog_id"}), 500

    if endpoint and hasattr(acct, "atompub_endpoint"):
        try:
            acct.atompub_endpoint = endpoint
            touched = True
        except Exception:
            db.session.rollback()
            return jsonify({"ok": False, "error": "failed to save endpoint"}), 500

    if api_key and hasattr(acct, "atompub_key_enc"):
        try:
            acct.atompub_key_enc = encrypt(api_key)
            if hasattr(acct, "api_post_enabled"):
                acct.api_post_enabled = True
            if hasattr(acct, "is_captcha_completed"):
                acct.is_captcha_completed = True
            touched = True
        except Exception:
            db.session.rollback()
            return jsonify({"ok": False, "error": "failed to save api_key"}), 500

    if touched:
        try:
            db.session.commit()
        except Exception:
            db.session.rollback()
            return jsonify({"ok": False, "error": "db commit failed"}), 500

    # ã‚»ãƒãƒ•ã‚©è§£æ”¾åˆ¤å®šï¼ˆçœç•¥å¯ã€‚æ—¢å­˜å®Ÿè£…ãŒã‚ã‚Œã°ãã®ã¾ã¾ï¼‰
    try:
        step_l = (step or "").lower()
        prog_i = None
        if isinstance(progress, (int, float)):
            try:
                prog_i = int(progress)
            except Exception:
                prog_i = None
        should_release = (
            step_l in {"apikey_received", "api_key_ok", "done", "complete", "failed", "error"}
            or bool(api_key)
            or (prog_i is not None and prog_i >= 100)
        )
        if should_release and tok:
            try:
                release(tok)  # æ—¢å­˜ã® try_acquire ã«å¯¾å¿œ
                current_app.logger.info("[EXTSEO-CB] released semaphore token")
            except Exception as e:
                current_app.logger.exception("[EXTSEO-CB] release token failed: %s", e)
            if session.get("extseo_token") == tok:
                session.pop("extseo_token", None)
    except Exception:
        pass

    return jsonify({"ok": True})



# --- å¤–éƒ¨SEO: ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ˜ãƒ«ãƒ‘ãƒ¼ãŒCAPTCHAç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹å—ã‘å£ ---
@bp.post("/external-seo/prepare_captcha")
def external_seo_prepare_captcha_upload():
    """
    ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆ127.0.0.1ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼ï¼‰ãŒæ’®ã£ãŸCAPTCHAç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€‚
    æœŸå¾…: multipart/form-data ã§ file(or captcha), token, site_id, account_id ã‚’å—ã‘å–ã‚‹
    è¿”å´: { ok: True, captcha_url: "https://.../static/captchas/xxx.png" }
    """
    from flask import request, session, jsonify, url_for, current_app
    from pathlib import Path
    from uuid import uuid4
    import time as _time

    # token ã¯ /external-seo/start ã§æ‰•ã„å‡ºã—ãŸã‚‚ã®
    tok = (request.form.get("token") or request.values.get("token") or "").strip()
    if not tok:
        return jsonify({"ok": False, "error": "missing token"}), 400

    # ä»»æ„ã®æ•´åˆãƒã‚§ãƒƒã‚¯ï¼ˆã‚ºãƒ¬ã¦ã‚‚è‡´å‘½ã§ã¯ãªã„ã®ã§è­¦å‘Šãƒ­ã‚°ã®ã¿ï¼‰
    try:
        if session.get("extseo_token") and session["extseo_token"] != tok:
            current_app.logger.warning("[EXTSEO-UP] token mismatch (session present but different)")
    except Exception:
        pass

    # ãƒ•ã‚¡ã‚¤ãƒ«ã¯ 'file' ã¾ãŸã¯ 'captcha' ã®ã©ã¡ã‚‰ã§ã‚‚å—ã‘ã‚‹
    f = request.files.get("file") or request.files.get("captcha")
    if not f or not getattr(f, "filename", ""):
        return jsonify({"ok": False, "error": "no file"}), 400

    # ä»˜å¸¯æƒ…å ±ï¼ˆã‚ã‚Œã°ä¿å­˜ï¼‰
    site_id = request.form.get("site_id", type=int)
    account_id = request.form.get("account_id", type=int)

    # ä¿å­˜
    capt_dir = Path("app/static/captchas")
    capt_dir.mkdir(parents=True, exist_ok=True)
    ts = _time.strftime("%Y%m%d_%H%M%S")
    name = f"captcha_{ts}_{uuid4().hex[:8]}.png"
    save_path = capt_dir / name
    f.save(str(save_path))

    # å…¬é–‹URL
    captcha_url = url_for("static", filename=f"captchas/{name}", _external=True) + f"?v={int(_time.time())}"

    # âœ… ãƒ–ãƒ©ã‚¦ã‚¶ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¾å­˜ã›ãšã€ãƒˆãƒ¼ã‚¯ãƒ³ã§çŠ¶æ…‹ã‚’ä¿æŒ
    _extseo_update(tok,
                   step="captcha_shown",
                   progress=20,
                   captcha_url=captcha_url,
                   site_id=site_id,
                   account_id=account_id)

    # äº’æ›: ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½¿ã†UIãŒæ®‹ã£ã¦ã„ã‚‹å ´åˆã®ãŸã‚ã«ã€å…¥ã‚Œã¦ã‚‚ãŠãï¼ˆè¦‹ãˆãªã„ç’°å¢ƒãªã‚‰ç„¡è¦–ã•ã‚Œã‚‹ã ã‘ï¼‰
    try:
        st = dict(session.get("captcha_status") or {})
        st.update({
            "step": "captcha_shown",
            "progress": max(15, int(st.get("progress") or 0)),
            "captcha_url": captcha_url,
            "site_id": site_id or st.get("site_id"),
            "account_id": account_id or st.get("account_id"),
        })
        session["captcha_status"] = st
    except Exception:
        pass

    return jsonify({"ok": True, "captcha_url": captcha_url})


# ===========================
# Topic Anchors / Topic Page
# ===========================

# --- å·®åˆ†: æ–°ã—ã„ãƒ«ãƒ¼ãƒˆæ§‹æˆ ---
# 1) /topic/anchors           â†’ ã‚¢ãƒ³ã‚«ãƒ¼æ–‡ç”Ÿæˆã®ã¿ï¼ˆWPæŠ•ç¨¿ãªã—ï¼‰
# 2) /topic/build-skeleton    â†’ WPã«ä¸‹æ›¸ãã‚’ä½œæˆï¼ˆå¿…è¦ãªã¨ãã®ã¿ï¼‰
# 3) /topic/generate-now      â†’ ã‚¯ãƒªãƒƒã‚¯ç¬é–“ã«æœ¬æ–‡ç”Ÿæˆãƒ»WPæ›´æ–°ãƒ»URLè¿”å´
from urllib.parse import unquote, quote

# =====================================================
# 1ï¸âƒ£ /topic/anchors ï¼ˆã‚¢ãƒ³ã‚«ãƒ¼æ–‡ç”Ÿæˆã®ã¿ã€éª¨çµ„ã¿æŠ•ç¨¿ã¯åˆ†é›¢ï¼‰
# =====================================================
from app.models import Site
@bp.post("/topic/anchors")
def topic_anchors():
    ok, auth_uid = _topic_api_authorized()
    if not ok or not auth_uid:
        return jsonify({"ok": False, "error": "unauthorized"}), 401

    data = request.get_json(silent=True) or {}
    site_id = data.get("site_id")
    source_url = data.get("source_url") or ""
    current_title = data.get("current_title") or ""
    page_summary = data.get("page_summary") or ""
    user_traits = data.get("user_traits") or None
    topic_prompt_id = data.get("topic_prompt_id")

    if not site_id:
        return jsonify({"ok": False, "error": "site_id required"}), 400
    site = Site.query.get(site_id)
    if not site:
        return jsonify({"ok": False, "error": "invalid site_id"}), 400
    if auth_uid != site.user_id:
        return jsonify({"ok": False, "error": "forbidden site ownership"}), 403

    # URLãŒè‡ªåˆ†ã®ã‚µã‚¤ãƒˆé…ä¸‹ã‹ç¢ºèªï¼ˆæœ«å°¾ã‚¹ãƒ©ãƒƒã‚·ãƒ¥å·®ç•°ã‚’æ­£è¦åŒ–ï¼‰
    site_base = (site.url or "").rstrip("/")
    if site_base and not source_url.startswith(site_base):
        return jsonify({"ok": False, "error": "invalid source domain"}), 400

    # 1) ã‚¢ãƒ³ã‚«ãƒ¼æ–‡ã®ã¿ç”Ÿæˆ
    from app.services.topics import generator as tg
    try:
        anchors = tg.generate_anchor_texts(
            user_id=site.user_id,
            site_id=site_id,
            source_url=source_url,
            current_title=current_title,
            page_summary=page_summary,
            user_traits_json=user_traits,
        )
    except Exception as e:
        current_app.logger.exception("[topic_anchors] anchor generation failed: %s", e)
        return jsonify({"ok": False, "error": "anchor generation failed"}), 500

    # 2) å„ã‚¢ãƒ³ã‚«ãƒ¼ã« slug ã‚’å‰²ã‚Šå½“ã¦ã‚‹ï¼ˆéª¨çµ„ã¿ã¯ã¾ã ä½œã‚‰ãªã„ï¼‰
    results = {}
    for pos, item in (("top", anchors.top), ("bottom", anchors.bottom)):
        results[pos] = {
            "text": item.text,
            # hrefã¯generate-nowã«slugæŒ‡å®šã§èª˜å°ï¼ˆposæƒ…å ±ã‚’ä»˜åŠ ï¼‰
            "href": url_for(".topic_generate_now", slug=item.slug, pos=pos, _external=True),
        }
    return jsonify({"ok": True, "anchors": results}), 200


# =====================================================
# 2ï¸âƒ£ /topic/build-skeleton ï¼ˆWPä¸‹æ›¸ãã‚’æ˜ç¤ºçš„ã«ä½œæˆï¼‰
# =====================================================
@bp.post("/topic/build-skeleton")
def topic_build_skeleton():
    ok, auth_uid = _topic_api_authorized()
    if not ok:
        return jsonify({"ok": False, "error": "unauthorized"}), 401

    data = request.get_json(silent=True) or {}
    slug = data.get("slug") or ""
    # URLã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã§æ¸¡ã£ã¦ããŸ slug ã‚’ DB ã«ã¯å¸¸ã«â€œç”Ÿæ–‡å­—åˆ—â€ã§ä¿å­˜ã™ã‚‹
    slug = unquote(slug)
    site_id = data.get("site_id")
    title = data.get("title") or "æº–å‚™ä¸­ãƒˆãƒ”ãƒƒã‚¯"
    source_url = data.get("source_url") or ""

    from app.models import TopicPage, Site
    from app.wp_client import post_topic_to_wp
    site = Site.query.get(site_id)
    if not site:
        return jsonify({"ok": False, "error": "invalid site"}), 400
    if auth_uid != site.user_id:
        return jsonify({"ok": False, "error": "forbidden site ownership"}), 403

    page = TopicPage.query.filter_by(slug=slug).first()
    if not page:
        page = TopicPage(
            user_id=site.user_id,
            site_id=site.id,
            slug=slug,
            title=title,
            body="æº–å‚™ä¸­â€¦ï¼ˆæ•°ç§’å¾Œã«è‡ªå‹•æ›´æ–°ã•ã‚Œã¾ã™ï¼‰",
            meta={"source_url": source_url, "phase": "skeleton"},
        )
        db.session.add(page)
        db.session.commit()

    # WPä¸‹æ›¸ãã‚’æŠ•ç¨¿ï¼ˆå†æŠ•ç¨¿ã§ã‚‚å®‰å…¨ï¼‰
    # è¦ä»¶: è‡ªå‹•ç”Ÿæˆã•ã‚Œã‚‹topicãƒšãƒ¼ã‚¸ã®URLã«ã¯ `topic` ã‚’ä»˜ã‘ã‚‹ï¼ˆæœ€å°å®Ÿè£…ã¨ã—ã¦ slug ã« `topic-` ã‚’å‰ç½®ï¼‰
    wp_slug = slug
    if not wp_slug.startswith("topic-"):
        wp_slug = f"topic-{wp_slug}"
    # âœ è¦æœ›: è‡ªå‹•ç”ŸæˆURLã«ã€Œtopicã€ã‚’ä»˜ã‘ã‚‹ï¼ˆæœ€å°å®Ÿè£…ï¼šslugã‚’ topic- å‰ç½®ï¼‰
    wp_slug = slug if slug.startswith("topic-") else f"topic-{slug}"
    post_id, link = post_topic_to_wp(
        site=site,
        title=page.title,
        html="<p>æº–å‚™ä¸­â€¦</p>",
        slug=wp_slug,
    )
    page.meta = dict(page.meta or {}) | {"wp_post_id": post_id}
    page.published_url = link
    db.session.commit()

    return jsonify({"ok": True, "slug": slug, "published_url": link}), 200


# =====================================================
# 3ï¸âƒ£ /topic/generate-now ï¼ˆã‚¯ãƒªãƒƒã‚¯ç¬é–“ â†’ æœ¬æ–‡ç”Ÿæˆï¼†å³è¡¨ç¤ºï¼‰
# =====================================================
@bp.get("/topic/generate-now")
def topic_generate_now():
    """
    ã‚¯ãƒªãƒƒã‚¯ç›´å¾Œã«æœ¬æ–‡ã‚’åŒæœŸç”Ÿæˆã—ã€WPã‚’å³æ›´æ–°ã—ã¦è¡¨ç¤ºã€‚
    - ã‚¯ã‚¨ãƒª: ?slug=<slug>&pos=top|bottom
    """
    from app.models import TopicPage, Site, TopicAnchorLog
    from app.services.topics import generator as tg
    from app.wp_client import update_post_content, post_topic_to_wp
    import time
    # URLã‹ã‚‰æ¥ãŸ slug ã‚’â€œç”Ÿæ–‡å­—åˆ—â€ã«æ­£è¦åŒ–ï¼ˆURLãƒ‡ã‚³ãƒ¼ãƒ‰ï¼‰
    slug = unquote(request.args.get("slug", "") or "")
    pos = request.args.get("pos", "unknown")

    page = TopicPage.query.filter_by(slug=slug).first()
    if not page:
        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãŒâ€œURLã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰slugâ€ã§ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã‚±ãƒ¼ã‚¹ã‚’æ•‘æ¸ˆ
        encoded = quote(slug, safe="")
        page = TopicPage.query.filter_by(slug=encoded).first()
    if not page:
        abort(404)
    site = Site.query.get(page.site_id)
    if not site:
        abort(404)

    start = time.time()
    # æ—¢ã«æœ€çµ‚ç”Ÿæˆæ¸ˆã¿ãªã‚‰å³ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ
    if (page.meta or {}).get("phase") == "final" and page.published_url:
        return redirect(page.published_url, code=302)

    # æœ¬æ–‡ç”Ÿæˆ
    try:
        affiliates = tg._get_affiliate_links(page.user_id, page.site_id, limit=2)
        filled_prompt = tg.OFFICIAL_TOPIC_PROMPT.format(
            user_traits="{}",
            title="",
            summary="",
            anchor=page.title,
            affiliates=json.dumps(affiliates, ensure_ascii=False),
        )
        out = tg._chat(
            [{"role": "system", "content": "å‡ºåŠ›å½¢å¼ã«å³å¯†ã«å¾“ã£ã¦ãã ã•ã„ã€‚"},
             {"role": "user", "content": filled_prompt}],
            max_t=2000, temp=0.5, user_id=page.user_id,
            timeout=0.8  # æ˜ç¤ºçš„ãªç· åˆ‡ï¼ˆç§’ï¼‰
        )

        m1 = re.search(r"ã€ã‚¿ã‚¤ãƒˆãƒ«ã€‘\s*(.+?)\s*ã€æœ¬æ–‡ã€‘", out, flags=re.DOTALL)
        m2 = re.search(r"ã€æœ¬æ–‡ã€‘\s*(.+)$", out, flags=re.DOTALL)
        title = (m1.group(1) or page.title).strip() if m1 else page.title
        body = (m2.group(1) or "").strip() if m2 else "æœ¬æ–‡ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚"

        if affiliates and "ãŠã™ã™ã‚ã¯ã“ã¡ã‚‰" not in body:
            a = affiliates[0]
            body += f"\n\nãŠã™ã™ã‚ã¯ã“ã¡ã‚‰ï¼š{a.get('title','ãŠã™ã™ã‚')}ï¼ˆ{a.get('url','')}ï¼‰"

        page.body = body
        page.title = title
        page.meta = dict(page.meta or {}) | {"phase": "final", "gen_ms": int((time.time() - start)*1000)}
        db.session.commit()

        # WP æ›´æ–°
        html = tg._topic_to_html(page.title, page.body or "")
        post_id = (page.meta or {}).get("wp_post_id")
        if site and post_id:
            update_post_content(site=site, post_id=post_id, new_html=html)
        elif site:
            # è¦ä»¶: URLã« `topic` ã‚’ä»˜ã‘ã‚‹
            wp_slug = page.slug if page.slug.startswith("topic-") else f"topic-{page.slug}"
            pid, link = post_topic_to_wp(site=site, title=page.title, html=html, slug=wp_slug)
            page.meta["wp_post_id"] = pid
            page.published_url = link
            db.session.commit()

        # ã‚¯ãƒªãƒƒã‚¯ãƒ­ã‚°
        db.session.add(TopicAnchorLog(
            user_id=page.user_id, site_id=page.site_id, page_id=page.id,
            source_url=(page.meta or {}).get("source_url") or "",
            position=pos, anchor_text=page.title, event="click"
        ))
        db.session.commit()

        # å³ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ
        if page.published_url:
            return redirect(page.published_url, code=302)
        return jsonify({"ok": True, "fallback_used": False, "slug": slug}), 200

    except Exception as e:
        current_app.logger.exception("[topic_generate_now] final generation failed: %s", e)
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬æœ¬æ–‡ï¼‰
        body = "ãƒšãƒ¼ã‚¸ç”ŸæˆãŒæ··ã¿åˆã£ã¦ã„ã¾ã™ã€‚æ•°ç§’å¾Œã«å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
        html = f"<h2>{page.title}</h2><p>{body}</p>"
        post_id = (page.meta or {}).get("wp_post_id")
        if site and post_id:
            update_post_content(site=site, post_id=post_id, new_html=html)
        return jsonify({"ok": True, "fallback_used": True}), 200


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒªãƒ©ã‚¤ãƒˆæ©Ÿèƒ½ãƒ¦ãƒ¼ã‚¶ãƒ¼ç”»é¢ï¼ˆæœ¬äººå°‚ç”¨ç°¡æ˜“ç‰ˆï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@bp.route("/rewrite", defaults={"username": None}, methods=["GET"])
@bp.route("/<username>/rewrite", methods=["GET"])
@login_required
def user_rewrite_dashboard(username):
    """
    ãƒ­ã‚°ã‚¤ãƒ³ãƒ¦ãƒ¼ã‚¶ãƒ¼è‡ªèº«ã®ã‚µã‚¤ãƒˆä¸€è¦§ï¼‹ãƒªãƒ©ã‚¤ãƒˆé€²æ—ã‚’è¡¨ç¤ºã™ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ç”¨ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã€‚
    ç®¡ç†ç”»é¢ /admin/rewrite/user/<id> ã¨åŒã˜é›†è¨ˆãƒ­ã‚¸ãƒƒã‚¯ã‚’ä½¿ã†ã€‚
    """
    # ç®¡ç†ç”¨ã¨åŒã˜ãƒ˜ãƒ«ãƒ‘ã‚’å†åˆ©ç”¨
    rows = _rewrite_counts_for_user_sites(current_user.id)

    return render_template(
        "rewrite.html",
        user=current_user,
        rows=rows,
    )


@bp.route("/rewrite/enqueue", defaults={"username": None}, methods=["POST"])
@bp.route("/<username>/rewrite/enqueue", methods=["POST"])
@login_required
def user_rewrite_enqueue_self(username):
    payload = request.get_json(silent=True) or {}
    def _to_int_list(v):
        if v is None or v == "":
            return None
        if isinstance(v, list):
            return [int(x) for x in v if str(x).strip().isdigit()]
        return [int(x) for x in str(v).replace("\n", ",").split(",") if x.strip().isdigit()]
    site_ids = _to_int_list(payload.get("site_ids"))
    article_ids = _to_int_list(payload.get("article_ids"))
    priority = float(payload.get("priority", 0.0))
    res = rewrite_enqueue_for_user(current_user.id, site_ids=site_ids, article_ids=article_ids, priority=priority)
    return jsonify({"ok": True, "result": res})

@bp.route("/rewrite/progress", defaults={"username": None}, methods=["GET"])
@bp.route("/<username>/rewrite/progress", methods=["GET"])
@login_required
def user_rewrite_progress_self(username):
    # ç®¡ç†APIã«å§”è­²ï¼ˆuser_id æŒ‡å®šï¼‰
    with current_app.test_request_context(f"/admin/rewrite/progress?user_id={current_user.id}"):
        return admin_rewrite_progress()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ¦ãƒ¼ã‚¶ãƒ¼ç”¨: ã‚µã‚¤ãƒˆåˆ¥ã®ãƒªãƒ©ã‚¤ãƒˆæ¸ˆã¿è¨˜äº‹ä¸€è¦§
# URL:
#   /rewrite/site/<site_id>
#   /<username>/rewrite/site/<site_id>
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@bp.route("/rewrite/site/<int:site_id>", defaults={"username": None}, methods=["GET"])
@bp.route("/<username>/rewrite/site/<int:site_id>", methods=["GET"])
@login_required
def user_rewrite_site_articles(username, site_id):
    """
    ãƒ­ã‚°ã‚¤ãƒ³ãƒ¦ãƒ¼ã‚¶ãƒ¼è‡ªèº«ã®ã‚µã‚¤ãƒˆã«å¯¾ã™ã‚‹ãƒªãƒ©ã‚¤ãƒˆæ¸ˆã¿è¨˜äº‹ä¸€è¦§ã€‚
    ç®¡ç†å´ admin_rewrite_site_articles ã¨åŒã˜é›†è¨ˆãƒ­ã‚¸ãƒƒã‚¯ã§ã€
    HTML ã‚‚ç®¡ç†ãƒ†ãƒ³ãƒ—ãƒ¬ã¨æƒãˆã‚„ã™ã„å½¢ã«æ•´å½¢ã™ã‚‹ã€‚
    """
    from sqlalchemy import text as _sql
    from urllib.parse import urljoin
    from app.models import Site
    from app.services.rewrite.state_view import fetch_site_totals

    # ã‚µã‚¤ãƒˆãŒ current_user æ‰€æœ‰ã‹ãƒã‚§ãƒƒã‚¯
    site = db.session.get(Site, site_id)
    if not site or site.user_id != current_user.id:
        abort(404)

    # ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    status = (request.args.get("status") or "").strip().lower()
    page   = max(1, request.args.get("page", type=int) or 1)
    per    = min(100, max(10, request.args.get("per", type=int) or 50))

    # è¨±å®¹ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ï¼ˆsuccess / failed ã®2ç³»çµ±ï¼‰
    allowed = {"success", "failed"}
    if status not in allowed:
        status = "success"

    bucket = "success" if status == "success" else "failed"

    # â”€â”€ ã‚µã‚¤ãƒˆå…¨ä½“ã®çµ±ä¸€ã‚«ã‚¦ãƒ³ãƒˆï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼ç”¨ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    totals = fetch_site_totals(user_id=current_user.id, site_id=site_id)
    stats = {
        "queued":  int(totals.get("waiting", 0)),
        "running": int(totals.get("running", 0)),
        "success": int(totals.get("success", 0)),
        "error":   int(totals.get("failed", 0)),
        "unknown": int(totals.get("other", 0)),
    }
    # ç®¡ç†ãƒ†ãƒ³ãƒ—ãƒ¬äº’æ›ï¼šdisplay_error ã‚’å¿…ãšæŒãŸã›ã‚‹
    stats["display_error"] = stats.get("error", 0)

    # â”€â”€ ä¸€è¦§å¯¾è±¡ article_id ã‚’ vw_rewrite_state ã‹ã‚‰æŠ½å‡ºï¼ˆç®¡ç†å´ã¨åŒã˜ï¼‰ â”€â”€
    ids_sql = _sql("""
      SELECT article_id
      FROM vw_rewrite_state
      WHERE user_id = :uid AND site_id = :sid AND final_bucket = :bucket
      ORDER BY log_executed_at DESC NULLS LAST,
               plan_created_at DESC NULLS LAST,
               article_id DESC
      LIMIT :limit OFFSET :offset
    """)
    id_rows = db.session.execute(
        ids_sql,
        {
            "uid": current_user.id,
            "sid": site_id,
            "bucket": bucket,
            "limit": per,
            "offset": (page - 1) * per,
        },
    ).fetchall()
    article_ids = [int(r[0]) for r in id_rows]

    # ç·ä»¶æ•°ï¼ˆãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ç”¨ï¼‰
    total_sql = _sql("""
      SELECT COUNT(*) FROM vw_rewrite_state
      WHERE user_id = :uid AND site_id = :sid AND final_bucket = :bucket
    """)
    total_count = int(
        db.session.execute(
            total_sql,
            {"uid": current_user.id, "sid": site_id, "bucket": bucket},
        ).scalar()
        or 0
    )

    # â”€â”€ è©³ç´°è¡Œã‚’å–å¾—ï¼ˆç®¡ç†å´ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    rows = []
    if article_ids:
        if status == "success":
            # å„è¨˜äº‹ã®æœ€æ–° success ãƒ­ã‚°
            detail_sql = _sql("""
              WITH latest AS (
                SELECT
                  l.id         AS log_id,
                  l.article_id,
                  l.plan_id,
                  l.wp_post_id,
                  l.executed_at,
                  ROW_NUMBER() OVER (
                    PARTITION BY l.article_id
                    ORDER BY l.executed_at DESC, l.id DESC
                  ) AS rn
                FROM article_rewrite_logs l
                WHERE l.article_id = ANY(:ids)
                  AND l.wp_status = 'success'
              )
              SELECT
                lt.log_id,
                a.id          AS article_id,
                a.title       AS title,
                lt.plan_id    AS plan_id,
                lt.wp_post_id AS wp_post_id,
                lt.executed_at AS executed_at
              FROM latest lt
              JOIN articles a ON a.id = lt.article_id
              WHERE lt.rn = 1
              ORDER BY lt.executed_at DESC NULLS LAST, a.id DESC
            """)
            rows = list(
                db.session.execute(detail_sql, {"ids": article_ids}).mappings()
            )
        else:
            # å„è¨˜äº‹ã®æœ€æ–° failed ç³»ãƒ­ã‚°
            detail_sql = _sql("""
              WITH latest AS (
                SELECT
                  l.id         AS log_id,
                  l.article_id,
                  l.plan_id,
                  l.wp_post_id,
                  l.executed_at,
                  l.wp_status,
                  ROW_NUMBER() OVER (
                    PARTITION BY l.article_id
                    ORDER BY l.executed_at DESC, l.id DESC
                  ) AS rn
                FROM article_rewrite_logs l
                WHERE l.article_id = ANY(:ids)
                  AND l.wp_status IN (
                    'failed','error','canceled','aborted','timeout','stale'
                  )
              )
              SELECT
                lt.log_id,
                a.id          AS article_id,
                a.title       AS title,
                lt.plan_id    AS plan_id,
                lt.wp_post_id AS wp_post_id,
                lt.executed_at AS executed_at,
                lt.wp_status  AS wp_status
              FROM latest lt
              JOIN articles a ON a.id = lt.article_id
              WHERE lt.rn = 1
              ORDER BY lt.executed_at DESC NULLS LAST, a.id DESC
            """)
            rows = list(
                db.session.execute(detail_sql, {"ids": article_ids}).mappings()
            )

    # â”€â”€ ãƒ†ãƒ³ãƒ—ãƒ¬äº’æ›: articles é…åˆ—ã‚’æ§‹ç¯‰ï¼ˆç®¡ç†ãƒ†ãƒ³ãƒ—ãƒ¬ã¨åŒã˜ã‚­ãƒ¼æ§‹æˆï¼‰ â”€â”€
    articles = []
    base_url = (site.site_url or site.url or "").rstrip("/")
    _last_dt = None

    for r in rows:
        dt = r.get("executed_at")
        if dt and (_last_dt is None or dt > _last_dt):
            _last_dt = dt

        wp_post_id = r.get("wp_post_id")
        if status == "success" and wp_post_id and base_url:
            wp_url = urljoin(base_url + "/", f"?p={wp_post_id}")
        else:
            wp_url = None

        # ç®¡ç†ãƒ†ãƒ³ãƒ—ãƒ¬ã¨åŒã˜ã‚­ãƒ¼å
        articles.append(
            {
                "id":         r.get("article_id"),
                "article_id": r.get("article_id"),
                "title":      r.get("title"),
                "status":     status,  # success / failed
                "updated_at": (dt.isoformat() if dt else None),
                "posted_url": None,
                "wp_url":     wp_url,
                "plan_id":    r.get("plan_id"),
                "log_id":     r.get("log_id"),
            }
        )

    last_updated = _last_dt.isoformat() if _last_dt else None

    # â”€â”€ ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±ï¼ˆç®¡ç†ãƒ†ãƒ³ãƒ—ãƒ¬ã¨åŒã˜æ§‹é€ ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    total_pages = (total_count + per - 1) // per if per > 0 else 1
    first_idx = ((page - 1) * per + 1) if total_count > 0 else 0
    last_idx  = min(page * per, total_count)

    prev_url = (
        url_for(
            "main.user_rewrite_site_articles",
            site_id=site_id,
            status=status,
            page=page - 1,
            per=per,
        )
        if page > 1
        else None
    )
    next_url = (
        url_for(
            "main.user_rewrite_site_articles",
            site_id=site_id,
            status=status,
            page=page + 1,
            per=per,
        )
        if page * per < total_count
        else None
    )

    pagination = {
        "total": total_count,
        "page": page,
        "per": per,
        "pages": total_pages,
        "first": first_idx,
        "last": last_idx,
        "prev_url": prev_url,
        "next_url": next_url,
    }

    return render_template(
        "rewrite_site_articles.html",
        site=site,
        site_id=site_id,
        stats=stats,
        status=status,
        per=per,
        articles=articles,
        pagination=pagination,
        last_updated=last_updated,
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ¦ãƒ¼ã‚¶ãƒ¼ç”¨: ãƒªãƒ©ã‚¤ãƒˆãƒ­ã‚°è©³ç´°ï¼ˆä¿®æ­£æ–¹é‡ï¼‰
# URL:
#   /rewrite/log/<log_id>
#   /<username>/rewrite/log/<log_id>
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@bp.route("/rewrite/log/<int:log_id>", defaults={"username": None}, methods=["GET"])
@bp.route("/<username>/rewrite/log/<int:log_id>", methods=["GET"])
@login_required
def user_rewrite_log_detail(username, log_id):
    """
    ãƒ­ã‚°IDå˜ä½ã®è©³ç´°ã€‚
    ç®¡ç†ç”»é¢ã®ä¿®æ­£æ–¹é‡è©³ç´°ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘ã«ç°¡ç•¥è¡¨ç¤ºã€‚
    """
    from urllib.parse import urljoin
    from app.models import ArticleRewriteLog, Article, Site

    log = db.session.get(ArticleRewriteLog, log_id)
    if not log:
        abort(404)

    article = db.session.get(Article, log.article_id)
    if not article or article.user_id != current_user.id:
        # ä»–äººã®è¨˜äº‹ã®ãƒ­ã‚°ã¯è¦‹ã›ãªã„
        abort(404)

    site = db.session.get(Site, article.site_id) if article.site_id else None

    # WPãƒªãƒ³ã‚¯ï¼ˆã‚ãã¾ã§ç°¡æ˜“ã€‚permalinkæ§‹é€ ã¯è€ƒæ…®ã—ãªã„ï¼‰
    wp_url = None
    if site and getattr(log, "wp_post_id", None):
        wp_url = urljoin((site.url or "").rstrip("/") + "/", f"?p={log.wp_post_id}")

    return render_template(
        "rewrite_log_detail.html",
        log=log,
        article=article,
        site=site,
        wp_url=wp_url,
    )

