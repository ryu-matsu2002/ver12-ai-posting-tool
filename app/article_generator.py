# app/article_generator.py
# æœ€æ–°ç‰ˆï¼šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ100%åæ˜  + ã‚¿ã‚¤ãƒˆãƒ«/æœ¬æ–‡å‡ºåŠ›ãƒã‚°ä¿®æ­£æ¸ˆ

import os, re, random, threading, logging, requests
from datetime import datetime, date, timedelta, time, timezone
from typing import List, Dict, Tuple
from difflib import SequenceMatcher
import pytz
from flask import current_app
from openai import OpenAI, BadRequestError
from sqlalchemy import func
from threading import Event
from .image_utils import fetch_featured_image_from_body  # â† è¿½åŠ 
from . import db
from .models import Article
from concurrent.futures import ThreadPoolExecutor, as_completed

# OpenAIè¨­å®š
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY", ""))
MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

# ğŸ”§ tokenæ•°åˆ¶é™ï¼ˆæœ¬æ–‡åˆ‡ã‚Œå¯¾ç­–ï¼‰
TOKENS = {
    "title": 120,
    "outline": 800,
    "block": 3600
}

# ğŸ”§ æ¸©åº¦è¨­å®šï¼ˆå‡ºåŠ›ã®ãƒ–ãƒ¬æŠ‘åˆ¶ï¼‰
TEMP = {
    "title": 0.6,
    "outline": 0.65,
    "block": 0.65
}

TOP_P = 0.9
CTX_LIMIT = 12000
SHRINK = 0.85
MAX_BODY_CHARS_DEFAULT = 4000
MAX_TITLE_RETRY = 7
TITLE_DUP_THRESH = 0.90
JST = pytz.timezone("Asia/Tokyo")
POST_HOURS = list(range(10, 21))
MAX_PERDAY = 5
AVERAGE_POSTS = 4
MAX_SCHEDULE_DAYS = 30  # â† æœ¬æ—¥ã‹ã‚‰30æ—¥ä»¥å†…ã®æŠ•ç¨¿æ ã«é™å®š

# ============================================
# ğŸ”§ å®‰å…¨ãªå‡ºåŠ›ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°é–¢æ•°
# GPTãŒ <html> ã‚„ <body> ã§å›²ã‚“ã§ãã‚‹ã‚±ãƒ¼ã‚¹ã‚’é™¤å»
# ============================================
def clean_gpt_output(text: str) -> str:
    text = re.sub(r"```(?:html)?", "", text)
    text = re.sub(r"```", "", text)
    text = re.sub(r"<!DOCTYPE html>.*?<body.*?>", "", text, flags=re.DOTALL|re.IGNORECASE)
    text = re.sub(r"</body>.*?</html>", "", text, flags=re.DOTALL|re.IGNORECASE)
    return text.strip()

# ============================================
# ğŸ”§ ãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ãƒˆï¼ˆæ¦‚ç®—ï¼‰
# ============================================
def _tok(s: str) -> int:
    return int(len(s) / 1.8)

# ============================================
# ğŸ”§ OpenAIãƒãƒ£ãƒƒãƒˆå‘¼ã³å‡ºã—é–¢æ•°
# ============================================
def _chat(msgs: List[Dict[str, str]], max_t: int, temp: float) -> str:
    used = sum(_tok(m["content"]) for m in msgs)
    available = CTX_LIMIT - used - 16
    max_t = min(max_t, available)
    if max_t < 1:
        raise ValueError("Calculated max_tokens is below minimum.")

    def _call(m: int) -> str:
        res = client.chat.completions.create(
            model=MODEL,
            messages=msgs,
            max_tokens=m,
            temperature=temp,
            top_p=TOP_P,
            timeout=120,
        )
        content = res.choices[0].message.content.strip()
        finish = res.choices[0].finish_reason

        if finish == "length":
            logging.warning("âš ï¸ OpenAI response was cut off due to max_tokens.")
            content += "<p><em>â€»ã“ã®æ–‡ç« ã¯ãƒˆãƒ¼ã‚¯ãƒ³ä¸Šé™ã§é€”ä¸­çµ‚äº†ã—ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚</em></p>"

        return clean_gpt_output(content)

    try:
        return _call(max_t)
    except BadRequestError as e:
        if "max_tokens" in str(e):
            retry_t = max(1, int(max_t * SHRINK))
            return _call(retry_t)
        raise

# ============================================
# ğŸ”§ ã‚¿ã‚¤ãƒˆãƒ«é¡ä¼¼æ€§ãƒã‚§ãƒƒã‚¯
# ============================================
def _similar(a: str, b: str) -> bool:
    return SequenceMatcher(None, a, b).ratio() >= TITLE_DUP_THRESH

# ============================================
# âœ… ä¿®æ­£æ¸ˆã¿ï¼šã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆï¼ˆHTMLæ’é™¤ãƒ»1è¡Œåˆ¶é™ï¼‰
# ============================================
def _title_once(kw: str, pt: str, retry: bool) -> str:
    extra = "\nâ€»éå»ã«ä½¿ã‚ã‚ŒãŸã‚¿ã‚¤ãƒˆãƒ«ã‚„ä¼¼ãŸã‚¿ã‚¤ãƒˆãƒ«ã‚’çµ¶å¯¾ã«é¿ã‘ã¦ãã ã•ã„ã€‚" if retry else ""
    usr = f"{pt}{extra}\n\nâ–¼ æ¡ä»¶\n- å¿…ãšã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚ã‚‹\n- ã‚¿ã‚¤ãƒˆãƒ«ã¯ãƒ¦ãƒ‹ãƒ¼ã‚¯ã§ã‚ã‚‹ã“ã¨\n- å‡ºåŠ›ã¯1è¡Œã ã‘\n- ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é †ã¯å¤‰æ›´ä¸å¯\nâ–¼ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {kw}"
    sys = "ã‚ãªãŸã¯SEOã«å¼·ã„æ—¥æœ¬èªãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚çµ¶å¯¾ã«ã‚¿ã‚¤ãƒˆãƒ«1è¡Œã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
    return _chat([
        {"role": "system", "content": sys},
        {"role": "user", "content": usr},
    ], TOKENS["title"], TEMP["title"])

# ============================================
# ğŸ”§ ã‚¿ã‚¤ãƒˆãƒ«ã®ä¸€æ„æ€§ä¿è¨¼
# ============================================
def _unique_title(kw: str, pt: str) -> str:
    history = [t[0] for t in db.session.query(Article.title).filter(Article.keyword == kw)]
    last_cand = ""
    for i in range(MAX_TITLE_RETRY):
        cand = _title_once(kw, pt, retry=i > 0)
        if not any(_similar(cand, h) for h in history):
            return cand
        last_cand = cand  # æœ€å¾Œã«è©¦ã—ãŸå€™è£œã‚’è¨˜éŒ²
    # ã™ã¹ã¦é¡ä¼¼ â†’ æœ€å¾Œã®å€™è£œã‚’å¼·åˆ¶æ¡ç”¨
    logging.warning(f"[ã‚¿ã‚¤ãƒˆãƒ«é¡ä¼¼è­¦å‘Š] {kw} ã«å¯¾ã—ã¦é¡ä¼¼ã‚¿ã‚¤ãƒˆãƒ«ãŒå¤šã™ãã¾ã—ãŸãŒæœ€å¾Œã®å€™è£œã‚’æ¡ç”¨ã—ã¾ã™")
    return last_cand


# ============================================
# âœ… ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¸Œæœ›æ–‡å­—æ•°ã‚’GPTã«æ˜ç¤ºã—ã¦é•·ã•ä¸è¶³ã‚’é˜²æ­¢
# ============================================
def _compose_body(kw: str, pt: str, format: str = "html", self_review: bool = False) -> str:
    """
    SEOè¨˜äº‹æœ¬æ–‡ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°ï¼ˆè¿½è¨˜ãªã—ãƒ»æ§‹é€ å¼·åˆ¶ãƒ»è£…é£¾ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ä»˜ãï¼‰

    Args:
        kw: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        pt: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        format: "html" ã¾ãŸã¯ "markdown"
        self_review: True ã§è‡ªå·±æ·»å‰Šã‚’å®Ÿè¡Œ

    Returns:
        æœ¬æ–‡ï¼ˆHTMLã¾ãŸã¯Markdownå½¢å¼ï¼‰
    """
    min_chars, max_chars_user = _parse_range(pt)
    max_total = max_chars_user or MAX_BODY_CHARS_DEFAULT

    # ğŸ“Œå½¢å¼ã«å¿œã˜ãŸæ§‹æˆ/è£…é£¾æŒ‡ç¤º
    if format == "markdown":
        structure_helper = (
            "\n- Markdownå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆ## è¦‹å‡ºã—ã€### ã‚µãƒ–è¦‹å‡ºã—ã€- ç®‡æ¡æ›¸ãã€**å¼·èª¿**ï¼‰"
            "\n- ## è¦‹å‡ºã—ã¯3ã€œ5å€‹ã¾ã§ã«ã—ã¦ãã ã•ã„"
            "\n- ç•ªå·ä»˜ãå°è¦‹å‡ºã—ï¼ˆ1.ã€œãªã©ï¼‰ã¯ ### ã‚’ä½¿ã£ã¦ãã ã•ã„"
            "\n- æœ€å¾Œã¯ ## ã¾ã¨ã‚ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§å¿…ãšç· ã‚ã¦ãã ã•ã„"
        )
    else:
        structure_helper = (
            "\n- HTMLå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„"
            "\n- <h2 class='wp-heading'>â€¦</h2> ã‚’3ã€œ5å€‹ä½¿ã£ã¦ãã ã•ã„"
            "\n- ç•ªå·ä»˜ãå°è¦‹å‡ºã—ï¼ˆ1.ã€œãªã©ï¼‰ã¯ <h3 class='wp-heading'>â€¦</h3> ã‚’ä½¿ã£ã¦ãã ã•ã„"
            "\n- ç®‡æ¡æ›¸ãã«ã¯ <ul><li>â€¦</li></ul> ã‚’ä½¿ã£ã¦ãã ã•ã„"
            "\n- æœ€å¾Œã¯ <h2 class='wp-heading'>ã¾ã¨ã‚</h2> ã§ç· ã‚ã¦ãã ã•ã„"
        )

    # ğŸ“Œæ–‡å­—æ•°åˆ¶ç´„ã‚’å¼·ãæŒ‡ç¤º
    char_instruction = f"\n- æœ¬æ–‡ã¯å¿…ãš {min_chars}ã€œ{max_total} å­—ã®ç¯„å›²ã§æ›¸ã„ã¦ãã ã•ã„"

    system_prompt = (
        "ã‚ãªãŸã¯ä¸€æµã®SEOè¨˜äº‹ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚"
        "ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŒ‡ç¤ºã«100%å¾“ã„ã€æ§‹é€ çš„ã§é«˜å“è³ªãªè¨˜äº‹ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
        f"{structure_helper}{char_instruction}"
    )
    user_prompt = f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {kw}\n\nâ–¼ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŒ‡ç¤º:\n{pt}"

    # âœ…1å›ã®ã¿ç”Ÿæˆ
    full = _chat([
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ], TOKENS["block"], TEMP["block"])

    # âœ…è‡ªå·±æ·»å‰Šã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆä»»æ„ï¼‰
    if self_review:
        logging.info("ğŸ§  è‡ªå·±æ·»å‰Šãƒ¢ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œä¸­...")
        full = _chat([
            {"role": "system", "content": "ã‚ãªãŸã¯SEOè¨˜äº‹ã®ç·¨é›†è€…ã§ã™ã€‚ä»¥ä¸‹ã®è¨˜äº‹ã‚’æ·»å‰Šã—ã€æ§‹æˆã¨è«–ç†ã‚’å¼·åŒ–ã—ã¦ãã ã•ã„ã€‚"},
            {"role": "user", "content": full}
        ], TOKENS["block"], TEMP["block"])

    # âœ…æ–‡å­—æ•°åˆ¶é™è¶…éå¯¾å¿œ
    if len(full) > max_total:
        snippet = full[:max_total]
        cut = max(
            snippet.rfind("</p>"),
            snippet.rfind("</h2>"),
            snippet.rfind("</h3>"),
            snippet.rfind("</li>") if format == "html" else snippet.rfind("\n")
        )
        full = snippet[:cut + 5] if cut != -1 else snippet
        if format == "html" and not full.strip().endswith("</p>"):
            full += "</p>"
        logging.warning("âš ï¸ æœ¬æ–‡ãŒæœ€å¤§é•·ã‚’è¶…ãˆãŸãŸã‚å®‰å…¨ã«åˆ‡ã‚Šå–ã‚Šã¾ã—ãŸ")

    return full


# ============================================
# ğŸ”§ æ–‡å­—æ•°ãƒ¬ãƒ³ã‚¸ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰è‡ªå‹•æ¨å®š
# ============================================
def _parse_range(pt: str) -> Tuple[int, int | None]:
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ–‡å­—æ•°ã«å¿œã˜ã¦ã€å¿…è¦ãªæœ¬æ–‡ã®é•·ã•ã‚’æ¨å®šã€‚
    - æ˜ç¤ºçš„ãªã€Œâ—‹â—‹å­—ã‹ã‚‰â—‹â—‹å­—ã€ãŒã‚ã‚Œã°å„ªå…ˆ
    - ãªã‘ã‚Œã°ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·ã•ã«å¿œã˜ã¦å¼·ã‚ã«æŒ‡ç¤ºï¼ˆæœ€å°2200å­—ä»¥ä¸Šï¼‰
    """
    if m := re.search(r"(\d{3,5})\s*å­—ã‹ã‚‰\s*(\d{3,5})\s*å­—", pt):
        return int(m.group(1)), int(m.group(2))
    if m := re.search(r"(\d{3,5})\s*å­—", pt):
        return int(m.group(1)), None

    pt_len = len(pt)
    if pt_len < 500:
        return 2200, 2600
    elif pt_len < 1000:
        return 2400, 3000
    elif pt_len < 1500:
        return 2500, 3200
    else:
        return 2700, 3500


# ============================================
# ğŸ”§ æŠ•ç¨¿ã‚¹ãƒ­ãƒƒãƒˆç”Ÿæˆï¼ˆ1æ—¥3ã€œ5è¨˜äº‹ãƒ«ãƒ¼ãƒ«ï¼‰
# ============================================
def _generate_slots_per_site(app, site_id: int, n: int) -> List[datetime]:
    if n <= 0:
        return []
    with app.app_context():
        jst_date = func.date(func.timezone("Asia/Tokyo", Article.scheduled_at))
        rows = db.session.query(jst_date.label("d"), func.count(Article.id))\
            .filter(Article.site_id == site_id, Article.scheduled_at.isnot(None))\
            .group_by("d").all()
    booked = {d: c for d, c in rows}
    slots, day = [], date.today()
    while len(slots) < n:
        if (day - date.today()).days > MAX_SCHEDULE_DAYS:
            raise RuntimeError(f"{MAX_SCHEDULE_DAYS}æ—¥ä»¥å†…ã«ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã§ãã‚‹æ ãŒè¶³ã‚Šã¾ã›ã‚“")
        remain = MAX_PERDAY - booked.get(day, 0)
        if remain > 0:
            need = min(random.randint(1, AVERAGE_POSTS), remain, n - len(slots))
            for h in sorted(random.sample(POST_HOURS, need)):
                minute = random.randint(1, 59)
                local = datetime.combine(day, time(h, minute), tzinfo=JST)
                slots.append(local.astimezone(timezone.utc))
        day += timedelta(days=1)
    return slots[:n]


# ============================================
# ğŸ”§ å˜ä½“è¨˜äº‹ç”Ÿæˆå‡¦ç†ï¼ˆã‚¿ã‚¤ãƒˆãƒ«â†’æœ¬æ–‡â†’ç”»åƒâ†’å®Œäº†ï¼‰
# ============================================
def _generate(app, aid: int, tpt: str, bpt: str, format: str = "html", self_review: bool = False):
    """
    å˜ä½“è¨˜äº‹ç”Ÿæˆé–¢æ•°ï¼ˆ1è¨˜äº‹ã”ã¨ã«å‘¼ã³å‡ºã•ã‚Œã‚‹ï¼‰
    - ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ
    - æœ¬æ–‡ç”Ÿæˆï¼ˆformat / self_review ã‚ªãƒ—ã‚·ãƒ§ãƒ³å¯¾å¿œï¼‰
    - ã‚¢ã‚¤ã‚­ãƒ£ãƒƒãƒç”»åƒå–å¾—

    Args:
        app: Flaskã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
        aid: Article ID
        tpt: ã‚¿ã‚¤ãƒˆãƒ«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        bpt: æœ¬æ–‡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        format: "html" ã¾ãŸã¯ "markdown"
        self_review: True ã®å ´åˆã€GPTã«è‡ªå·±æ·»å‰Šã‚’ä¾é ¼ã™ã‚‹
    """
    with app.app_context():
        art = Article.query.get(aid)
        if not art or art.status != "pending":
            return

        try:
            if not art.title:
                art.title = f"{art.keyword}ã®è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«"

            art.status, art.progress = "gen", 10
            db.session.flush()

            # ã‚¿ã‚¤ãƒˆãƒ«ãŒã‚ã‚‹å‰æã§æœ¬æ–‡ç”Ÿæˆã¸ï¼ˆé€²æ—50%ï¼‰
            art.progress = 50
            db.session.flush()

            # âœ… æ–°ã—ã„ã‚ªãƒ—ã‚·ãƒ§ãƒ³ä»˜ãæœ¬æ–‡ç”Ÿæˆ
            art.body = _compose_body(
                kw=art.keyword,
                pt=bpt,
                format=format,
                self_review=self_review
            )
            art.progress = 80
            db.session.flush()

            # âœ… ã‚¢ã‚¤ã‚­ãƒ£ãƒƒãƒç”»åƒï¼ˆ1ã¤ç›®ã®h2è¦‹å‡ºã—ã‚’å‚ç…§ï¼‰
            match = re.search(r"<h2\b[^>]*>(.*?)</h2>", art.body or "", re.IGNORECASE)
            first_h2 = match.group(1) if match else ""
            query = f"{art.keyword} {first_h2}".strip()
            art.image_url = fetch_featured_image_from_body(art.body, art.keyword)

            art.status = "done"
            art.progress = 100
            art.updated_at = datetime.utcnow()
            db.session.commit()

        except Exception as e:
            logging.exception(f"Error generating article ID {aid}: {e}")
            art.status = "error"
            art.body = f"Error: {e}"
            db.session.commit()

        finally:
            # âœ… ã‚»ãƒƒã‚·ãƒ§ãƒ³æ˜ç¤ºçš„ã«è§£æ”¾ï¼ˆæ¥ç¶šãƒ—ãƒ¼ãƒ«ã®ç„¡é§„ãªä¿æŒã‚’é˜²æ­¢ï¼‰
            db.session.close()    


# ============================================
# ğŸ”§ éåŒæœŸä¸€æ‹¬ç”Ÿæˆï¼ˆenqueueï¼‰ã€ä¿®æ­£ç‰ˆã€‘
# ============================================
def enqueue_generation(
    user_id: int,
    keywords: List[str],
    title_prompt: str,
    body_prompt: str,
    site_id: int,
    format: str = "html",
    self_review: bool = False
) -> None:
    """
    è¤‡æ•°è¨˜äº‹ã‚’ä¸¦åˆ—ç”Ÿæˆã‚­ãƒ¥ãƒ¼ã«è¿½åŠ ã€‚ThreadPoolExecutor ã«ã‚ˆã‚ŠåŒæ™‚ä¸¦åˆ—ç”Ÿæˆã€‚
    """
    if site_id is None:
        raise ValueError("site_id is required for scheduling")

    app = current_app._get_current_object()
    copies = [random.randint(2, 3) for _ in keywords[:40]]
    total = sum(copies)
    slots = iter(_generate_slots_per_site(app, site_id, total))

    def _bg():
        with app.app_context():
            ids: list[int] = []

            # DBã¸ã®è¨˜äº‹ç™»éŒ²å‡¦ç†ï¼ˆç”Ÿæˆå‰ï¼‰
            for kw, c in zip(keywords[:40], copies):
                for _ in range(c):
                    try:
                        title = _unique_title(kw.strip(), title_prompt)
                        art = Article(
                            keyword=kw.strip(),
                            title=title,
                            user_id=user_id,
                            site_id=site_id,
                            status="pending",
                            progress=0,
                            scheduled_at=next(slots, None),
                        )
                        db.session.add(art)
                        db.session.flush()
                        ids.append(art.id)
                    except Exception as e:
                        db.session.rollback()
                        logging.exception(f"[ç™»éŒ²å¤±æ•—] keyword='{kw}': {e}")
            db.session.commit()

            # ä¸¦åˆ—ç”Ÿæˆå‡¦ç†
            with ThreadPoolExecutor(max_workers=4) as executor:
                futures = []
                for aid in ids:
                    futures.append(executor.submit(
                        _generate, app, aid, title_prompt, body_prompt, format, self_review
                    ))
                for future in as_completed(futures):
                    try:
                        future.result()
                    except Exception as e:
                        logging.exception(f"[ä¸¦åˆ—ç”Ÿæˆä¸­ã®ä¾‹å¤–] {e}")

    threading.Thread(target=_bg, daemon=True).start()


# ============================================
# ğŸ”§ åŒæœŸç”Ÿæˆç”¨ï¼ˆä¸»ã«å†ç”Ÿæˆç”¨ï¼‰
# ============================================
def _generate_and_wait(app, aid, tpt, bpt):
    event = Event()
    def background():
        _generate(app, aid, tpt, bpt)
        event.set()
    threading.Thread(target=background, daemon=True).start()
    event.wait()
