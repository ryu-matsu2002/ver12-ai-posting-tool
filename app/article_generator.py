# app/article_generator.py
# ä¿®æ­£ç‰ˆï¼ˆPixabayå¯¾å¿œ + ãƒã‚°ä¿®æ­£æ¸ˆï¼‰

import os, re, random, threading, logging, requests
from datetime import datetime, date, timedelta, time, timezone
from typing import List, Dict, Tuple
from difflib import SequenceMatcher
import pytz
import re
from flask import current_app
from openai import OpenAI, BadRequestError
from sqlalchemy import func
from threading import Event
from .image_utils import fetch_featured_image
from . import db
from .models import Article

# OpenAIè¨­å®š
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY", ""))
MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
TOKENS = {"title": 120, "outline": 800, "block": 3000}
TEMP = {"title": 0.6, "outline": 0.65, "block": 0.7}
TOP_P = 0.9
CTX_LIMIT = 12000
SHRINK = 0.6
AVG_BLOCK_CHARS = 600
MIN_BODY_CHARS_DEFAULT = 1800
MAX_BODY_CHARS_DEFAULT = 4000
MAX_TITLE_RETRY = 7
TITLE_DUP_THRESH = 0.90

# ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è¨­å®šï¼ˆJSTï¼‰
JST = pytz.timezone("Asia/Tokyo")
POST_HOURS = list(range(10, 21))
MAX_PERDAY = 5
AVERAGE_POSTS = 4


def _generate_slots_per_site(app, site_id: int, n: int) -> List[datetime]:
    """
    ç‰¹å®šã®ã‚µã‚¤ãƒˆã”ã¨ã«ã€1æ—¥3ï½5è¨˜äº‹ï¼ˆå¹³å‡4è¨˜äº‹ï¼‰ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦æŠ•ç¨¿ã‚¹ãƒ­ãƒƒãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    if n <= 0:
        return []

    with app.app_context():
        # JST ã§æ—¥å˜ä½ã«ã™ã§ã«ä½•ä»¶ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹å–å¾—
        jst_date = func.date(func.timezone("Asia/Tokyo", Article.scheduled_at))
        rows = db.session.query(jst_date.label("d"), func.count(Article.id))\
            .filter(
                Article.site_id == site_id,
                Article.scheduled_at.isnot(None)
            ).group_by("d").all()

    # æ—¥ä»˜ã”ã¨ã®äºˆç´„æ•°ã‚’ dict ã«
    booked = {d: c for d, c in rows}
    slots = []
    day = date.today() + timedelta(days=1)

    while len(slots) < n:
        # ãã®æ—¥ã®æ®‹ã‚ŠæŠ•ç¨¿æ ã‚’è¨ˆç®—
        remain = MAX_PERDAY - booked.get(day, 0)
        if remain > 0:
            # ãƒ©ãƒ³ãƒ€ãƒ ã§ 1ï½5ä»¶ã€ãŸã ã— remain/n ã«å¿œã˜ã¦èª¿æ•´
            need = min(random.randint(1, AVERAGE_POSTS), remain, n - len(slots))
            for h in sorted(random.sample(POST_HOURS, need)):
                minute = random.randint(1, 59)
                local = datetime.combine(day, time(h, minute), tzinfo=JST)
                slots.append(local.astimezone(timezone.utc))  # UTC ã«å¤‰æ›ã—ã¦ä¿å­˜
        day += timedelta(days=1)

        if (day - date.today()).days > 365:
            raise RuntimeError("slot generation runaway")

    current_app.logger.debug(f"Generated {n} slots for site {site_id}: {slots}")
    return slots[:n]


SAFE_SYS = "ã‚ãªãŸã¯ä¸€æµã®æ—¥æœ¬èª SEO ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚SEOã‚’æ„è­˜ã—ãŸè¦‹å‡ºã—ã‚„æœ¬æ–‡ã‚’æ§‹æˆã—ã€èª­è€…ã«ã¨ã£ã¦æœ‰ç›Šãªæƒ…å ±ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚"

def _tok(s: str) -> int:
    return int(len(s) / 1.8)

def clean_gpt_output(text: str) -> str:
    text = re.sub(r"```(?:html)?", "", text)
    text = re.sub(r"```", "", text)
    return text.strip()


def _chat(msgs: List[Dict[str, str]], max_t: int, temp: float) -> str:
    used = sum(_tok(m["content"]) for m in msgs)
    available = CTX_LIMIT - used - 16
    max_t = min(max_t, available)
    if max_t < 1:
        logging.error(f"max_tokens below minimum: {max_t} (used: {used})")
        raise ValueError("Calculated max_tokens is below minimum.")

    def _call(m: int) -> str:
        res = client.chat.completions.create(
            model=MODEL,
            messages=msgs,
            max_tokens=m,
            temperature=temp,
            top_p=TOP_P,
            timeout=120,
        )
        finish = res.choices[0].finish_reason
        content = res.choices[0].message.content.strip()

        # âœ… usageãƒ­ã‚°ã®ä¿è­·ä»˜ãè¡¨ç¤º
        usage = getattr(res, "usage", None)
        if usage:
            logging.info(
                f"[ChatGPT] finish_reason={finish} | tokens: prompt={usage.prompt_tokens}, "
                f"completion={usage.completion_tokens}, total={usage.total_tokens}"
            )

        if finish == "length":
            logging.warning("âš ï¸ OpenAI response was cut off due to max_tokens.")
            content += "\n<p><em>â€»ã“ã®æ–‡ç« ã¯ãƒˆãƒ¼ã‚¯ãƒ³ä¸Šé™ã§é€”ä¸­çµ‚äº†ã—ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚</em></p>"

        content = re.sub(r"^```html\s*", "", content, flags=re.IGNORECASE)
        content = re.sub(r"^```\s*", "", content)
        content = re.sub(r"\s*```$", "", content)
        content = clean_gpt_output(content)
        return content

    try:
        return _call(max_t)
    except BadRequestError as e:
        if "max_tokens" in str(e):
            retry_t = max(1, int(max_t * SHRINK))
            return _call(retry_t)
        raise



def _similar(a: str, b: str) -> bool:
    return SequenceMatcher(None, a, b).ratio() >= TITLE_DUP_THRESH

def _title_once(kw: str, pt: str, retry: bool) -> str:
    extra = "\nâ€»éå»ã«ä½¿ã‚ã‚ŒãŸã‚¿ã‚¤ãƒˆãƒ«ã‚„ä¼¼ãŸã‚¿ã‚¤ãƒˆãƒ«ã‚’çµ¶å¯¾ã«é¿ã‘ã¦ãã ã•ã„ã€‚" if retry else ""
    usr = f"{pt}{extra}\n\nâ–¼ æ¡ä»¶\n- å¿…ãšã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚ã‚‹\n- ã‚¿ã‚¤ãƒˆãƒ«ã¯ãƒ¦ãƒ‹ãƒ¼ã‚¯ã§ã‚ã‚‹ã“ã¨\nâ–¼ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {kw}"
    sys = SAFE_SYS + "é­…åŠ›çš„ãªæ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«ã‚’ 1 è¡Œã ã‘è¿”ã—ã¦ãã ã•ã„ã€‚"
    return _chat([
        {"role": "system", "content": sys},
        {"role": "user", "content": usr},
    ], TOKENS["title"], TEMP["title"])

def _unique_title(kw: str, pt: str) -> str:
    history = [t[0] for t in db.session.query(Article.title).filter(Article.keyword == kw)]
    for i in range(MAX_TITLE_RETRY):
        cand = _title_once(kw, pt, retry=i > 0)
        if not any(_similar(cand, h) for h in history):
            return cand
    logging.error(f"[ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆå¤±æ•—] keyword={kw}")
    raise ValueError(f"ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {kw}")

# outline, body ä½œæˆï¼ˆçœç•¥ã›ãšã«ç¶šããŒå¿…è¦ãªã‚‰é€ä¿¡ï¼‰


def _outline(kw: str, title: str, pt: str) -> str:
    sys = SAFE_SYS + "## / ### ã§è¦‹å‡ºã—ã‚’ç”Ÿæˆã—ã€è¨˜äº‹ã®å†…å®¹ã«åˆã‚ã›ã¦æŸ”è»Ÿã«èª¿æ•´ã—ã¾ã™ã€‚"
    usr = f"{pt}\n\nâ–¼ KW: {kw}\nâ–¼ TITLE: {title}"
    return _chat([
        {"role": "system", "content": sys},
        {"role": "user", "content": usr},
    ], TOKENS["outline"], TEMP["outline"])

def _parse_outline(raw: str) -> List[Tuple[str, List[str]]]:
    blocks, h2, h3s = [], None, []
    for ln in raw.splitlines():
        s = ln.strip()
        if not s:
            continue
        if s.startswith("## "):
            if h2:
                blocks.append((h2, h3s))
            h2, h3s = s[3:], []
        elif s.startswith("### "):
            h3s.append(s[4:])
        else:
            if h2:
                blocks.append((h2, h3s))
            h2, h3s = s, []
    if h2:
        blocks.append((h2, h3s))
    return blocks

def _block_html(kw: str, h2: str, h3s: List[str], persona: str, pt: str) -> str:
    h3_mark = "\n".join(f"### {h}" for h in h3s) if h3s else ""
    sys = (
        SAFE_SYS +
        "ä»¥ä¸‹ã®æ¡ä»¶ã§ <h2> ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ HTML ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚\n"
        "- ã“ã® H2 ãƒ–ãƒ­ãƒƒã‚¯ã¯ 550ã€œ750 å­—ã§ã¾ã¨ã‚ã‚‹\n"
        "- å°è¦‹å‡ºã—(H2) ã¯ 15 å­—ä»¥å†…\n"
        "- æ§‹æˆ: çµè«–â†’ç†ç”±â†’å…·ä½“ä¾‹Ã—3â†’å†çµè«–\n"
        "- å…·ä½“ä¾‹ã¯ <h3 class=\"wp-heading\"> ã§ç¤ºã™\n"
        f"- è¦–ç‚¹: {persona}\n"
        "- <h2>/<h3> ã«ã¯ class=\"wp-heading\" ã‚’ä»˜ä¸"
    )
    usr = f"{pt}\n\nâ–¼ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {kw}\nâ–¼ H2: {h2}\nâ–¼ H3 å€™è£œ:\n{h3_mark}"
    return _chat([
        {"role": "system", "content": sys},
        {"role": "user", "content": usr},
    ], TOKENS["block"], TEMP["block"])

def _parse_range(pt: str) -> Tuple[int, int | None]:
    if m := re.search(r"(\d{3,5})\s*å­—ã‹ã‚‰\s*(\d{3,5})\s*å­—", pt):
        return int(m.group(1)), int(m.group(2))
    if m := re.search(r"(\d{3,5})\s*å­—", pt):
        return int(m.group(1)), None

    pt_len = len(pt)
    if pt_len < 500:
        return 800, 1200
    elif pt_len < 1000:
        return 1200, 1800
    elif pt_len < 1500:
        return 1800, 2400
    else:
        return 2200, 3000


def _compose_body(kw: str, outline_raw: str, pt: str) -> str:
    min_chars, max_chars_user = _parse_range(pt)
    max_total = max_chars_user or MAX_BODY_CHARS_DEFAULT
    outline = _parse_outline(outline_raw)
    parts: List[str] = []

    for h2, h3s in outline:
        h2_short = (h2[:15] + "â€¦") if len(h2) > 15 else h2
        h3s_limited = [h for h in h3s if len(h) <= 10][:3]
        block_html = _block_html(kw, h2_short, h3s_limited, "default_persona", pt)
        parts.append(block_html)

    # ğŸ”° ã¾ã¨ã‚ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆ
    summary_prompt_sys = (
        SAFE_SYS +
        "ä»¥ä¸‹ã®æœ¬æ–‡ã‚’è¦ç´„ã—ã¦ã€<h2 class=\"wp-heading\">ã¾ã¨ã‚</h2><p>ï½</p> ã‚’ HTML ã§è¿”ã—ã¦ãã ã•ã„ã€‚\n"
        "ãƒ»æœ€å¾Œã«èª­äº†æ„ŸãŒã‚ã‚‹ã‚ˆã†ã«çµè«–ã‚„ãŠã™ã™ã‚ãªã©ã§ç· ã‚ããã£ã¦ãã ã•ã„ã€‚"
    )
    summary_prompt_usr = "\n\n".join(parts) + "\n\nâ–¼ ä¸Šè¨˜ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚"

    summary_html = _chat([
        {"role": "system", "content": summary_prompt_sys},
        {"role": "user", "content": summary_prompt_usr}
    ], TOKENS["block"], TEMP["block"]).strip()

    # ğŸ”§ å¿œç­”ãŒ <h2> ã‹ã‚‰å§‹ã¾ã‚‰ãªã‘ã‚Œã°æ˜ç¤ºçš„ã«å›²ã‚€
    if not summary_html.startswith("<h2"):
        summary_html = '<h2 class="wp-heading">ã¾ã¨ã‚</h2><p>' + summary_html + '</p>'

    full = "\n\n".join(parts + [summary_html])

    # ğŸ”§ é•·ã™ãã‚‹å ´åˆã¯å®‰å…¨ã«åˆ‡ã‚Šå–ã‚‹
    if len(full) > max_total:
        snippet = full[:max_total]

        # ğŸ”§ æœ€å¾Œã® <p>, <h2>, <h3> ã®çµ‚äº†ã‚¿ã‚°ä½ç½®ã‚’æ¢ã™
        cut = max(
            snippet.rfind("</p>"),
            snippet.rfind("</h2>"),
            snippet.rfind("</h3>")
        )

        # ğŸ”§ å®‰å…¨ã«ã‚¿ã‚°ã”ã¨ã‚«ãƒƒãƒˆã€ãã‚Œã§ã‚‚è¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã°ãã®ã¾ã¾åˆ‡ã‚‹
        full = snippet[:cut + 5] if cut != -1 else snippet

        # ğŸ”§ ä¸å®Œå…¨ã‚¿ã‚°ã§çµ‚ã‚ã£ã¦ãŸã‚‰ <p> ã§é–‰ã˜ã‚‹
        if not full.strip().endswith("</p>"):
            full += "</p>"

        logging.warning("âš ï¸ æœ¬æ–‡ãŒæœ€å¤§é•·ã‚’è¶…ãˆãŸãŸã‚å®‰å…¨ã«åˆ‡ã‚Šå–ã‚Šã¾ã—ãŸ")

    logging.debug("compose_body len=%s (max=%s)", len(full), max_total)
    return full

def _parse_range(pt: str) -> Tuple[int, int | None]:
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æœ¬æ–‡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ–‡å­—æ•°ã«å¿œã˜ã¦ã€ç”Ÿæˆã™ã‚‹æœ¬æ–‡ã®é•·ã•ï¼ˆæ–‡å­—æ•°ï¼‰ã‚’èª¿æ•´ã™ã‚‹ã€‚
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€Œâ—‹â—‹å­—ã‹ã‚‰â—‹â—‹å­—ã€ã¨æ˜ç¤ºã—ãŸå ´åˆã¯ãã®æŒ‡å®šã‚’å„ªå…ˆã€‚
    """
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ˜ç¤ºçš„ã«æ–‡å­—æ•°ç¯„å›²ã‚’æŒ‡å®šã—ã¦ã„ã‚‹å ´åˆ
    if m := re.search(r"(\d{3,5})\s*å­—ã‹ã‚‰\s*(\d{3,5})\s*å­—", pt):
        return int(m.group(1)), int(m.group(2))
    if m := re.search(r"(\d{3,5})\s*å­—", pt):
        return int(m.group(1)), None

    # ğŸ”§ è‡ªå‹•èª¿æ•´ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®é•·ã•ãƒ™ãƒ¼ã‚¹ï¼‰
    pt_len = len(pt)

    if pt_len < 500:
        return 800, 1200
    elif pt_len < 1000:
        return 1200, 1800
    elif pt_len < 1500:
        return 1800, 2400
    else:
        return 2200, 3000



def _generate(app, aid: int, tpt: str, bpt: str):

    with app.app_context():
        art = Article.query.get(aid)
        if not art or art.status != "pending":
            return
        try:
            if not art.title:
                art.title = f"{art.keyword}ã®è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«"
                logging.warning(f"Title was empty, setting default title: {art.title}")

            art.status, art.progress = "gen", 10
            db.session.flush()

            # âœ… STEP1: ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ç”Ÿæˆ
            outline = _outline(art.keyword, art.title, bpt)
            art.progress = 50
            db.session.flush()

            # âœ… STEP2: æœ¬æ–‡ç”Ÿæˆ
            art.body = _compose_body(art.keyword, outline, bpt)
            art.progress = 80
            db.session.flush()

            # âœ… STEP3: ã‚¢ã‚¤ã‚­ãƒ£ãƒƒãƒç”»åƒå–å¾—ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ + h2 ã§ç²¾åº¦å¼·åŒ–ï¼‰
            match = re.search(r"<h2\b[^>]*>(.*?)</h2>", art.body or "", re.IGNORECASE)
            first_h2 = match.group(1) if match else ""
            query = f"{art.keyword} {first_h2}".strip()
            art.image_url = fetch_featured_image(query)  # âœ… 1å¼•æ•°ã«çµ±ä¸€

            # âœ… STEP4: å®Œäº†å‡¦ç†
            art.status = "done"
            art.progress = 100
            art.updated_at = datetime.utcnow()
            db.session.commit()

            logging.info(f"Completed article ID {aid} generation.")

        except Exception as e:
            logging.exception(f"Error generating article ID {aid}: {e}")
            art.status = "error"
            art.body = f"Error: {e}"
            db.session.commit()

        finally:
            db.session.commit()

def enqueue_generation(user_id: int,
                       keywords: List[str],
                       title_prompt: str,
                       body_prompt: str,
                       site_id: int) -> None:
    if site_id is None:
        raise ValueError("site_id is required for scheduling")

    app = current_app._get_current_object()
    copies = [random.randint(1, 3) for _ in keywords[:40]]
    total = sum(copies)

    # ã‚µã‚¤ãƒˆã”ã¨ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç”Ÿæˆé–¢æ•°ã‚’ä½¿ç”¨
    slots = iter(_generate_slots_per_site(app, site_id, total))

    def _bg():
        with app.app_context():
            ids: list[int] = []
            for kw, c in zip(keywords[:40], copies):
                for _ in range(c):
                    try:
                        title = _unique_title(kw.strip(), title_prompt)
                        art = Article(
                            keyword=kw.strip(),
                            title=title,
                            user_id=user_id,
                            site_id=site_id,
                            status="pending",
                            progress=0,
                            scheduled_at=next(slots, None),
                        )
                        db.session.add(art)
                        db.session.flush()
                        db.session.commit()
                        ids.append(art.id)
                    except Exception as e:
                        db.session.rollback()
                        logging.exception(f"Error creating Article for keyword '{kw}': {e}")
            for aid in ids:
                _generate(app, aid, title_prompt, body_prompt)

    threading.Thread(target=_bg, daemon=True).start()




def _generate_and_wait(app, aid, tpt, bpt):
    event = Event()
    def background():
        _generate(app, aid, tpt, bpt)
        event.set()
    threading.Thread(target=background, daemon=True).start()
    event.wait()
